```
Skip to main content

An official website of the United States government

Here's how you know

                                  NCBI home page
                              
Search

Log in
Primary site navigation
Search PMC Full-Text Archive
Search PMC Full-Text Archive

Search in PMC
Advanced Search 
Journal List 
User Guide
As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.
Learn more: PMC Disclaimer | PMC Copyright Notice
Data in Brief logo
Data Brief. 2024 Jun 22;55:110665. doi: 10.1016/j.dib.2024.110665
Tennis player actions dataset for human pose estimation
Chun-Yi Wang a, Kalin Guanlun Lai b, Hsu-Chun Huang c, Wei-Ting Lin d,⁎
Author information
Article notes
Copyright and License information
PMCID: PMC11282921  PMID: 39071962
Abstract
Tennis is a popular sport, and integrating modern technological advancements can greatly enhance player training. Human pose estimation has seen substantial developments recently, driven by progress in deep learning. The dataset described in this paper was compiled from videos of researchers’ friend playing tennis. These videos were retrieved frame by frame to categorize various tennis movements, and human skeleton joints were annotated using COCO-Annotator to generate labelled JSON files. By combining these JSON files with the classified image set, we constructed the dataset for this paper. This dataset enables the training and validation of four tennis postures, forehand shot, backhand shot, ready position, and serves, using deep learning models (such as OpenPose). The researchers believe that this dataset will be a valuable asset to the tennis community and human pose estimation field, fostering innovation and excellence in the sport.

Keywords: Human posture recognition, Pose estimation, Keypoint detection, Tennis action, COCO, Sports Technology

Specifications Table

Subject	Computer Science / Computer Vision and Pattern Recognition;
Data Science / Applied Machine Learning
Specific subject area	Human Posture Recognition;
Action Recognition;
Pose Estimation;
Keypoint Detection
Data format	Filtered
Type of data	.jpeg file (the images from video's frame)
.json file (COCO-format)
Data collection	The dataset comprises 4 different actions in tennis, each action has 500 images and a COCO-format JSON files.The actions in this dataset, and the action categories name in COCO-format is in brackets:
1.backhand shot (backhand)
2.forehand shot (forehand)
3.ready position (ready_position)
4.serve (serve)
We organize two main directories: annotations and images.
•annotations: the JSON files of the actions (COCO-format)
▪We use COCO-Annotator to annotating and categorizing human actions.
•images: the images of the actions (according four actions classify to four folders)
▪The images in the dataset were extracted frame by frame from videos that were self-recorded, and manually classified according to different tennis actions.
Data source location	Taipei Tennis Center, in Taipei City, Taiwan.
Data accessibility	Repository name: Tennis Player Action Dataset for Human Pose Estimation
Data identification number: 10.17632/nv3rpsxhhkt
Direct URL to data: https://data.mendeley.com/datasets/nv3rpsxhhk
Open in a new tab
1. Value of the Data
•This dataset has significantly contributed to sports technology by integrating computer vision techniques to further the advancement of sports tech.
•Employing the widely used COCO-format and annotates human skeletal joints (key points), facilitating easy access and training for users.
•The dataset is meticulously curated to capture the nuances of tennis movements, providing detailed annotations for a variety of actions such as serves, volleys, and groundstrokes. This allows for the development of precise pose estimation models that are highly effective in analyzing and enhancing tennis performance.
•If needed, users can also utilize this dataset for other applications, such as tracking tennis balls, by labeling and training it on their own.
2. Background
Datasets related to sports provide valuable data for a wide range of research fields, including policy-making, education, public health, and sports science. Traditionally, these datasets mainly contain raw statistics on athletes' physical conditions, outputs from various modeling efforts, or data collected through software tools, all of which contribute significantly to the advancement of these fields [[1], [2], [3], [4]]. As technology progresses, computer vision has emerged as a critical area of research, especially in human pose estimation. This domain has witnessed the development of specific datasets to support such research efforts [[5], [6]]. Consequently, several datasets within the field of sports science are now specifically designed for training human pose estimation models. For instance, LDCNet focuses on flexible human pose estimation by leveraging limb direction cues, highlighting its application in industrial behavioral biometrics systems [7]. Another example is ARHPE, which employs asymmetric relation-aware representation learning to enhance head pose estimation, a crucial aspect in industrial human-computer interaction [8]. Additionally, MFDNet advances the field by integrating collaborative pose perception with matrix Fisher distribution for precise head pose estimation [9]. These datasets are integral in supporting the development and refinement of human pose estimation models, facilitating advancements in sports science and other related fields.

Traditional practices for creating datasets have predominantly relied on computer vision techniques. However, with the advent and evolution of deep learning, the need for raw image files and annotation data has become paramount. The COCO format has emerged as a standard for annotation data in recent years [8]. Our dataset also utilizes the COCO format, facilitating its use for training and validation in deep learning models such as OpenPose [9] and MediaPipe [10]. This dataset comprises a comprehensive collection of annotated tennis action images, designed to train models capable of recognizing specific postures within tennis matches. Moreover, users can customize the dataset for other applications, such as tracking tennis balls, by adding their own labels and training data. The primary objective of this dataset is to promote the advancement of computer vision applications in tennis-related fields. In recent years, several significant advancements have been made in the field of computer vision and deep learning. For example, OpenPose represents a notable improvement over traditional pose estimation models by providing a multi-person pose detection framework, which enhances the accuracy and applicability of pose recognition [9]. Similarly, MediaPipe has extended these capabilities by integrating real-time pose estimation with high efficiency, making it a preferred tool for a wide range of applications beyond sports [10]. The progression from basic pose estimation models to more sophisticated frameworks illustrates the rapid development and increasing precision of computer vision technologies, which our dataset aims to support.

3. Data Description
This dataset is designed for human pose estimation applications within tennis, featuring commonly observed tennis postures including forehand stroke, backhand stroke, ready position, and serve, as shown in Fig. 1.

Fig. 1.
Fig 1

Open in a new tab
Common tennis postures. (A) Backhand stroke, (B) Forehand stroke, (C) Ready Position, (D) Serve.

This dataset contains two parts: 1. images from the frame of the video of the players’ action, and 2. the action annotation JSON files (COCO-format). Part 1 have 2,000 images, part 2 have 4 files, and it on Mendeley Data shown in Fig. 2 (size on disk is about 508 MB (533,372,928 bytes)).

Fig. 2.
Fig 2

Open in a new tab
Dataset files on Mendeley Data.

The researchers organized two parts as two main directories. One is images, it divided into four subfolders by posture in ``images'' folder. The files in the subfolders are named by researchers, following a specific convention. Researchers extract the first letter of the parent folders and assign sequential numbering. For instance, the name of the images within ``images/backhand'' folder have prefix ``B_'', and followed by a numerical sequence (e.g., B_001, B_002, …, B_500). The Other is annotation JSON files, it has four files and named by four postures. Folder structure is shown in Fig. 3.

Fig. 3.
Fig 3

Open in a new tab
Folder structure.

4. Image Information
The dataset described in this article contains 500 images for each posture, total have 2000 images. Before classified to four specific actions, the researchers first recorded videos of themselves playing tennis, then analyzed these videos’ frame by frame to classify the frames’ image into the specified actions. These videos were captured using a smartphone with a resolution of 720P, with dimensions of 1280 pixels width and 720 pixels height, and a frame rate of 30 fps, so the images’ resolution also is 1280 × 720. The data collection outline is shown in Table 1.

Table 1.
Brief description about the data collection.

No.	Particulars	Description
1	Data type	4 tennis postures:
(1)forehand stroke
(2)backhand stroke
(3)ready position
(4)serve
2	Original data format	Video file using H.264/MPEG-4 AVC codec (.mp4)
Resolution: 720P (1280 × 720 pixels)
Frame Rate: 30 fps
3	Filtered data format	JPEG image file (.jpeg)
Resolution: 720P (1280 × 720 pixels)
4	Period and Date	January-December 2023
5	Participants	Member of the World Junior Team Championships (Lin,yu-min. Taiwan)
6	Location	Taipei Tennis Center
Open in a new tab
Source: Author's own organization.

5. Annotation File Information
The researchers utilize the extracted images to annotate human skeletal joints and classify the postures. For supplying common deep learning model of human pose estimation to train, the researchers use COCO-Annotator [11] as annotation tool, annotated joints are illustrated in Fig. 4 and the joints number and name pairs are shown in Table 2.

Fig. 4.
Fig 4

Open in a new tab
Human skeleton joints in the dataset.

Table 2.
Skeleton joint number to name pairs in Fig. 4.

Joint's No.	Joint's Name
0	nose
1	left_eye
2	right_eye
3	left_ear
4	right_ear
5	left_shoulder
6	right_shoulder
7	left_elbow
8	right_elbow
9	left_wrist
10	right_wrist
11	left_hip
12	right_hip
13	left_knee
14	right_knee
15	left_ankle
16	right_ankle
17	neck
Open in a new tab
Source: Author's own organization.

Because the researchers use COCO-Annotator, so the generated JSON files must be COCO format. The JSON file's format in this dataset is shown in Table 3. The instances of categories’ name, keypoints, and skeleton in JSON file is represent to Fig. 5, the name of category in the red box is the posture's name, the category information is set by researchers using COCO-Annotator. The instance of image and annotation in the JSON file is represent to Fig. 6.

Table 3.
JSON file's format of this dataset.

{
``images'': [
{
``id'': (image ID, same as the id in part of ``annotations''),
``dataset_id'': (dataset ID),
``path'': (image file path),
``width'': (image width),
``height'': (image height),
``file_name'': (image file name)
},
…
],
``categories'': [
{
``id'': (category ID),
``name'': (category name, same as the id in part of ``annotations''),
``keypoints'': (keypoints list),
``skeleton'': (skeleton (connected keypoints) list)
}
],
``annotations'': [
{
``id'': (annotation ID),
``image_id'': (image ID, same as the id in part of "images"),
``category_id'': (category ID, same as the id in part of ``category''),
``segmentation'': (polygon list),
``area'': (the area of the target box. unit: pixel),
``bbox'': (the coordinates list of the target box’ each corners),
``iscrowd'': (whether the image is a crowd),
``isbbox'': (whether the image has target box),
``keypoints'': (list of keypoints coordinates on the image),
``num_keypoints'': (number of keypoints on the image)
},
…
]
}
Open in a new tab
Source: Author's own organization.

Fig. 5.
Fig 5

Open in a new tab
The instance of the categories’ part in JSON file (for 4 postures).

Fig. 6.
Fig 6

Open in a new tab
The instance of the part of image and annotation in JSON file (from 2 backhand images).

6. Experimental Design, Materials and Methods
The camera is positioned at the rear of the tennis court, capturing the player from behind (aligned with the player's facing direction). The camera is positioned approximately 6.4 meters from the court's baseline. The height, while not fixed or recorded, is considered by researchers to be inconsequential for the purpose of analyzing tennis movements. The location of the camera setup is shown in Fig. 7.

Fig. 7.
Fig 7

Open in a new tab
Location of camera setup in the experimental field.

Before playing tennis, we set up an experimental recording environment like above. Once the setup is complete, we began recording the video. Subsequently, we retrieve the video frame by frame, classifying each frame according to the specific tennis action it captures to compile an image dataset. Then the researchers annotated target human's skeleton joint for each image in these images using COCO-Annotator and generate labeled JSON files to construct the dataset for this article. The process flow is illustrated in Fig. 8.

Fig. 8.
Fig 8

Open in a new tab
The process flow of annotating using COCO-Annotator.

Limitations
When creating this dataset, the camera setup was not at a fixed distance; it was simply positioned behind the player to record the various strokes. The dataset currently includes only four actions: forehand shot, backhand shot, ready position, and serve. While these encompass most of the essential tennis movements, some minor actions might still be missing. In the future, we aim to expand the collection to include a broader range of movements and to augment the dataset with additional images.

Ethics Statement
After the performance of the experiment, we blurred all unrelated people in images (the people of the opposite field). And the participant (the person back on the camera) in images is the authors’ friend, he provided some data related to physical status and habits of individual, and they read and signed an informed consent form, conserved at Physical Education Office at ``National Kaohsiung University of Science and Technology'' (the correspondent's office). We follow Research ethics guidelines in everything we do, and have obtained a certificate from the local Center for Taiwan Academic Research Ethics Education, certificate number: P107259575-1.

CRediT authorship contribution statement
Chun-Yi Wang: Conceptualization, Data curation, Methodology. Kalin Guanlun Lai: Software, Writing – original draft. Hsu-Chun Huang: Validation, Writing – review & editing. Wei-Ting Lin: Supervision, Validation, Writing – review & editing.

Acknowledgement
This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.

Declaration of Competing Interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Data Availability
Tennis Player Actions Dataset for Human Pose Estimation (Original data) (Mendeley Data).

References
1.Bourdas D.I., Bakirtzoglou P., Travlos A.K., Andrianopoulos V., Zacharakis E. Analysis of a comprehensive dataset: Influence of vaccination profile, types, and severe acute respiratory syndrome coronavirus 2 re-infections on changes in sports-related physical activity one month after infection. Data Brief. 2023;51 doi: 10.1016/j.dib.2023.109723. [DOI] [PMC free article] [PubMed] [Google Scholar]
2.Mountifield C. Data on Gaussian copula modelling of the views of sport club members relating to community sport, Australian sport policy and advocacy. Data Brief. 2022;42 doi: 10.1016/j.dib.2022.108111. [DOI] [PMC free article] [PubMed] [Google Scholar]
3.Pinheiro P., Cavique L. Regular sports services: dataset of demographic, frequency and service level agreement. Data Brief. 2021;36 doi: 10.1016/j.dib.2021.107054. [DOI] [PMC free article] [PubMed] [Google Scholar]
4.Limroongreungrat W., Mawhinney C., Kongthongsung S., Pitaksathienkul C. Landing error scoring system: data from youth volleyball players. Data Brief. 2022;41 doi: 10.1016/j.dib.2022.107916. [DOI] [PMC free article] [PubMed] [Google Scholar]
5.Rodrigues N.R.P., Costa N.M.C.da, Novais R., Fonseca J., Cardoso P., Borges J. AI based monitoring violent action detection data for in-vehicle scenarios. Data Brief. 2022;45 doi: 10.1016/j.dib.2022.108564. [DOI] [PMC free article] [PubMed] [Google Scholar]
6.Ruescas-Nicolau A.V., Medina-Ripoll E.J., Bernabé E.P., Martínez H., de R. Multimodal human motion dataset of 3D anatomical landmarks and pose keypoints. Data Brief. 2024;53 doi: 10.1016/j.dib.2024.110157. [DOI] [PMC free article] [PubMed] [Google Scholar]
7.Suryawanshi Y., Gunjal N., Kanorewala B., Patil K. Yoga dataset: a resource for computer vision-based analysis of Yoga asanas. Data Brief. 2023;48 doi: 10.1016/j.dib.2023.109257. [DOI] [PMC free article] [PubMed] [Google Scholar]
8.Lin, T.-Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Ramanan D., Zitnick, C. L., and Dollár, P., "Microsoft COCO: common objects in context." (2015) arXiv:1405.0312.
9.Cao Z., Hidalgo G., Simon T., Wei S.-E., Sheikh Y. OpenPose: realtime multi-person 2D pose estimation using part affinity fields. IEEE Trans. Pattern Anal. Mach. Intell. 2021;43(1):172–186. doi: 10.1109/TPAMI.2019.2929257. [DOI] [PubMed] [Google Scholar]
10.Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja E., Hays, M., Zhang, F., Chang, C.-L., Yong M., Lee, J., Chang, W.-T., Hua, W., Georg, M., and Grundmann, M., "MediaPipe: a framework for building perception pipelines." (2019) arXiv:1906.08172.
11.Brooks, J. "COCO annotator." 2019. Retrieved from https://github.com/jsbroks/coco-annotator/.
Associated Data
This section collects any data citations, data availability statements, or supplementary materials included in this article.

Data Availability Statement
Tennis Player Actions Dataset for Human Pose Estimation (Original data) (Mendeley Data).

Articles from Data in Brief are provided here courtesy of Elsevier

ACTIONS
View on publisher site
PDF (1.6 MB)

Cite

Collections

Permalink
RESOURCES
Similar articles
Cited by other articles
Links to NCBI Databases
On this page
Abstract
1. Value of the Data
2. Background
3. Data Description
4. Image Information
5. Annotation File Information
6. Experimental Design, Materials and Methods
Limitations
Ethics Statement
CRediT authorship contribution statement
Acknowledgement
Data Availability
References
Associated Data

Follow NCBI
NCBI on X (formerly known as Twitter)
NCBI on Facebook
NCBI on LinkedIn
NCBI on GitHub
NCBI RSS feed
Connect with NLM

NLM on X (formerly known as Twitter)
NLM on Facebook
NLM on YouTube
National Library of Medicine
8600 Rockville Pike
Bethesda, MD 20894

Web Policies
FOIA
HHS Vulnerability Disclosure
Help
Accessibility
Careers
NLM
NIH
HHS
USA.gov
Tell us what you think!
```

```
Skip to main content

An official website of the United States government

Here's how you know

                                  NCBI home page
                              
Search

Log in
Primary site navigation
Search PMC Full-Text Archive
Search PMC Full-Text Archive

Search in PMC
Advanced Search 
Journal List 
User Guide
As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.
Learn more: PMC Disclaimer | PMC Copyright Notice
Data in Brief logo
Data Brief. 2024 Apr 18;54:110438. doi: 10.1016/j.dib.2024.110438
Tennis shot side-view and top-view data set for player analysis in Tennist
Kalin Guanlun Lai a, Hsu-Chun Huang b, Wei-Ting Lin c,⁎, Shang-Yi Lin a, Kawuu Weicheng Lin a
Author information
Article notes
Copyright and License information
PMCID: PMC11068545  PMID: 38708306
Abstract
Tennis is a popular sport, and the introduction of technology has allowed players to diversify their training. Tennis ball tracking is currently a focal point, serving not only to assist referees but also to enhance sports analysis. We introduce the Tennis Shot Side-View and Top-View Dataset, which serves as an invaluable resource for analyzing tennis movements and verifying landing positions after flight. This dataset combines side-view and top-view video clips, capturing various shot types and player movements from both outdoor and indoor fields. The dataset includes the actual ball positions of each clip for verification purposes. The Tennis Shot Side-View and Top-View Dataset represents a significant advancement in tennis research. Its multidimensional nature opens doors for in-depth player analysis, performance enhancement, and strategy development. We believe that this dataset will be a valuable asset to the tennis community, fostering innovation and excellence in the sport.

Keywords: Object tracking, Physical simulation, Tennis ball flying, Sports technology

Specifications Table

Subject	Computer Science / Computer Vision and Pattern Recognition
Specific subject area	Image Processing; 3D Reconstruction; Object Tracking in Video;
Tennis Tracking; 3D Ball Trajectory Simulation
Data format	Raw
Type of data	Video file using H.264/MPEG-4 AVC codec (.mp4)
.csv file (the records of real landing point)
Data collection	The dataset includes 472 clips, organized to two main directories: “Outdoor Field” and “Indoor Field”. These directories are divided into sub-directories, “Straight Shot” and “Cross-court Shot”. Both of shots (tennis forehand shots) directories are split into two view folders, “Top-View” and “Side-View”:
•“Outdoor Field/Straight Shot/Top-View” includes 18 clips representing the top-view of tennis straight shot in outdoor field.
•“Outdoor Field/Straight Shot /Side-View” includes 18 clips representing the side-view of tennis straight shot in outdoor field.
•“Outdoor Field/Cross-court Shot/Top-View” includes 20 clips representing the top-view of tennis cross-court shot in outdoor field.
•“Outdoor Field/Cross-court Shot/Side-View” includes 20 clips representing the side-view of tennis cross-court shot in outdoor field.
•“Indoor Field/Straight Shot/Top-View” includes 99 clips representing the top-view of tennis straight shot in Indoor field.
•“Indoor Field/Straight Shot/Side-View” includes 99 clips representing the side-view of tennis straight shot in Indoor field.
•“Indoor Field/Cross-court Shot/Top-View” includes 99 clips representing the top-view of tennis cross-court shot in Indoor field.
•“Indoor Field/Cross-court Shot/Side-View” includes 99 clips representing the side-view of tennis cross-court shot in Indoor field.
The CSV files under root folder contain each ball's real landing point coordinates records. The file's name indicates the data is from where: field categories and shot types.
Data source location	National Kaohsiung University of Science and Technology (NKUST).
Outdoor field:Tennis Courts in NKUST
Indoor field:Stadiums in NKUST
Data accessibility	Repository name: Tennis Shot Side-View and Top-View Data Set for Player Analysis in Tennis
Data identification number: 10.17632/75m8vz7jr2.2
Direct URL to data: https://data.mendeley.com/datasets/75m8vz7jr2
Open in a new tab
1. Value of the Data
•Advancing sports technology, our dataset represents a significant contribution to the field of sports technology. Demonstrates how the integration of computer vision technology can be utilized in tennis practice assistance and data analysis.
•Facilitating image recognition in sports, our dataset includes valuable insights into image recognition techniques applied in sports. The accuracy of the data helps researchers and practitioners in the development of recreational games.
•To predict the landing position of the tennis ball after flight, our dataset contains data related to the landing position of the tennis ball after flight. By analyzing the verification of the correct position of the tennis ball after flight, we help to understand ball physics and help to predict the flight pattern of the ball in a real tennis match.
•It is necessary to establish a diversified database of sports data, and through the data collection in different tennis courts, we can understand the difference between the data collection in Outdoor field and Indoor field. It will be helpful for researchers to have a reference on the diversity of data collection.
2. Background
Sports-related datasets offer valuable insights into various aspects such as policy-making, consumer decision-making, and sports science. These datasets play a crucial role in monitoring athlete health, managing sports injuries, analyzing athlete skills, and enhancing science and technology [1], [2], [3]. As technology continues to advance, its application in sports-related domains becomes increasingly prevalent. Whether it involves data collection through technology or the utilization of data to develop technological systems, this approach represents the current mainstream trend [4], [5], [6].

In our specific context, our focus lies on the development of interactive entertainment. This entails harnessing computer vision methodologies, including moving object segmentation and color segmentation. Within the realm of sports science and technology, the dataset under consideration serves as a vital resource for research endeavors aiming to uncover the intricate dynamics of tennis gameplay [7,8]. The dataset comprises rich top-view and side-view video clips, facilitating the estimation of the tennis ball's landing position [9].

This dataset offers spatial data from two perspectives, contributing to the establishment of comprehensive landing coordinates for tennis trajectories [10,11]. By integrating computer vision technology, players can predict the landing position of the tennis ball after contact. Our goal with this dataset is to foster the advancement of computer vision applications in tennis-related fields, particularly in interactive entertainment scenarios. The dataset is tailored for validation purposes to ensure its utility and effectiveness across various applications in the field.

3. Data Description
Our dataset represents a valuable resource for researchers and enthusiasts in the realm of sports science, computer vision, and tennis analysis [12,13]. We have constructed a unique dataset that captures tennis activities in diverse environments, encompassing both outdoor fields, exemplified by tennis clay courts, and Indoor fields built within stadiums. Indoor fields serve as a valuable resource for players seeking indoor practice environments, a feature less popular in regions such as Taiwan compared to Europe and the United States. Moreover, these Indoor fields in school gymnasiums address the challenge of playing tennis outdoors during adverse weather conditions, facilitating year-round training.

This experiment was conducted at NKUST, involving both tennis courts and stadiums. Two cameras were utilized for the experiment, and the same participant conducted the experiment in different venues. The data in our dataset is collected from both an outdoor field and an indoor field, which enhances the reliability of our data [14]. In the outdoor field, we specifically chose a clay tennis court because it provides greater accuracy in measuring real distances, as it retains the imprint of the tennis ball on the ground. For the indoor field, we utilize the gymnasium to set up a tennis court, which can be used for data acquisition in the indoor space. The comparison between the outdoor field and the indoor field is illustrated in Fig. 1.

Fig. 1.
Fig 1

Open in a new tab
The comparison between the outdoor field and the indoor field is illustrated. (A) Outdoor field top view. (B) Outdoor field side view. (C) Indoor field top view. (D) Indoor field side view.

Researchers can track the precise movement trajectories of athletes and the landing positions of tennis balls in dynamic real-world environments. This capability opens avenues for in-depth spatial analysis, enabling investigations into factors such as shot accuracy, player positioning, and the influence of court geometry on gameplay. This dataset contains two parts: 1. clips of players hitting the ball, and 2. the landing position of the ball after the flight (the landing position of each ball).

4. Clips Information
The dataset described in this article contains 472 clips of a tennis ball being swung. The data is categorized into two types based on the field: Outdoor field and Indoor field. Within these categories, there are two types of shots: Straight shot and Cross-court shot. Each data item includes Top view clips and side view clips. Researchers can utilize various computer vision and image processing algorithms to recognize and detect these different versions of the dataset. Clips from 2 viewpoints to verify the landing position of a flying tennis ball, revealing the complex dynamics of this fast-paced sport [15,16]. All clips were captured on the campus of the National Kaohsiung University of Science and Technology (NKUST) using a GoPro HERO 10 Black camera, with support from sports research experts and graduate students. Aerial camera operations were employed for top-view imaging. All clips have a resolution of 1080P, with dimensions of 1920 pixels width and 1080 pixels height, and a frame rate of 60 fps. The data collection process is outlined in Table 1.

Table 1.
Brief description about the data collection.

No.	Particulars	Description
1	Data type	Outdoor field and Indoor field
2	Data categories	Straight shot and Cross-court shot
3	Data item	Top view clips and Side view clips
4	Data format	Video file using H.264/MPEG-4 AVC codec (.mp4)
Resolution: 1080P (1920 × 1080 pixels)
Frame Rate: 60 fps
5	Period and Date	Outdoor field:March 1, 2023, 10 a.m.-12 p.m.
Indoor field:March 2, 2023, 10 a.m.-12 p.m.
6	Participants	The Students of NKUST Tennis Team
7	Location	Outdoor field:Tennis Courts in NKUST
Indoor field:Stadiums in NKUST
Open in a new tab
Source: Author's own organization

5. Dataset Information
Because researchers collected data at outdoor field and indoor field, the dataset organized to two main directories. Under these directories, both are divided into two subfolders by shot type (straight shot and cross-court shot). Then, each ball includes two views, side-view and top view, so splitting into two folders in these subfolders. The files in the dataset are named by researchers, following a specific convention. Researchers extract the first letter of the parent folders and assign sequential numbering. For instance, clips within the “Outdoor Field/Straight Shot/Top-View” subfolder are denoted by OST followed by a numerical sequence (e.g., OST01, OST02, ..., OST99). Folder structure is shown in Fig. 2.

Fig. 2.
Fig 2

Open in a new tab
Folder structure.

The dataset contains 472 clips (both of side-view and top-view are 236 clips), and 4 records files, and it on Mendeley Data shown in Fig. 3 (size on disk is about 12.42 GB (2,601,105,575 bytes)).

Fig. 3.
Fig 3

Open in a new tab
Dataset files on Mendeley Data

Landing Position after Tennis Ball Flying, researchers record each ball's real landing point coordinates. These data are recorded in the CSV files, and the CSV files are under the root folder. The file's name indicates where the data is from: field categories and shot types. An essential aspect of the image acquisition process is the need for actual coordinates. Throughout the data collection process, we measure and record the real landing point's coordinates of the ball each time a participant hits it, using the distance of the closest doubles sideline and the distance of the baseline to present (outside ball represent by negative number). These actual coordinates are crucial for validating the projections. Data category description is provided in Table 2.

Table 2.
Data category description and capture techniques.

Categories	Description
Straight shot	Total 234 clips, including Outdoor field's Top-view 18 clips, Side-view 18 clips; Indoor field's Top-view 99 clips, Side-view 99 clips.
Cross-court shot	Total 238 clips, including Outdoor field's Top-view 20 clips, Side-view 20 clips; Indoor field's Top-view 99 clips, Side-view 99 clips.
Open in a new tab
Source: Author's own organization

6. Experimental Design, Materials and Methods
The camera setup comprises two parts: top view and side view. For the top view, we positioned the camera directly behind the field, about 1.21 m from the bottom line, and at a height of 5.15 m. For the side view, we set up on the right side of the field, about 2.45 m from the sideline and about 2.40 m from the baseline, with the camera at a height of 1.27 m.

Setting up the top view for the Outdoor field proved more challenging, so we utilized an aerial camera to assist in this part. This approach ensured the consistency of the data obtained from both the outdoor field and the indoor field. The location of the camera setup is shown in Fig. 4.

Fig. 4.
Fig 4

Open in a new tab
Location map of the camera setup in the experimental field. (A) Top view camera. (B) Side view camera.

The landing position of the ball after the flight (the landing position of each ball) is mentioned in the data description. What we do in Outdoor field is to circle the landing position of each ball, number each ball and finally measure and record the actual position. In Indoor field, the landing position of each ball is not marked, so we put a label with a number on it every time the ball hits the ground, and then measure and record the actual position of the ball. The measurement and recording of the data are shown in Fig. 5.

Fig. 5.
Fig 5

Open in a new tab
Measurement and recording of data (A) Measurement and recording of the Outdoor Field (Inside the blue box are the surveyor). (B) Measurement and recording of the Indoor field (Inside the blue box are the surveyor).

Limitations
The sources for this article are red clay tennis courts and indoor virtual tennis courts; there are no other sources for material tennis courts. In the future, more tennis courts of different materials will be planned to collect data and interpret tennis ball tracking information on a larger scale.

Ethics Statement
Before the performance of the experiment, all participants involved in the clip recording provided some data related to physical status and habits of individual, and they read and signed an informed consent form, conserved at Physical Education Office at “National Kaohsiung University of Science and Technology” (the correspondent's office).

CRediT authorship contribution statement
Kalin Guanlun Lai: Conceptualization, Methodology, Software, Writing – original draft, Investigation. Hsu-Chun Huang: Validation, Writing – review & editing. Wei-Ting Lin: Supervision, Validation, Writing – review & editing. Shang-Yi Lin: Validation, Writing – review & editing. Kawuu Weicheng Lin: Validation, Writing – review & editing.

Acknowledgments
Acknowledgments
This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.

Declaration of Competing Interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Data Availability
Tennis Shot Side-View and Top-View Data Set for 3D Reconstruction and Player Analysis in Tennis (Original data) (Mendeley Data).

References
1.Mountifield C. Data on Gaussian copula modelling of the views of sport club members relating to community sport, Australian sport policy and advocacy. Data Br. 2022;42 doi: 10.1016/j.dib.2022.108111. [DOI] [PMC free article] [PubMed] [Google Scholar]
2.Breuer C., Boronczyk F., Rumpf C. Dataset for the analysis of TV viewer response to live sport broadcasts and sponsor messages. Data Br. 2021;38 doi: 10.1016/j.dib.2021.107281. [DOI] [PMC free article] [PubMed] [Google Scholar]
3.Dejgaard L.A., Haland T.F., Lie O.H., Ribe M., Bjune T., Leren I.S.…Haugaa K.H. Data on exercise and cardiac imaging in a patient cohort with hypertrophic cardiomyopathy. Data Br. 2017;15:30–39. doi: 10.1016/j.dib.2017.08.018. [DOI] [PMC free article] [PubMed] [Google Scholar]
4.Sbrollini A., et al. Sport database: cardiorespiratory data acquired through wearable sensors while practicing sports. Data Br. 2019;27 doi: 10.1016/j.dib.2019.104793. [DOI] [PMC free article] [PubMed] [Google Scholar]
5.Studnicki A., Ferris D.P. Dual-layer electroencephalography data during real-world table tennis. Data Br. 2023 doi: 10.1016/j.dib.2023.110024. [DOI] [PMC free article] [PubMed] [Google Scholar]
6.Tabrizi S.S., Pashazadeh S., Javani V. Data acquired by a single object sensor for the detection and quality evaluation of table tennis forehand strokes. Data Br. 2020;33 doi: 10.1016/j.dib.2020.106504. [DOI] [PMC free article] [PubMed] [Google Scholar]
7.Khder M.A., Fujo S.W. Applying machine learning-supervised learning techniques for tennis players dataset analysis. Int. J. Adv. Soft Comput. Appl. 2022;14(3) [Google Scholar]
8.Shimizu T., Hachiuma R., Saito H., Yoshikawa T., Lee C. Proceedings of the 2nd International Workshop on Multimedia Content Analysis in Sports. 2019. Prediction of future shot direction using pose and position of tennis player; pp. 59–66. [Google Scholar]
9.Skublewska-Paszkowska M., Powroznik P., Lukasik E. Learning three dimensional tennis shots using graph convolutional networks. Sensors. 2020;20(21):6094. doi: 10.3390/s20216094. [DOI] [PMC free article] [PubMed] [Google Scholar]
10.Delgado-García G., Coll J.S., Infantes S.C., Malagón E.J.R., Colio B.B., Fernández F.T.G. Validation of wearables for technical analysis of tennis players. Int. J. Racket Sports Sci. 2022;4(2):56–60. [Google Scholar]
11.Gao Y., Tebbe J., Krismer J., Zell A. Markerless racket pose detection and stroke classification based on stereo vision for table tennis robots. 2019 Third IEEE International Conference on Robotic Computing (IRC); IEEE; 2019. pp. 189–196. [Google Scholar]
12.Cant O., Kovalchik S., Cross R., Reid M. ISBS Proceedings Archive. Vol. 37. 2019. Using tracking technology to estimate ball SPIN IN tennis; p. 507. [Google Scholar]
13.Cant O., Kovalchik S., Cross R., Reid M. Validation of ball spin estimates in tennis from multi-camera tracking data. J. Sports Sci. 2020;38(3):296–303. doi: 10.1080/02640414.2019.1697189. [DOI] [PubMed] [Google Scholar]
14.Gong X., Wang F. Classification of tennis video types based on machine learning technology. Wirel. Commun. Mobile Comput. 2021;2021:1–11. [Google Scholar]
15.Noury P.L., Buszard T., Reid M., Farrow D. Examining the representativeness of a virtual reality environment for simulation of tennis performance. J. Sports Sci. 2021;39(4):412–420. doi: 10.1080/02640414.2020.1823618. [DOI] [PubMed] [Google Scholar]
16.Tang H. Detection algorithm of tennis serve mistakes based on feature point trajectory. Adv. Meteorol. 2022;2022 [Google Scholar]
Associated Data
This section collects any data citations, data availability statements, or supplementary materials included in this article.

Data Availability Statement
Tennis Shot Side-View and Top-View Data Set for 3D Reconstruction and Player Analysis in Tennis (Original data) (Mendeley Data).

Articles from Data in Brief are provided here courtesy of Elsevier

ACTIONS
View on publisher site
PDF (1.4 MB)

Cite

Collections

Permalink
RESOURCES
Similar articles
Cited by other articles
Links to NCBI Databases
On this page
Abstract
1. Value of the Data
2. Background
3. Data Description
4. Clips Information
5. Dataset Information
6. Experimental Design, Materials and Methods
Limitations
Ethics Statement
CRediT authorship contribution statement
Acknowledgments
Data Availability
References
Associated Data

Follow NCBI
NCBI on X (formerly known as Twitter)
NCBI on Facebook
NCBI on LinkedIn
NCBI on GitHub
NCBI RSS feed
Connect with NLM

NLM on X (formerly known as Twitter)
NLM on Facebook
NLM on YouTube
National Library of Medicine
8600 Rockville Pike
Bethesda, MD 20894

Web Policies
FOIA
HHS Vulnerability Disclosure
Help
Accessibility
Careers
NLM
NIH
HHS
USA.gov
Back to TopTell us what you think!
```

```
Deep Learning for Domain-Specific Action Recognition in Tennis
Silvia Vinyes Mora
Department of Computing
Imperial College London
London, SW7 2AZ, UK
sv212@ic.ac.uk
William J. Knottenbelt
Department of Computing
Imperial College London
London, SW7 2AZ, UK
wjk@doc.ic.ac.uk
Abstract
Recent progress in sports analytics has been driven by
the availability of spatio-temporal and high level data.
Video-based action recognition in sports can significantly
contribute to these advances. Good progress has been made
in the field of action recognition but its application to sports
mainly focuses in detecting which sport is being played. In
order for action recognition to be useful in sports analytics
a finer-grained action classification is needed. For this reason we focus on the fine-grained action recognition in tennis and explore the capabilities of deep neural networks for
this task. In our model, videos are represented as sequences
of features, extracted using the well-known Inception neural network, trained on an independent dataset. Then a
3-layered LSTM network is trained for the classification.
Our main contribution is the proposed neural network architecture that achieves competitive results in the challenging THETIS dataset, comprising low-resolution monocular
videos of tennis actions. We also show that the network is
learning semantically meaningful information as most errors are interpretable and sensitive to player expertise.
1. Introduction
Sports analytics are on the rise, thanks to the volume
and richness of data that is now available in this domain.
For years, sports data was collected manually and consisted
mainly of match results and coarse statistics (e.g. percentage of first serves in, in tennis). In recent years, spatiotemporal data such as locations of the players and high-level
information has been made available, enabling the analysis
to go a step further. In our work we are interested in classifying fine-grained tennis actions automatically from videos
with the objective to bring an extra dimension to the analysis of the sport. We focus on tennis, but our work has the
potential to be extended to other sports.
Current research in vision-based action recognition applied to sports is limited, mirroring the lack of benchmark
datasets for this problem. Some of the most popular sports
action datasets include UCF-Sport [19, 23] or more recently
the Sports-1M dataset [13]. These datasets contain videos
from many different sports and their labels describe which
sport is being played. Different from these, we are interested in detecting finer-grained actions, such as specific tennis shots (serve, backhand and forehand) or even which
sub-type of stroke (e.g. flat serve). This task accentuates
the imbalance between a high intra-class variability and a
low inter-class variability, bringing an additional challenge
when compared to coarser action recognition. However, we
also think that in order for action labels to be useful in more
nuanced applications like professional training, these must
be of fine-grained actions.
Some research has been done in the area of tennis action recognition. In [30, 31] the authors present a video
descriptor based on optical flow and classify actions into
‘left-swing’ and ‘right-swing’ with a support vector machine. In [8] tennis actions are classified into ‘non-hit’, ‘hit’
and ‘serve’. Unfortunately, the videos used in these experiments are not publicly available ([8] uses the ACASVA Actions Dataset [6] which provides features and labels, but not
the RGB videos). Therefore, for our work we wanted to
evaluate our methods using a publicly available dataset so
that future research can be compared to our methods.
Amongst the many existing datasets for action recognition, we found one that conveniently suited our objective
of fine-grained action recognition in tennis: THETIS [10].
Presented in 2013, THETIS is a complete dataset of finegrained tennis actions comprising footage from 55 different
subjects performing 12 distinct tennis shots multiple times.
The videos are RGB, low-definition, monocular and shot
in-the-wild, with dynamic background and occlusions. Our
objective is to build a model able to classify the videos into
the 12 fine-grained actions from raw footage, without the
114
need of pre-processing (e.g. silhouette detection) and with
the ability to generalize to other tasks. For this reason, we
are interested in exploring deep learning techniques instead
of more traditional approaches based on hand-crafted features (both will be described later in more detail).
The proposed algorithm extracts features from each
frame individually by using the well-known convolutional
neural network (CNN) named Inception [25, 26], pretrained on an independent image dataset and without finetuning. The resulting sequences of features are then fed to a
deep neural network consisting of three stacked long short
term memory units (LSTMs), a particular type of recurrent
neural network (RNN).
The main contribution of this paper is the presentation
of this neural network and its successful application to the
challenging THETIS dataset. We also provide interesting
insights from the results: first, we show that the algorithm
is sensitive to the level of player expertise. Second, we compare the network’s performance for classifying different levels of fine-grained actions (stroke type such as ‘serve’ vs
sub-type such as ‘flat-serve’) and how it can be best trained
for each task. Finally, we also show that our approach can
be extended to action recognition in general by the application of our network to the HMDB dataset [16].
The rest of the paper is organized as follows. Section 2
revises previous work and state-of-the art techniques for action recognition. Section 3 depicts the characteristics of
the two datasets used in our experiments and describes our
methodology. Section 4 shows the experimental results and
evaluation. Finally, section 5 concludes the paper and offers
directions for future work.
2. Related work
2.1. Techniques for action recognition
Research in action recognition encompasses problems
from a broad range of scenarios and their characteristics affect dramatically the choice of technique that is best suited
to solve the problem. These are some of the variations that
may occur:
• Action type: coarse or fine-grained (e.g. ‘person playing tennis’ vs ‘person doing flat service in tennis’).
• Scene setting: actions recorded in an experimental setting or in-the-wild. The latter may contain changes in
illumination, occlusions or moving background.
• Video properties: monocular or multi-view, static or
moving camera, high or low definition .
Amongst the approaches to video-based action recognition,
two main categories can be be drawn: classifiers based on
hand-crafted features and deep neural networks.
2.1.1 Classifiers based on hand-crafted features
Classifiers based on hand-crafted features are the most classical approach. They generally involve two main steps:
feature extraction and classification. Extraction of handcrafted features is based on domain-knowledge and some of
the most popular techniques include Histogram of Oriented
Gradients (HOG) [4], Harris detector [17], Motion Boundary Histograms (MBH) [5] or Cuboid detector [7]. Classifiers built on top of these features have achieved impressive
results making their success undeniable but the major drawback in using them is that their selection can be problem
dependent and difficult to generalize.
2.1.2 Deep architectures for action recognition
Different from hand-crafted features which are engineered
and pre-defined, learned features are obtained through the
performance of a machine learning task. For example, a
neural network that learns to classify labeled images will
contain in its hidden layers a representation of the input data
that can be used as features to represent such data. These
learned features have the potential of detecting structures
that are more semantically meaningful and of being more
generalizable. In recent years, learned features have gained
popularity and they have been shown to be extremely powerful in the field of still image understanding. In particular,
CNNs have exceeded any other state-of-the-art method in
the domain of image classification [25, 15].
Driven by these achievements, attention has been
brought to the application of deep neural networks to video
classification. Unfortunately, their application to video processing has been proven to be more challenging and their
success cannot yet be compared to that in still images. This
can be attributed to two main limitations. First, video data
is more complex than still images because of the temporal dependencies, requiring models to learn more complicated structures. Second, the availability of large datasets
is reduced in comparison to still images. For instance,
video classification benchmark datasets – such as KTH [20],
Weizmann [3, 9], UCF Sports Action Dataset [19, 23],
UCF-50 [18], HMDB-51 [16] – contain a smaller number
of classes.
Progress has been made in overcoming these issues and
applying deep networks to action recognition. In [2] the
authors extend a traditional 2D CNN to 3D, incorporating
the time domain, to learn features and then use an LSTM
for classification. Their results improve upon other deep
learning approaches and are competitive with hand-crafted
based classifiers. Their experiments also show the benefits of using LSTMs in comparison to traditional RNNs. In
[13], an end-to-end CNN video classifier is presented and
evaluated in the Sports-1M dataset. They investigate different approaches of incorporating the time dimension, by fus115
ing the information across the time domain earlier or later
in the network. Interestingly, their best model performs in
hand with their single-frame model, opening the question
of whether these features are capturing any motion information for the classification task. In [22] a two-stream CNN is
presented, with a spatial stream that works on single frames
and a temporal stream that utilizes optical flow. Their results outperform these presented in [13] and are competitive with state-of-the-art hand-crafted models. All of these
models bring insights to the application of deep learning to
videos but also highlight the difficulty of transferring their
potential from still images to video sequences.
3. Methods
3.1. Experimental datasets
3.1.1 THETIS
Most of our experiments were conducted on the THETIS
dataset [10]. It contains 1980 monocular RGB videos
of 12 tennis actions performed three times by 55 different players (31 amateurs and 24 experienced). Actions are performed using a tennis racket but there is
no tennis ball in the videos. The 12 actions are:
• backhand (with two hands)
• backhand
• backhand (slice)
• backhand (volley)
• forehand (flat)
• forehand (open stance)
• forehand (slice)
• forehand (volley)
• service (flat)
• service (kick)
• service (slice)
• smash
We used the RGB videos from the dataset but other data
such as depth, skeleton 2D and 3D and silhouettes are also
provided. Some challenges of this dataset are that videos
contain moving background and the video sequences vary in
length. Figure 1 shows a sample of frames from the dataset.
To our knowledge, only two publications make use of
THETIS in action recognition experiments and there are no
published results on the RGB videos alone. [10] presents
the dataset and experiments accompanying it. They perform
action recognition using state-of-the-art algorithms applied
to 2D and 3D skeleton data. They achieve an average accuracy of 60.23% and 54.40% respectively, compared to
a 92.99% accuracy when applied to the well-known KTH
dataset [20], showing how challenging the THETIS dataset
is. In [27], experiments are performed using silhouette data
achieving an accuracy of 86%.
Figure 1. Samples from THETIS dataset.
Evaluation
As recommended by the authors, we performed a leaveone-out cross-validation procedure. For each experiment,
all the videos from a specific subject are selected as the test
set, videos from five others subjects (randomly selected) are
kept as validation set and the rest are used to train the network. This procedure is repeated three times for each experiment. For the evaluation, we show a normalized confusion matrix of the results averaged between all subjects
and across the three repetitions of the experiment and provide the accuracy and F1 scores, to assess the precision and
recall.
3.1.2 HMDB
To show the applicability of the proposed NN to general action recognition tasks, we also show experiments performed
on the HMDB dataset [16]. It contains 6849 videos from
51 actions that range from facial actions like smiling to
body movements like climbing, horse riding or hand shaking. Videos are extracted mostly from movies but also from
other datasets, and they can be considered in-the-wild.
Evaluation
In our experiments we use the three different splits of the
data (into training and testing sets) as provided by the authors. For each split, the training set contain 3 570 examples, which we randomly divide into training and validation
sets with 70% and 30% of the data respectively. Results
are displayed as for THETIS with a normalized confusion
matrix, accuracy and F1 scores.
3.2. Action classification
Our action classification algorithm is composed of two
main steps: first feature extraction using the Inception neural network and second classification through a deep LSTM
network.
116
Figure 2. Feature extraction pipeline diagram.
3.2.1 Feature extraction
Inception is the name of a well-known deep CNN architecture, from [25, 26]. It was first introduced in 2015, obtaining the best results in the ImageNet Large-Scale Visual
Recognition Challenge ’14 (ILSVRC) – an image classification challenge of 1000 categories containing about 1.2
million images for training. Inception is a network 22
layers deep consisting of traditional convolutional layers
stacked in the lower layers and ‘Inception modules’ stacked
at higher layers. Every Inception module concatenates the
output of the following operations preformed on its input
(which is the result from the previous layers): 1 × 1 convolution, 1 × 1 convolution followed by 3 × 3 convolution,
1 × 1 convolution followed by 5 × 5 convolution and 3 × 3
max pooling followed by a 1 × 1 convolution.
Motivated by its performance in the image classification
task, we chose Inception as our feature extraction algorithm.
In ILSVRC ’14, the network was able to attach coarsegrained labels to still images such as ‘person playing tennis’ but we wondered whether the features in the last layers
also carried information about a person’s posture or features
discriminative for the action recognition in videos. Interestingly, the Inception architecture was designed to optimize
computational resources so that inference could be done in
settings such as mobile vision. We find this to be critically
important for many action recognition applications.
In our work, Inception is used for feature extraction as
shown in Figure 2. Each video clip, whose duration ranges
from 90 to 150 frames, is cropped to the first 100 frames
(alternate frames for HMDB, where videos are longer). At
each frame, the previously mentioned network is applied to
make predictions and the resulting 2048 features from the
previous-to-last layer are stacked into a 2048 × 100 representation of the video. For videos shorter than 100 frames,
we employ zero-padding. These are presented to our classification network to learn to label them with the appropriate
tennis shot type.
Different from many applications in which the last layer
is retrained for the specific problem, we decided not to retrain the network using THETIS. First, we wanted to see
how applicable the features learned from ImageNet were
in a different context. Second, given the small size of the
THETIS dataset compared to the datasets used in deep architectures, we wanted to avoid as much as possible overfitting by fine-tuning the network to this particular dataset.
3.2.2 Deep LSTM for action classification
LSTM cell architecture
RNNs are a type of neural network with the ability to learn
time dependencies, making them very suitable to process
sequences. At time t, the output of the RNN ht is calculated
by taking as inputs its previous output ht−1 and the current
element of the sequence xt as follows:
ht = f(Wxh × xt + Whh × ht−1 + b) (1)
where Wxh and Whh are weight matrices, b the bias and f
is the output activation function.
Although RNNs are suitable for learning time dependencies, when applied to long sequences, the gradient is likely
to vanish. In 1997, a type of RNN called LSTMs were introduced to overcome this issue [12]. LSTMs are particularly
suited to learn long-term dependencies in sequences, such
as in video classification or speech processing. They are
composed of memory cells, which contain a memory state
c that is updated with the new inputs but controlled by gates
determining which information to keep and what to forget.
The cell state ct is updated by forgetting some information through the multiplication of the previous cell state
ct−1 and the forget gate ft and by adding new information,
controlled by the input gate it. Finally, the output gate ot,
controls the output of the cell ht. The LSTM implementation that we used is based on [11, 29] (Figure 3) and the
calculations of the activations are as follows:
Input gate
it = σ(Wxixt + Whiht−1 + Wcict−1 + bi) (2)
Forget gate
ft = σ(Wxfxt + Whfht−1 + Wcf ct−1 + bf ) (3)
Memory cell state
ct = ftct−1 + it tanh(Wxcxt + Whcht−1 + bc) (4)
Output gate
ot = σ(Wxoxt + Whoht−1 + Wcoct + bo) (5)
Hidden state
ht = ot tanh(ct) (6)
117
Figure 3. LSTM cell architecture. The memory of the LSTM cell
is stored in c. Through time and as new inputs are fed in, the memory state is updated controlled by the forget and input gates. Both
have as input: (1) the previous memory state ct−1, (2) the previous output ht−1 and (3) the current input xt; their activation is
calculated as described in Equations (2) and (3). The cell state is
modified by multiplying the old memory ct−1 by the forget gate,
which will determine how much of the old memory to keep. Then,
new memories (input activation) are added, controlled by the input gate. The output, which is then fed back to the network, is
calculated as in Equation (5). Diagram inspired by [11].
Deep LSTM implementation details
Video-based action recognition requires the modeling of
long-term time dependencies on highly complex data (images). We have seen that LSTMs are very suitable to learn
these long-term dependencies. By stacking LSTMs on top
of each other, it becomes possible to learn high level structures in high dimensional data such as images. Each layer
uses as input the output of the previous layer, creating a hierarchical representation of the input data, where higher layers have more abstract and complex representations of the
data. In [11], the authors showed that deep LSTMs greatly
improved performance in speech recognition compared to
one-layer LSTMs. For these reasons we decided to use a
deep LSTM network.
The detailed architecture of our network is shown in Figure 4. It has 3 stacked LSTM layers, empirically found to
give best results. Each of these LSTMs layers have 90 hidden units and a softmax function is applied to the last layer
to obtain the predicted classification output. In learning, the
cost is calculated as the cross entropy and with L2 regularization to reduce overfitting, the L2 is scaled by a λ value
of 0.003. Adam optimizer is used to perform gradient descent [14] and optimize the network. We employ exponential decay of the learning rate, with a starting learning rate of
0.001 (0.005 for HMDB) and decaying with a base of 0.96
Figure 4. Architecture of our classification neural network. At the
bottom is the input to the network, a sequence of 2048 features per
frame for 100 frames. This is the unrolled version of the recurrent
network with time going from left to right, and input processed
in this direction. The input is also processed through 3 LSTMs
layers, upwards. At the end, input is processed through a softmax
layer to obtain the predicted label.
every 100 000 steps. During training, the accuracy of prediction for the validation set is calculated every 10 steps to
select the best model and the parameters for the best results
stored. Parameters were found to be empirically effective
and we used Tensorflow for our implementation [1].
4. Results and evaluation
4.1. Action classification
The first experiment consists in classifying the videos
into the correct class, amongst the 12 actions from the
THETIS dataset. Figure 5 shows the confusion matrix of
this experiment. The average accuracy in prediction is of
47.22%, with an F1 score of 47.05%. Figure 5 shows that
for each of the 12 actions, most videos are labeled with
the correct shot type and some actions, such as backhand
with two hand and backhand have an accuracy of over 60%.
By looking at the results in more detail, one can realize
that most errors are interpretable. For instance, the network makes mistakes in discriminating between the different types of serve or smash. Videos in the THETIS dataset
do not contain the tennis ball, and this could explain why
smash and serve are often confused. Another source of confusion are slices and volleys, both in backhand and fore118
Figure 5. Confusion matrix of our model applied to the THETIS
dataset.
hand; these two actions are also quite similar for a human
observer. Again, one main difference between volley and
slice is that in the former the ball is hit before bouncing.
In [10], the authors perform similar experiments but use
depth videos and 3D skeletons rather than raw image and
obtain 60% and 54.4% accuracy, respectively. It is reasonable to assume that classifying raw footage brings additional challenges and we consider that our results are competitive.
4.2. Expertise detection
As described in Section 3.1.1, THETIS dataset contains
shots performed by 31 amateur and 24 experienced players.
To assess whether our network’s classification accuracy was
affected by the expertise of a player, we performed two different experiments. First, we calculated the prediction accuracy for each group of players separately, when trained
on the entire dataset (with the same leave-one out cross
validation procedure). Interestingly, our model’s accuracy
is higher for professional players (54.09%) than amateurs
(41.90%). A more detailed representation of the results is
shown in Figures 6 and 7, for amateur and professional
players respectively. One possible explanation is that professionals have a neater technique making their shots more
distinct and the biggest difference, as can be seen in the figures, is within the different types of serve.
To further investigate how the network was affected by
the players’ expertise, we compared the network’s performance when trained using only amateur players, only professionals and a mixed set of players. In order for the results
to be comparable, the number of examples used for training
Figure 6. Confusion matrix of our model applied to the THETIS
dataset, results on amateur players.
Figure 7. Confusion matrix of our model applied to the THETIS
dataset, results on professional players.
should be similar. For this reason, we couldn’t use previous
results for the mixed set of players since they are calculated
using double the amount of data compared to the data that
can be used when training on only amateurs or experts. To
solve the issue, we re-run the experiments selecting the test
and validation sets as before but randomly selecting only
25 examples for training. Taking into account that we used
videos from 5 players for validation and 1 for testing in all
experiments, the final training sets contain videos from 25
119
Players Players Accuracy
in training set in test set
mixed mixed 39.65% (47.22%)
mixed amateur 37.02% (41.90%)
mixed professional 43.06% (54.09%)
amateur amateur 37.70%
professional professional 45.00%
Table 1. Accuracy of classification when training with amateurs,
professionals or a mixed population.
players for the amateurs and mixed groups and 18 for professionals.
Results are summarized in Table 1. As expected, the
first observation is that when training with a mixed group of
players but using only 25 players for training, the classification accuracy for all groups of players is lower than when
using the entire dataset (training with 49 players). When
training with a reduced number of examples the accuracy is
39.65%, 37.02% and 43.06% for mixed players, amateurs
and professionals respectively versus 47.22% , 41.90% and
54.09%. This results are consistent with previous experiments since classification of videos of professional players
achieves the highest accuracy. Interestingly, this is further
increased when only professionals are used for training –
accuracy increases from 43.06% to 45.00%. Classification
of videos from amateur players also benefits from training
with only amateur players, increasing the classification accuracy from 37.02% to 37.70%. These results suggest that
the network could be learning different features depending
on the level of expertise of the players. It may be that features that help to best discriminate between different actions
in amateur players are different than those to identify different shots played by professionals. Another interesting observation from these experiments is that the quality of the
training data is important, but in our particular example, size
of the training set is even more important as best results are
achieved when using the entire dataset.
4.3. From fine-grained actions to stroke types
Observing the results from Figure 5, we noticed that our
learning algorithm was not only able to identify the 12 finegrained actions from the THETIS dataset but, when doing
mistakes, these were generally between actions that can be
grouped into the same type of tennis stroke. For instance,
even though a slice service is confused with a flat or kick
service, the network is still recognizing that it is a serve.
For this reason, we looked at the accuracy of the prediction
when grouping classes into more general stroke types, as
shown in Table 2. We still consider these actions to be finegrained as they are within the domain of tennis actions and
fine-grained when compared to general action recognition
(e.g. detecting which sport is being played).
For this, we used the results from the first experiments of
action classification and grouped the labels into the 4 main
actions in Table 2: backhand, forehand, service and smash.
The result from this is shown in Figure 8. In this setting
the action detection accuracy reaches 76.92% with and F1
score of 76.90%. As can be seen from the Figure 5, the
mean accuracy is brought down by the smash detection. In
fact, most errors come from a confusion between smash and
serve. These are quite similar in terms of body movement
and the main differences are the state of the game (serve is
played at the beginning of a point), player position in the
court and ball trajectory before hitting the ball. THETIS
videos do not contain the tennis ball, which could help in
discriminating between the two actions. Also, in real-world
applications we might expect to know the players position
or state of the game, helping to further discriminate between
the two actions.
Having obtained these results, we wondered how predictions would compare if we trained on the main strokes directly. For this, we grouped smash and serves into the same
category as they are very similar in terms of body movement and it helps balancing the classes. Table 3 shows
the results by category, and we can see that training for
the specific task, which is detecting one of the three main
strokes in this case, produces better detection results than
training for finer-grained actions and then regrouping the
actions into their more general categories. The classification accuracy improves from 84.10% to 88.16% for players
of mixed abilities, from 81.23% to 84.33% for amateurs and
from 87.82% to 89.42% for professionals, when trained using the entire dataset.
Two main observations can be derived from that. First,
the network performs best when trained for the specific task
in which it is evaluated and second the features relevant to
discriminate between stroke type and between finer-grained
actions might be different.
4.4. Applicability to general action recognition tasks
To investigate the ability of generalization of our network, we evaluated it on the HMDB dataset. We achieved
an accuracy of 43.19% and F1 score of 42.48%. In Table 4,
our performance in HMDB is compared to existing models
that, as ourselves, use exclusively RGB data. For instance,
we do not include: the two-stream ConvNet of [22] (59.4%)
which uses optical flow information, models in [28] that use
Fisher Vectors (53.3%) and a combination of HOG, HOF
and MBH (60.1%). The results presented here show that
our network has the potential to be applied to other tasks,
further supporting that it could be applicable to other sports.
120
Figure 8. Confusion matrix of our model on the THETIS dataset,
grouped classes.
Action group Actions
Backhand
backhand (with two hands)
backhand
backhand (slice)
backhand (volley)
Forehand
forehand (flat)
forehand (open stance)
forehand (slice)
forehand (volley)
Service
service (flat)
service (kick)
service (slice)
Smash smash
Table 2. Fine-grained actions grouped into stroke types.
5. Conclusions and future work
In this work we have presented a 3-layered LSTM network able to classify fine-grained tennis actions and which
uncovered a number of interesting points.
First, our network achieved good results by using features extracted through the application of the Inception neural network, trained on an independent dataset and without
the need of fine-tuning. This suggests that it is a robust
data representation with the potential to be transferable to
multiple tasks and domains. Second, the networks’ classification errors were interpretable, suggesting it was learning semantically meaningful information. Endorsing this
idea, the network performed better when trained with only
amateur or only professional players rather than a mixed
Players Trained Accuracy
tested actions
all all 84.10%
all 3 88.16%
amateur all 81.23%
amateur 3 84.33%
professional all 87.82%
professional 3 89.42%
Table 3. Accuracy of detection when training with fine-grained
actions and then re-grouping vs training directly with the three
main strokes classes.
Model HMDB-51 accuracy
Spatial stream ConvNet [22] 40.5%
Soft attention model [21] 41.3%
Our model 43.2%
Composite LSTM [24] 44.1%
Table 4. HMDB-51 classification accuracy by state-of-the-art
models from RGB data exclusively.
population. It is possible that it learned different features
when looking at amateurs and professional players and it
would be interesting to investigate this further. Third, the
network performed better for professional players than amateurs, when trained on a mixed population. A possible cause
is that professionals have a better techniques that makes
their strokes more distinct. In the future, we would like to
consider whether this can be exploited to assess a player’s
expertise. Fourth, the same network architecture was able
to detect the three main strokes with an 88.16% accuracy,
and it performed better than when an indirect inference was
made from finer-grained actions. This further supports the
robustness and transferability of the Inception features. Finally, we also showed how the proposed approach can be
applied to general action recognition tasks, by evaluating it
with the HMDB dataset.
With this work we wish to motivate the exploration of
deep neural networks in the sports domain and the use and
production of benchmark datasets in sports action recognition. In the future, it would be interesting to investigate
how to incorporate spatio-temporal data to our network to
improve action detection and how to combine action recognition with statistical data in order to push forward the field
of tennis analytics.
121
References
[1] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen,
C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia,
R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane,´
R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster,
J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker,
V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. War- ´
den, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.
[2] M. Baccouche, F. Mamalet, C. Wolf, C. Garcia, and
A. Baskurt. Sequential deep learning for human action
recognition. In International Workshop on Human Behavior Understanding, pages 29–39. Springer, 2011.
[3] M. Blank, L. Gorelick, E. Shechtman, M. Irani, and R. Basri.
Actions as space-time shapes. In ICCV, volume 2, pages
1395–1402. IEEE, 2005.
[4] N. Dalal and B. Triggs. Histograms of oriented gradients for
human detection. In Proceedings of the IEEE Computer Vision and Pattern Recognition (CPVR), volume 1, pages 886–
893. IEEE, 2005.
[5] N. Dalal, B. Triggs, and C. Schmid. Human detection using
oriented histograms of flow and appearance. In European
conference on computer vision, pages 428–441. Springer,
2006.
[6] T. De Campos, M. Barnard, K. Mikolajczyk, J. Kittler,
F. Yan, W. Christmas, and D. Windridge. An evaluation of
bags-of-words and spatio-temporal shapes for action recognition. In IEEE Workshop on Applications of Computer Vision (WACV), pages 344–351. IEEE, 2011.
[7] P. Dollar, V. Rabaud, G. Cottrell, and S. Belongie. Behav- ´
ior recognition via sparse spatio-temporal features. In 2nd
Joint IEEE International Workshop on Visual Surveillance
and Performance Evaluation of Tracking and Surveillance,
pages 65–72. IEEE, 2005.
[8] N. FarajiDavar, T. De Campos, J. Kittler, and F. Yan. Transductive transfer learning for action recognition in tennis
games. In ICCV, pages 1548–1553. IEEE, 2011.
[9] L. Gorelick, M. Blank, E. Shechtman, M. Irani, and R. Basri.
Actions as space-time shapes. IEEE transactions on pattern
analysis and machine intelligence, 29(12):2247–2253, 2007.
[10] S. Gourgari, G. Goudelis, K. Karpouzis, and S. Kollias.
THETIS: Three dimensional tennis shots a human action
dataset. In CVPR Workshops, pages 676–681. IEEE, 2013.
[11] A. Graves, A.-R. Mohamed, and G. Hinton. Speech recognition with deep recurrent neural networks. In Proceedings of
the IEEE Conference on Acoustics, Speech and Signal Processing, pages 6645–6649. IEEE, 2013.
[12] S. Hochreiter and J. Schmidhuber. Long short-term memory.
Neural computation, 9(8):1735–1780, 1997.
[13] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar,
and L. Fei-Fei. Large-scale video classification with convolutional neural networks. In CVPR, pages 1725–1732. IEEE,
2014.
[14] D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
[15] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet
classification with deep convolutional neural networks. In
NIPS, pages 1097–1105, 2012.
[16] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre.
HMDB: a large video database for human motion recognition. In ICCV, pages 2556–2563. IEEE, 2011.
[17] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld.
Learning realistic human actions from movies. In CVPR,
pages 1–8. IEEE, 2008.
[18] K. K. Reddy and M. Shah. Recognizing 50 human action
categories of web videos. Machine Vision and Applications,
24(5):971–981, 2013.
[19] M. D. Rodriguez, J. Ahmed, and M. Shah. Action mach
a spatio-temporal maximum average correlation height filter
for action recognition. In CVPR, pages 1–8. IEEE, 2008.
[20] C. Schuldt, I. Laptev, and B. Caputo. Recognizing human
actions: A local SVM approach. In ICPR, volume 3, pages
32–36. IEEE, 2004.
[21] S. Sharma, R. Kiros, and R. Salakhutdinov. Action recognition using visual attention. arXiv preprint arXiv:1511.04119,
2015.
[22] K. Simonyan and A. Zisserman. Two-stream convolutional
networks for action recognition in videos. In NIPS, pages
568–576, 2014.
[23] K. Soomro and A. R. Zamir. Action recognition in realistic
sports videos. In Computer Vision in Sports, pages 181–208.
Springer, 2014.
[24] N. Srivastava, E. Mansimov, and R. Salakhutdinov. Unsupervised learning of video representations using LSTMs. In
ICML, pages 843–852, 2015.
[25] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In CVPR, pages 1–9. IEEE,
2015.
[26] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna.
Rethinking the inception architecture for computer vision. In
CVPR, pages 2818–2826. IEEE, 2016.
[27] J. Vainstein, J. F. Manera, P. Negri, C. Delrieux, and A. Maguitman. Modeling video activity with dynamic phrases and
its application to action recognition in tennis videos. In
Iberoamerican Congress on Pattern Recognition, pages 909–
916. Springer, 2014.
[28] H. Wang, D. Oneata, J. Verbeek, and C. Schmid. A robust and efficient video representation for action recognition.
IJCV, 119(3):219–238, 2016.
[29] W. Zaremba, I. Sutskever, and O. Vinyals. Recurrent neural network regularization. arXiv preprint arXiv:1409.2329,
2014.
[30] G. Zhu, C. Xu, W. Gao, and Q. Huang. Action recognition
in broadcast tennis video using optical flow and support vector machine. In European Conference on Computer Vision,
pages 89–98. Springer, 2006.
[31] G. Zhu, C. Xu, Q. Huang, W. Gao, and L. Xing. Player action
recognition in broadcast tennis video with applications to semantic analysis of sports game. In Proceedings of the 14th
ACM international conference on Multimedia, pages 431–
440. ACM, 2006.
122
```

```
Skip to main content

An official website of the United States government

Here's how you know

                                  NCBI home page
                              
Search

Log in
Primary site navigation
Search PMC Full-Text Archive
Search PMC Full-Text Archive

Search in PMC
Advanced Search 
Journal List 
User Guide
As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.
Learn more: PMC Disclaimer | PMC Copyright Notice
Diagnostics logo
Diagnostics (Basel). 2024 Aug 1;14(15):1668. doi: 10.3390/diagnostics14151668
Exploring Publicly Accessible Optical Coherence Tomography Datasets: A Comprehensive Overview
Anastasiia Rozhyna 1,2,*,†, Gábor Márk Somfai 3,4,†, Manfredo Atzori 1,5, Delia Cabrera DeBuc 6, Amr Saad 3,4, Jay Zoellin 3,4, Henning Müller 1,2,7
Editor: Antonio Yaghy
Author information
Article notes
Copyright and License information
PMCID: PMC11312046  PMID: 39125544
Abstract
Artificial intelligence has transformed medical diagnostic capabilities, particularly through medical image analysis. AI algorithms perform well in detecting abnormalities with a strong performance, enabling computer-aided diagnosis by analyzing the extensive amounts of patient data. The data serve as a foundation upon which algorithms learn and make predictions. Thus, the importance of data cannot be underestimated, and clinically corresponding datasets are required. Many researchers face a lack of medical data due to limited access, privacy concerns, or the absence of available annotations. One of the most widely used diagnostic tools in ophthalmology is Optical Coherence Tomography (OCT). Addressing the data availability issue is crucial for enhancing AI applications in the field of OCT diagnostics. This review aims to provide a comprehensive analysis of all publicly accessible retinal OCT datasets. Our main objective is to compile a list of OCT datasets and their properties, which can serve as an accessible reference, facilitating data curation for medical image analysis tasks. For this review, we searched through the Zenodo repository, Mendeley Data repository, MEDLINE database, and Google Dataset search engine. We systematically evaluated all the identified datasets and found 23 open-access datasets containing OCT images, which significantly vary in terms of size, scope, and ground-truth labels. Our findings indicate the need for improvement in data-sharing practices and standardized documentation. Enhancing the availability and quality of OCT datasets will support the development of AI algorithms and ultimately improve diagnostic capabilities in ophthalmology. By providing a comprehensive list of accessible OCT datasets, this review aims to facilitate better utilization and development of AI in medical image analysis.

Keywords: OCT, optical coherence tomography, datasets, data, open data, data sharing, data analysis

1. Introduction
Artificial intelligence (AI) has become one of the most innovative fields that have revolutionized healthcare [1]. Recent progress in deep learning (DL) enables the identification, classification, and quantification of patterns within medical images. DL algorithms can detect biomarkers and abnormalities in medical images, aiding in early disease detection and computer-aided diagnosis [2]. These algorithms heavily rely on diverse amounts of labeled data for training robust models. The performance of DL models is directly influenced by the quality, quantity, and diversity of the data used for training [3]. Access to biomedical datasets is crucial for ensuring the generalizability and effectiveness of DL models. Annotated, labeled datasets facilitate the training process by providing ground truth labels of specific medical conditions. Thus, the availability and quality of data are vital to reduce the problem of overfitting and to improve the generalization performance of DL models [4]. Privacy, ethical concerns, and restricted access are significant limitations of data sharing in the medical imaging field [5]. The absence of standardized protocols for data sharing and the use of different formats and standards make it challenging to integrate and share data across healthcare and research institutions.

In ophthalmology, there are various imaging modalities for the detection, diagnosis, and management of eye conditions. These modalities include Color Fundus Photography (CFP), Fundus fluorescein angiography (FFA), Indocyanine green angiography (ICGA), Optical coherence tomography (OCT), Optical coherence tomography angiography (OCTA), and Confocal scanning laser ophthalmoscopy (CSLO) [6]. Optical coherence tomography (OCT) is widely employed for early diagnosis and guiding therapeutic decisions in various retinal diseases and shows promise in detecting subtle retinal vascular changes [7]. OCT is an important imaging modality that allows for the high-resolution, non-invasive observation of retinal structures with an almost cellular resolution. OCT works by emitting light waves into the eye and measuring the delay and intensity of the reflected light. When light reflects off different layers of the retina, it creates an interference pattern that can be detected and analyzed. OCT stands out as the most widely used diagnostic tool for retinal disorders because it is a non-invasive, distinctive, and high-resolution assessment of tissues. Its ability to directly correspond to the histological features of the retina allows for achieving an axial resolution of 2–3 µm within tissues [8].

The vast amount of ocular imaging data produced in clinical and research environments presents a significant challenge for clinicians and researchers in effectively sharing images, even with patients. Despite advancements in imaging technology, this struggle persists. Given the reliance on big data in modern research, widespread adoption of standardized practices would substantially improve digital workflow efficiency. Various studies have highlighted the need for uniform, cohesive, standardized reporting guidelines [9].

The Advised Protocol for OCT Study Terminology and Elements (APOSTEL) recommendations were introduced in 2016 and updated in 2021 [10]. These guidelines offer a concise 9-point checklist outlining essential elements to include when reporting quantitative retinal OCT studies. Other studies have introduced recommendations for OCT/OCTA nomenclature and reporting in retinal vascular diseases [11,12]. Standardization and interoperability are key for advancing research and introducing breakthroughs in the field [13,14].

The National Eye Institute’s (NEI) recent notice (NOT-EY-24-006) emphasizes the importance of using common file formats and metadata standards for ocular imaging in clinical and nonclinical research [15,16]. This initiative aims to facilitate data standardization, interoperability, and the sharing of raw data and metadata, thereby addressing some of the key challenges identified in our study. The NEI strongly encourages the adoption of standards like the Digital Imaging and Communications in Medicine (DICOM) format, which will greatly enhance the digital workflow, allow for the sharing of large datasets, and create substantial training sets for AI-based research. These standardized practices are essential for advancing the field and ensuring that research findings are reproducible and reliable. By adhering to these standardized data-sharing practices, the research community can significantly improve the utility and impact of OCT datasets. This will not only enhance the development of AI tools but also contribute to more effective and efficient patient care in ophthalmology. Therefore, future research and data-sharing efforts must align with the guidelines and recommendations set forth by the NEI, promoting a more collaborative and standardized approach to ocular imaging research.

Regarding medical image open-access datasets, Johann Li et al. provided a collection of medical image datasets and the DL challenges associated with these data. In particular, the article discusses the significance of ophthalmic datasets, emphasizing the critical role of eye health in preventing blindness. It provides an overview of various datasets with a focus on modalities such as CFP and OCT, as well as surgical videos. The datasets are categorized based on analysis tasks. In the paper, it is noted that only five datasets were specifically focused on OCT. Three of the mentioned datasets were linked to specific DL challenges and were featured as part of conferences, while the remaining two were publicly accessible. However, the datasets associated with challenges require additional data agreements and restrict their use [17].

Khan et al. found 94 open-access ophthalmological imaging datasets. Among those datasets, OCT datasets comprised 15 datasets out of 94. Out of the 15 OCT datasets mentioned, only 11 were accessible, while the remaining 4 were not available, despite the corresponding links provided in the review paper. These four links were either inaccessible or resulted in errors during use (during review in May 2024) [18]. Despite the availability of numerous datasets, challenges persist in accessing and utilizing them effectively, as evidenced by the limited accessibility of OCT datasets. Moving forward, addressing these challenges and promoting open access to diverse datasets will be essential for advancing research and improving patient outcomes.

For the above reasons, in our work, we aim to address the growing need for well-annotated OCT datasets for diagnosing eye diseases. Our goal is to create an updated list of existing OCT image datasets for researchers to gain easier access to data for training algorithms, addressing the accessibility issues highlighted in previous works by providing direct links and verification of dataset availability. Also, we aimed to identify gaps in available datasets to address these issues and provide updated resources for researchers. Assessing the completeness and quality of metadata associated with each dataset is crucial for the effective utilization and integration of these datasets in AI research.

2. Materials and Methods
In this section, the methodology employed during the review is discussed in detail. The processes and techniques utilized to gather, analyze, and interpret the data are outlined, providing transparency and insight into the research approach.

2.1. Search Strategy and Selection Criteria
The search strategy and selection criteria for the dataset review were designed to ensure comprehensive coverage of ophthalmological imaging datasets while maintaining methodological precision. The search consisted of several parts. The review methodology aimed to examine two primary data sources: publicly accessible datasets and research papers containing references to accessible datasets within their findings. We initially employed established tools to explore repositories containing OCT images.

Figure 1 demonstrates the dataset search with detailing search engines. This involved targeted searches on platforms such as the Google Dataset search engine and the standard Google search engine, using varied keywords centered on terms like “retina” and “OCT”, along with keywords like “dataset”, “database”, and “repositories”. Additionally, we utilized the Mendeley Data repository, a platform enabling researchers to organize, share, and manage their data systematically. Another approach involved searching the Zenodo repository using the same keywords. Zenodo is an open repository established as part of the European OpenAIRE program and operated by CERN. Finally, we conducted searches on PubMed, a search engine primarily accessing the MEDLINE database, a comprehensive biomedical database maintained by the National Library of Medicine (NLM) in the United States. PubMed often contains links to datasets utilized in published studies.

Figure 1.
Figure 1

Open in a new tab
The dataset search with detailed search engines.

The review process entailed screening titles and abstracts for articles detailing OCT image datasets and studies employing OCT for retinal diagnosis, particularly those utilizing datasets to train machine learning algorithms. We also referred to the insights provided in the evaluation of publicly accessible ophthalmological imaging datasets [18] to validate the mentioned datasets and their current status and availability.

For the datasets to be eligible for data extraction, they needed to contain retinal OCT scan images. If datasets had no retinal OCT, they were excluded. Datasets with text or numeric-only data were excluded. Datasets currently inaccessible but previously described as open-access were excluded. The search was conducted from March to May 2024.

2.2. Dataset Access
The accessibility of the data varied based on the levels of access to the datasets, ranging from complete accessibility to being available upon request after contacting the authors.

We defined the access levels as follows:

Open access. No requirements for access. No preconditions for accessing or using data in a certain way, allowing users to retrieve the data freely;

Open access with restrictions. Requirements for access: completing the form, account registration, sending an email to authors and getting approval from them, and obtaining the assessment or special code for decryption of the images. The restriction on application use for instance datasets associated with conference challenges;

Restricted access. Additional legal agreements, meeting special requirements, payments for access, etc.;

Not accessible. The datasets categorized as not accessible are those for which the data were inaccessible or unavailable for use due to privacy or ethical concerns. This category includes the datasets that were initially described as accessible but has since become inaccessible due to various reasons, such as inactive links or lack of response from authors, thereby blocking access to the data.

Throughout the search process, our primary focus was on investigating the accessibility and usability of these datasets, with particular emphasis on those that are openly accessible or available with restrictions. We investigated the completeness of metadata and any additional information associated with those datasets. After gaining access, we examined each dataset by downloading them to extract details regarding file status, sizes, and any additional artifacts present in the images. The majority of the accessible datasets were provided as compressed files.

3. Results
In this study, a total of 23 publicly accessible OCT imaging datasets were identified. Out of the 23 datasets analyzed, 6 were discovered on Mendeley Data repository, 8 were sourced through Google Search engines, 7 were obtained from PubMed, and 2 were found on Zenodo repository. Each dataset was analyzed based on several key factors, including the country of origin, the number of images, annotations, image resolution, and image format. Figure 2 demonstrates random sample selection from the found datasets.

Figure 2.
Figure 2

Open in a new tab
Exemplary sample images from datasets. (A)—Kermany et al.; (B)—Data of rare retinal disease; (C)—OCTID; (D)—Labeled Retinal Optical Coherence Tomography Dataset for Classification; (E)—OCT MS and HC data; (F)—Duke OCT.

3.1. Quality of Images
A visual assessment of the image quality across datasets is crucial to understanding diagnostic and research findings. There are factors that contribute to the quality of OCT images, including image resolution, signal strength, noise level, artifacts, and overall image clarity. The higher-resolution images give better visualization of anatomical structures and abnormalities. OCT images are often influenced by several artifacts, and speckle noise is one of the most common artifacts in OCT imaging. Speckle noise appears as grainy or granular patterns on the image and can obscure important details, affecting the interpretation and analysis of the image [19]. Thus, many papers evaluate the quality of the images, and this evaluation is performed by human grading.

From Figure 2, it can be observed that some datasets have tilted images. This can be a result of incorrect, improper alignment in the imaging system. This misalignment can occur due to various reasons, such as improper positioning of the patient’s head during image acquisition or inaccuracies in the OCT device itself [20].

Table 1 summarizes publicly accessible OCT imaging datasets, including information on their origin country, accessibility status, image number, representation of diseases, file format, and resolution.

Table 1.
Publicly available OCT imaging datasets.

Dataset Name	Country	Access	Number of B-Scans	Eye Disease Details	File Details
Kermany et al. [21]	USA, China	Open access	109,312	DE, CNV, Drusen, Healthy	JPEG, 512 × 496
The retinal OCT images of rare diseases [22]	NA	Open access	119	CSR, MacTel, MH, Stargadt’s disease, RP	PNG, min. 290 × 277–max. 523 × 525
OCTID [23]	Canada, India	Open access with restrictions	572	Healthy, MH, AMD, CSR, DR	JPEG, 512 × 1024
Corneal-OCT Dataset [24]	Iran	Open access with restrictions	41	NA	MAT, 240 × 748
A Composite Retinal Fundus and OCT Dataset [25]	NA	Open access	768	DME, Acute CSR, Chronic CSR, Glaucoma, AMD	JPEG, 760 × 576
AROI database [26]	Croatia	Open access with restrictions	3200	Neovascular AMD	PNG, 1024 × 512
Labeled Retinal OCT Dataset for Classification [27]	Iran	Open access	16,822	CNV, Drusen, Healthy	JPEG, TIFF, 768 × 496
Duke OCT [28]	USA	Open access	35,400	AMD	MAT, 1001 × 1001
Data on OCT and Fundus Images [29]	NA	Open access	50	Healthy, Glaucoma	JPEG, 951 × 456
Retina OCT Glaucoma dataset [30]	NA	Open access	884	Healthy, Glaucoma	NumPy, 64 × 128
OLIVES Dataset [31]	Georgia	Open access	49	DR, AMD	PNG, TIFF, 504 × 496
Duke 2015 [32]	USA	Open access	110	DME	MAT, 512 × 740
2014 Srinivasan [33]	USA	Open access	3231	DE, AMD, Healthy	TIFF, 512 × 496
2012 Fang [34]	USA	Open access	51	AMD, Healthy	TIFF, 280 × 1000
OCT MS and HC data [35]	USA	Open access	1715	MS, Healthy	VOL, 496 × 1024
OIMHS [36]	China	Open access	3859	MH	JPEG, 1024 × 512
Retouch dataset [37]	NA	Open access with restrictions	11,334	IRF, SRF, PED	Raw Binary file, 512 × 1024, 512 × 496, 512 × 885 or 512 × 650
University of Auckland Dataset [38]	Nepal	Open access with restrictions	70,200	NA	VOL, 320 × 992, 1008 × 596
Retinal image dataset [39]	USA	Open access with restrictions	NA	AMD	VOL, 496 × 768 × 121
THOCT1800 [40]	China	Open access	1800	AMD, DME, Healthy	JPEG, 756 × 121
OCHID: An OCT Choroid Segmentation Dataset [41]	NA	Open access with restrictions	1920	Healthy	VOL, 992 × 512
CLOUD Dataset [42]	Spain	Open access with restrictions	112	NA	NA
OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods [43]	Russia	Open access	2064	AMD, DME, RVO, RAO, VID, ERM	JPEG, 1100 × 410
Open in a new tab
Table A1 from the Appendix A has additional information for dataset access (e.g., links for access).

3.2. Metadata
The completeness and availability of the metadata related to the found datasets is crucial in their usability. Metadata provides essential information about other data, making them easier to find, use, and manage. Metadata standards ensure that datasets can be integrated and compared across different studies and institutions. This is particularly important in ophthalmology, where combining data from multiple sources can enhance the robustness of research findings and support large-scale studies [44].

3.2.1. Disease Representation
Figure 3 demonstrates the disease representation across the available datasets. Conditions like diabetic eye disease (DE) and AMD are over-represented in the datasets but with fewer occurrences than healthy eyes. This suggests a limited number of diseases that are present in the publicly available datasets. The datasets provide a representation of glaucoma as well. The distribution of diseases represented in the dataset is influenced by several factors, including the prevalence of these conditions in the general population, as well as the focus of clinical studies. AMD and diabetic retinopathy (DR) are among the most prevalent causes of vision loss in older adults, which likely accounts for their significant representation in the datasets. Wong et al. report that AMD affects millions globally [45].

Figure 3.
Figure 3

Open in a new tab
Disease representation across datasets.

The high representation of conditions such as AMD and DR can also be attributed to the focus of many ophthalmological studies on these prevalent diseases. Researchers often prioritize these conditions due to their substantial public health burden and the potential for significant clinical improvements with better management and treatment options [46]. Biases in diagnosis and reporting can also play a role. Conditions that are more easily diagnosed or have well-established diagnostic criteria, such as AMD, DR, and DME, might be reported more frequently in contrast to rarer conditions or those with less clear diagnostic criteria.

3.2.2. Origin of Datasets
Geographical bias in datasets is a significant issue that can impact the generalizability and applicability of research findings. The over-representation of certain regions can limit the generalizability of research findings, as the results may not apply to populations in the underrepresented areas [47].

Figure 4 displays the distribution of OCT datasets by country of origin. During our study, no datasets were excluded based on country of origin. From the analysis, it is evident that the United States has contributed the highest number of datasets, followed by China. Several datasets have origins that include multiple countries with collaborative research. Additionally, there are datasets with unspecified origins labeled as “NA”. In metadata, it is either a lack of available information or not mentioning the country of acquisition.

Figure 4.
Figure 4

Open in a new tab
Origin of datasets.

Adopting open data policies can improve access to datasets from diverse geographical regions. Open data initiatives can facilitate the sharing and integration of data.

In our study, we noticed notable geographical bias in the absence of datasets from large parts of the world, including Africa, South America, and Oceania, indicating a significant geographical bias. Differences in healthcare access and the presence of screening programs can influence dataset composition.

3.2.3. Acquisition Protocols
Table 2 summarizes the additional metadata such as the number of patients and the used imaging device. The Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering) is the most commonly used acquisition scanner, appearing in 10 out of 20 datasets. This is approximately 50% of the datasets. Cirrus HD-OCT machine (Carl Zeiss Meditec) appears in 3 out of 20 datasets, constituting approximately 15% of the datasets. SD-OCT imaging system (Bioptigen) and OCT Cirrus 500 (Carl Zeiss Meditec) each appear in 1 out of 20 datasets, contributing approximately 5% of the datasets individually.

Table 2.
Acquisition metadata.

Dataset Name	Number of Patients	Device
Kermany et al. [21]	5319	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
The retinal OCT images of rare diseases [22]	NA (Synthetic images)	NA (Synthetic images)
OCTID [23]	NA	Cirrus HD-OCT machine (Carl Zeiss Meditec)
Corneal-OCT Dataset [24]	NA	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
A Composite Retinal Fundus and OCT Dataset [25]	64	NA
AROI database [26]	24	Zeiss Cirrus HD OCT 4000 device
Labeled Retinal OCT Dataset for Classification [27]	441	NA
Duke OCT [28]	384	Bioptigen system
Data on OCT and Fundus Images [29]	26	TOPCON’S 3D OCT-1000 system
Retina OCT Glaucoma dataset [30]	624	Cirrus SD-OCT Scanner
OLIVES Dataset [31]	96	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
Duke 2015 [32]	NA	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
2014 Srinivasan [33]	10	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
2012 Fang [34]	17	SD-OCT imaging system (Bioptigen)
OCT MS and HC data [35]	35	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
OIMHS [36]	119	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
Retouch dataset [37]	NA	OCT devices Cirrus, Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering), and Topcon
University of Auckland Dataset [38]	NA	NA
Retinal image dataset [39]	161	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
THOCT1800 [40]	NA	NA
OCHID: An OCT Choroid Segmentation Dataset [41]	10	Heidelberg Spectralis SD-OCT imaging system (Heidelberg Engineering)
CLOUD Dataset [42]	16	OCT Cirrus 500 (Carl Zeiss Meditec)
OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods [43]	821	Optovue Avanti RTVue XR
Open in a new tab
There are also instances where the acquisition scanner information is not available (NA), which indicates that the scanner used was either not specified or was not applicable for synthetic images or datasets where acquisition details were not provided. The Heidelberg Engineering Spectralis was the most used choice for acquiring OCT images.

3.2.4. Laterality
Laterality refers to the distinction between images acquired from the left eye versus the right eye. This distinction is important for properly interpreting and comparing OCT data, especially in ophthalmology where structural differences between the eyes may exist due to anatomical variations or pathological conditions. There are asymmetries between the left- and right-eye OCT images [48].

Laterality is often indicated using abbreviations such as OD (oculus dexter) for the right eye and OS (oculus sinister) for the left eye. Occasionally, the term OU (oculi uterque) indicates both eyes.

Out of the 22 OCT datasets analyzed, information about laterality is provided for only 6 datasets, representing approximately 27% of the total datasets. This limited availability of laterality information underscores the importance of comprehensive documentation in OCT studies, particularly regarding the distinction between left- and right-eye images for accurate interpretation and clinical relevance.

3.2.5. Image Format and Image Resolution
Among the commonly used file formats, JPEG, TIFF, and PNG were the most prevalent options. The choice of file format could potentially impact the quality and effectiveness of the images captured. Furthermore, certain datasets provide images in formats such as MAT and NumPy, which may necessitate specialized software or libraries for handling and processing. The discrepancy in image resolution across the datasets is notable, with sizes varying from 64 × 128 to 512 × 1024 pixels. Image resolution was a crucial aspect assessed to determine the quality and clarity of the images, with higher resolutions generally allowing for a more detailed analysis. The image format was examined to ensure compatibility with common image processing and analysis tools, facilitating seamless integration into research workflows. To assess the quality of images across the datasets, we decided to take three of the most similar datasets by disease and acquisition setup and compare the pixel intensities across the healthy subsets from the datasets. By analyzing the histograms of pixel intensities and by examining the shape of these histograms, we can identify key characteristics such as uniformity, dynamic range, and the presence of noise or artifacts. High-quality images exhibit a wide distribution of pixel intensities, indicating good contrast and the effective use of the available dynamic range. Comparing these histograms across different datasets helps to check consistency and detect possible biases in the dataset. Thus, we decided to take the Kermany dataset, OCTID dataset, and Labeled Retinal OCT Dataset for Classification. All of them were compared by healthy class. In OCT images, pixel-intensity histograms reveal information about the structure and composition of tissues within the scanned area. The variability in pixel intensity distribution histograms demonstrates that the images may show diverse characteristics, influenced by factors such as lighting conditions, acquisition settings, or differences between the datasets.

Figure 5 reveals a high frequency of low-pixel intensity values, indicating a significant number of dark pixels, which is characteristic of OCT images where the background is dark. There is a noticeable peak at the higher end of the pixel intensity spectrum, suggesting bright reflections from retinal layers. The gradual decrease in frequency as pixel intensity increases from 0 suggests a smooth transition from darker to brighter regions, indicating a uniform distribution and good image quality. This exhibits a wide dynamic range with minimal noise, making it suitable for model training. Figure 6 with the histogram of the OCTID dataset exhibits a peak around mid-range pixel intensities, indicating a balanced contrast with a distribution of light and dark regions. There is a sharp decline in frequency towards higher pixel intensities, with a small peak at the very end, suggesting bright spots that might be reflections or artifacts. The overall shape of the histogram suggests high-quality images with a good contrast. Figure 7 presents the histogram showing a very high frequency of low-pixel intensity values, indicating many dark regions. This distribution can demonstrate a potential issue with image uniformity, possibly due to noise. While this dataset has a good dynamic range, the variability in pixel intensity suggests the need for careful preprocessing.

Figure 5.
Figure 5

Open in a new tab
Histogram for Kermany dataset.

Figure 6.
Figure 6

Open in a new tab
Histogram for OCTID dataset.

Figure 7.
Figure 7

Open in a new tab
Histogram for Labeled Retinal OCT Dataset for Classification dataset.

3.3. Application of OCT Datasets
DL techniques are widely applied to OCT images. The most common tasks include disease classification, detection of abnormalities, and segmentation of retinal layers.

3.3.1. Classification
Classification tasks using OCT datasets involve categorizing images into distinct diseases or condition classes. For instance, the Kermany et al. dataset [21] has been utilized for numerous purposes, including classification [49,50]. The retinal OCT images of rare diseases [22] were used in [51] for the improvement of detecting rare retinal diseases using OCT images by DL with a GAN technique. OCTID [23] in [52,53] was used to train multi-modal image classification and improvement of retinal pathology classification. The network for noiseless image algorithm is proposed in [54] for sorting the clear images from Corneal-OCT Dataset [24]. A Composite Retinal Fundus and OCT Dataset [25] was performed for the screening of macular and glaucomatous disorders. Labeled Retinal OCT Dataset for Classification [27] was used in [55], introducing a multi-scale CNN based on the feature pyramid network structure for automated classification of retinal pathologies. Duke OCT [28] was used in the classification algorithm for defining quantitative indicators for the presence of intermediate AMD.

3.3.2. Detection
Detection tasks focus on identifying specific abnormalities or features within OCT images. The Retina OCT Glaucoma dataset [30] was applied to the detection of glaucoma with a feature-agnostic approach [56]. The OLIVES Dataset [31] was used in [57] for the simultaneous automatic recognition of ophthalmic biomarkers. In 2014, Srinivasan [33] was used to fully automate DME and dry AMD detection. THOCT1800 [40] was used for the automatic detection of retinal regions. OCHID: An OCT Choroid Segmentation Dataset [41] was used in several works that focus on detection in retinal images using multi-scale deep-feature sparse coding [58].

3.3.3. Segmentation
Segmentation tasks involve delineating different structures within OCT images, such as retinal layers. In 2012, Fang [34] was used in a sparsity-based denoising work. Duke 2015 [32] was used for kernel regression-based segmentation. Data on OCT and Fundus images [29] were used for the evaluation of an automated segmentation algorithm for the extraction of retinal layers [59]. The AROI database [26] is often used for a joint retinal layer and fluid segmentation. OCT MS and HC data [35] are often used in segmentation tasks [60]. OIMHS [36] was used in an image segmentation network that integrates spectrum information [61]. The Retouch dataset [37] was used in [62] to develop and validate deep learning models for segmenting retinal structures. The University of Auckland Dataset [38] and retinal image dataset [39] were utilized for retinal layer segmentation for patients with AMD.

The CLOUD Dataset [42] was used to automatically identify the cornea–contact lens relationship. OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods [43] was used in works such as developing foundational models for ophthalmic images [63]. Each of these datasets and corresponding studies demonstrates the critical role of DL in enhancing the analysis and interpretation of OCT images for various medical applications.

4. Discussion
Our results highlight several critical aspects of OCT imaging datasets, underscoring the importance of greater diversity in disease representation among these datasets. The over-representation of certain diseases like DE and AMD in publicly accessible datasets suggests a potential bias towards these conditions. This bias may limit the development of AI models that can generalize well to less common eye diseases. Future efforts should focus on creating and sharing datasets that represent a broader range of conditions. Establishing standardized file formats and resolutions for OCT imaging datasets is crucial for facilitating a seamless data integration and analysis. Furthermore, the variability in image resolutions across datasets may impact the performance of algorithms trained on these data. Additionally, the incomplete metadata associated with many datasets highlights the need for standardized metadata documentation. This documentation should include acquisition protocols, laterality, image quality metrics, and detailed annotations to enhance dataset usability and reproducibility. Geographical bias is another critical issue identified in our study. The disproportionate datasets from certain regions, particularly the United States and China, may limit the applicability of research findings to global populations. To address this, international collaboration initiatives should be promoted to support the collection and sharing of OCT imaging data from underrepresented regions. The paper in [64] demonstrates the effectiveness of transfer learning in adapting models across diverse populations to predict refractive errors and corneal curvature from OCT images, addressing performance issues across different ethnic populations by adapting models pre-trained on a Korean dataset and validated on an Indian dataset. The adapted models showed a significantly improved accuracy compared to non-adapted models. This study demonstrates the potential of transfer learning to enhance the applicability of AI models in multi-ethnic contexts, highlighting the need for further research with larger and more diverse datasets. By leveraging data from different ethnic groups and various OCT devices, it is possible to develop more robust and generalizable models. This approach ensures that the developed AI models are capable of providing accurate diagnostics across a wide range of populations and imaging conditions.

Ethical and privacy concerns remain significant barriers to data sharing in medical imaging. The development of standardized protocols for data anonymization and secure data sharing is essential to address these concerns. Implementing federated learning approaches, where AI models are trained on data from multiple institutions without sharing the actual data, could also help.

In summary, while there are valuable OCT imaging datasets publicly accessible, a prevalent issue is that many publicly accessible databases remain obscure, primarily because they lack visibility, accessibility, transparency, and comprehensive data descriptions.

5. Conclusions
In conclusion, while OCT imaging datasets offer great potential for advancing AI-based research in ophthalmology, several challenges need to be addressed to maximize their impact. These challenges include the need for greater disease diversity, standardized file formats, comprehensive metadata documentation, and strategies to mitigate geographical bias. Addressing these issues will require collaborative efforts among researchers and clinicians to promote open access to diverse and well-documented OCT imaging datasets. Future research should focus on developing standardized protocols for data collection, annotation, and sharing to enhance the utility and interoperability of OCT datasets. This should, in the long term, lead to the development of clinical tools that can increase the quality of patient care, while reducing healthcare costs and personnel workload.

Abbreviations
The following abbreviations are used in this manuscript:

OCT	Optical Coherence Tomography
AI	Artificial intelligence
DL	Deep Learning
FFA	Fundus fluorescein angiography
OCTA	Optical coherence tomography angiography
CFP	Color Fundus Photography
ICGA	Indocyanine green angiography
CSLO	Confocal scanning laser ophthalmoscopy (CSLO)
AMD	Age-related macular degeneration
DR	Diabetic retinopathy
DME	Diabetic macular edema
DE	Diabetic eye
CNV	Choroidal neovascularization
MH	Macular hole
CSR	Central serous retinopathy
MacTel	Macular telangiectasia
RP	Retinis pigmentosa
Acute CSR	Acute central serous chorioretinopathy
Chronic CSR	Chronic central serous chorioretinopathy
NA	Not applicable
MS	Multiple Sclerosis
IRF	Intraretinal fluid
SRF	Subretinal fluid
PED	Pigment epithelial detachment
RVO	Retinal vein occlusion
RAO	Retinal artery occlusion
VID	Vitreomacular interface
ERM	Epiretinal membrane
Open in a new tab
Appendix A
The appendix contains the links for access to the datasets.

Table A1.
Additional information for access.

Dataset Name	Link	Accessed Date
Kermany et al. [21]	https://data.mendeley.com/datasets/rscbjbr9sj/3	3 May 2024
The retinal OCT images of rare diseases [22]	https://data.mendeley.com/datasets/btv6yrdbmv/1	3 May 2024
OCTID [23]	https://borealisdata.ca/dataverse/OCTID	3 May 2024
Corneal-OCT Dataset [24]	https://sites.google.com/site/hosseinrabbanikhorasgani/available-datasets/corneal-oct?authuser=0	3 May 2024
A Composite Retinal Fundus and OCT Dataset [25]	https://data.mendeley.com/datasets/trghs22fpg/1/	3 May 2024
AROI database [26]	https://ipg.fer.hr/ipg/resources/oct_image_database	3 May 2024
Labeled Retinal OCT Dataset for Classification [27]	https://data.mendeley.com/datasets/8kt969dhx6/1	3 May 2024
Duke OCT [28]	https://people.duke.edu/~sf59/RPEDC_Ophth_2013_dataset.htm	3 May 2024
Data on OCT and Fundus Images [29]	https://data.mendeley.com/datasets/2rnnz5nz74/1	3 May 2024
Retina OCT Glaucoma dataset [30]	https://zenodo.org/records/7957454	3 May 2024
OLIVES Dataset [31]	https://zenodo.org/records/7105232	3 May 2024
Duke 2015 [32]	https://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm	3 May 2024
2014 Srinivasan [33]	https://people.duke.edu/~sf59/Srinivasan_BOE_2014_dataset.htm	3 May 2024
2012 Fang [34]	https://people.duke.edu/~sf59/Fang_BOE_2012.htm	3 May 2024
OCT MS and HC data [35]	https://medic.rad.jhmi.edu/index.php?title=OCT_Data	3 May 2024
OIMHS [36]	https://springernature.figshare.com/articles/dataset/OIMHS_dataset/23508453	3 May 2024
Retouch dataset [37]	https://retouch.grand-challenge.org/Home/	3 May 2024
University of Auckland Dataset [38]	NA, Corresponding author	3 May 2024
Retinal image dataset [39]	NA, Corresponding author	3 May 2024
THOCT1800 [40]	https://github.com/SJD095/OCT-Segmentation	3 May 2024
OCHID: An OCT Choroid Segmentation Dataset [41]	https://imed.nimte.ac.cn/OCHID.html	3 May 2024
CLOUD dataset [42]	http://www.varpa.es/research/ophtalmology.html	3 May 2024
OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods [43]	https://data.mendeley.com/datasets/sncdhf53xc/4	6 May 2024
Open in a new tab
Author Contributions
Conceptualization: A.R., M.A. and H.M.; methodology: A.R., G.M.S. and M.A.; dataset search: A.R.; data extraction: A.R.; writing—original draft preparation: A.R.; writing—review and editing of manuscript: A.R., G.M.S., M.A., D.C.D., A.S., J.Z. and H.M.; supervision: G.M.S., M.A. and H.M.; project administration: H.M. All authors have read and agreed to the published version of the manuscript.

Data Availability Statement
This study did not involve the creation or analysis of new data; thus, data sharing does not apply to this article.

Conflicts of Interest
The authors declare no conflicts of interest.

Funding Statement
This project has received funding from the European Union’s Horizon Europe research and innovation programme under grant agreement no 101137074—HEREDITARY.

Footnotes
Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.

References
1.Dhar T., Dey N., Borra S., Sherratt R.S. Challenges of deep learning in medical image analysis—Improving explainability and trust. IEEE Trans. Technol. Soc. 2023;4:68–75. doi: 10.1109/TTS.2023.3234203. [DOI] [Google Scholar]
2.Shen D., Wu G., Suk H.-I. Deep learning in medical image analysis. Annu. Rev. Biomed. Eng. 2017;19:221–248. doi: 10.1146/annurev-bioeng-071516-044442. [DOI] [PMC free article] [PubMed] [Google Scholar]
3.Suzuki K. Overview of deep learning in medical imaging. Radiol. Phys. Technol. 2017;10:257–273. doi: 10.1007/s12194-017-0406-5. [DOI] [PubMed] [Google Scholar]
4.Ker J., Wang L., Rao J., Lim T. Deep learning applications in medical image analysis. IEEE Access. 2017;6:9375–9389. doi: 10.1109/ACCESS.2017.2788044. [DOI] [Google Scholar]
5.Bansal M.A., Sharma R., Kathuria M. A systematic review on data scarcity problem in deep learning: Solution and applications. ACM Comput. Surv. (CSUR) 2022;54:1–29. doi: 10.1145/3502287. [DOI] [Google Scholar]
6.Saleh G.A., Batouty N.M., Haggag S., Elnakib A., Khalifa F., Taher F., Mohamed M.A., Farag R., Sandhu H., Sewelam A., et al. The role of medical image modalities and AI in the early detection, diagnosis and grading of retinal diseases: A survey. Bioengineering. 2022;9:366. doi: 10.3390/bioengineering9080366. [DOI] [PMC free article] [PubMed] [Google Scholar]
7.Li Y., Xia X., Paulus Y.M. Advances in Retinal Optical Imaging. Photonics. 2018;5:9. doi: 10.3390/photonics5020009. [DOI] [PMC free article] [PubMed] [Google Scholar]
8.Schmitt J.M. Optical coherence tomography (OCT): A review. IEEE J. Sel. Top. Quantum Electron. 1999;5:1205–1215. doi: 10.1109/2944.796348. [DOI] [PMC free article] [PubMed] [Google Scholar]
9.Wang D., Wang X., Wang L., Li M., Da Q., Liu X., Gao X., Shen J., He J., Shen T., et al. A real-world dataset and benchmark for foundation model adaptation in medical image classification. Sci. Data. 2023;10:574. doi: 10.1038/s41597-023-02460-0. [DOI] [PMC free article] [PubMed] [Google Scholar]
10.Aytulun A., Cruz-Herranz A., Aktas O., Balcer L.J., Balk L., Barboni P., Blanco A.A., Calabresi P.A., Costello F., Sanchez-Dalmau B., et al. APOSTEL 2.0 recommendations for reporting quantitative optical coherence tomography studies. Neurology. 2021;97:68–79. doi: 10.1212/WNL.0000000000012125. [DOI] [PMC free article] [PubMed] [Google Scholar]
11.Munk M.R., Kashani A.H., Tadayoni R., Korobelnik J.-F., Wolf S., Pichi F., Koh A., Ishibazawa A., Gaudric A., Loewenstein A., et al. Recommendations for OCT angiography reporting in retinal vascular disease: A Delphi approach by international experts. Ophthalmol. Retin. 2022;6:753–761. doi: 10.1016/j.oret.2022.02.007. [DOI] [PMC free article] [PubMed] [Google Scholar]
12.Munk M.R., Kashani A.H., Tadayoni R., Korobelnik J.-F., Wolf S., Pichi F., Tian M. Standardization of OCT angiography nomenclature in retinal vascular diseases: First survey results. Ophthalmol. Retin. 2021;5:981–990. doi: 10.1016/j.oret.2020.12.022. [DOI] [PubMed] [Google Scholar]
13.Goetz K.E., Reed A.A., Chiang M.F., Keane T., Tripathi M., Ng E., Nguyen T., Eydelman M. Accelerating Care: A Roadmap to Interoperable Ophthalmic Imaging Standards in the United States. Ophthalmology. 2024;131:12–15. doi: 10.1016/j.ophtha.2023.10.001. [DOI] [PubMed] [Google Scholar]
14.Halfpenny W., Baxter S.L. Towards effective data sharing in ophthalmology: Data standardization and data privacy. Curr. Opin. Ophthalmol. 2022;33:418–424. doi: 10.1097/ICU.0000000000000878. [DOI] [PMC free article] [PubMed] [Google Scholar]
15.Grants NIH. [(accessed on 29 May 2024)]; Available online: https://grants.nih.gov/grants/guide/notice-files/NOT-EY-24-006.html.
16.Lee A.Y., Campbell J.P., Hwang T.S., Lum F., Chew E.Y. Recommendations for standardization of images in ophthalmology. Ophthalmology. 2021;128:969–970. doi: 10.1016/j.ophtha.2021.03.003. [DOI] [PMC free article] [PubMed] [Google Scholar]
17.Li J., Zhu G., Hua C., Feng M., Bennamoun B., Li P., Lu X., Song J., Shen P., Xu X., et al. A systematic collection of medical image datasets for deep learning. ACM Comput. Surv. 2023;56:1–51. doi: 10.1145/3615862. [DOI] [Google Scholar]
18.Khan S.M., Liu X., Nath S., Korot E., Faes L., Wagner S.K., Keane P.A., Sebire N.J., Burton M.J., Denniston A.K. A global review of publicly available datasets for ophthalmological imaging: Barriers to access, usability, and generalisability. Lancet Digit. Health. 2021;3:e51–e66. doi: 10.1016/S2589-7500(20)30240-5. [DOI] [PubMed] [Google Scholar]
19.Somfai G., Denis C.E., Salinas H.M., Nagy Z.Z., Németh J., Puliafito C.A., Cabrera D. Evaluation of Potential Pitfalls Related to Operator Errors During OCT Image Acquisition. Investig. Ophthalmol. Vis. Sci. 2006;47:2631. [Google Scholar]
20.Hardin J.S., Taibbi G., Nelson S.C., Chao D., Vizzeri G. Factors affecting Cirrus-HD OCT optic disc scan quality: A review with case examples. J. Ophthalmol. 2015;2015:746150. doi: 10.1155/2015/746150. [DOI] [PMC free article] [PubMed] [Google Scholar]
21.Kermany D., Zhang K., Goldbaum M. Labeled optical coherence tomography (oct) and chest X-ray images for classification. Mendeley Data. 2018;2:651. doi: 10.17632/rscbjbr9sj.2. [DOI] [Google Scholar]
22.Yoo T. Data for: Improved accuracy in OCT diagnosis of rare retinal disease using few-shot learning with generative adversarial networks. Mendeley Data V1. 2020 doi: 10.17632/btv6yrdbmv.1. [DOI] [Google Scholar]
23.Gholami P., Roy P., Parthasarathy M.K., Lakshminarayanan V. OCTID: Optical coherence tomography image database. Comput. Electr. Eng. 2020;81:106532. doi: 10.1016/j.compeleceng.2019.106532. [DOI] [Google Scholar]
24.Jahromi M.K., Kafieh R., Rabbani H., Dehnavi A.M., Peyman A., Hajizadeh F., Ommani M. An automatic algorithm for segmentation of the boundaries of corneal layers in optical coherence tomography images using gaussian mixture model. J. Med. Signals Sensors. 2014;4:171. [PMC free article] [PubMed] [Google Scholar]
25.Hassan T., Akram M.U., Nazir M.N. A Composite Retinal Fundus and OCT Dataset with Detailed Clinical Markings of Retinal Layers and Retinal Lesions to Grade Macular and Glaucomatous Disorders. Mendeley Data V4. 2021 doi: 10.17632/trghs22fpg.4. [DOI] [Google Scholar]
26.Melinščak M., Radmilović M., Vatavuk Z., Lončarić S. Annotated retinal optical coherence tomography images (AROI) database for joint retinal layer and fluid segmentation. Autom. Časopis Autom. Mjer. Elektron. Računarstvo Komun. 2021;62:375–385. doi: 10.1080/00051144.2021.1973298. [DOI] [Google Scholar]
27.Sotoudeh-Paima S., Hajizadeh F., Soltanian-Zadeh H. Labeled Retinal Optical Coherence Tomography Dataset for Classification of Normal, Drusen, and CNV Cases. Mendeley Data V1. 2021 doi: 10.17632/8kt969dhx6.1. [DOI] [Google Scholar]
28.Farsiu S., Chiu S.J., O’Connell R.V., Folgar F.A., Yuan E., Izatt J.A., Toth C.A., Age-Related Eye Disease Study 2 Ancillary Spectral Domain Optical Coherence Tomography Study Group Quantitative classification of eyes with and without intermediate age-related macular degeneration using optical coherence tomography. Ophthalmology. 2014;121:162–172. doi: 10.1016/j.ophtha.2013.07.013. [DOI] [PMC free article] [PubMed] [Google Scholar]
29.Raja H., Usman Akram M., Ramzan A., Khalil T., Nazid N. Data on OCT and Fundus Images. Mendeley Data V1. 2019 doi: 10.17632/2rnnz5nz74.1. [DOI] [Google Scholar]
30.Ishikawa H. OCT Volumes for Glaucoma Detection (1.0.0) [Data Set] Zenodo; Genève, Switzerland: 2022. [DOI] [Google Scholar]
31.Prabhushankar M., Kokilepersaud K., Logan Y., Corona S.T., AlRegib G., Wykoff C. OLIVES Dataset: Ophthalmic Labels for Investigating Visual Eye Semantics [Data Set] Zenodo; Genève, Switzerland: 2022. [DOI] [Google Scholar]
32.Chiu S.J., Allingham M.J., Mettu P.S., Cousins S.W., Izatt J.A., Farsiu S. Kernel regression based segmentation of optical coherence tomography images with diabetic macular edema. Biomed. Opt. Express. 2015;6:1172–1194. doi: 10.1364/BOE.6.001172. [DOI] [PMC free article] [PubMed] [Google Scholar]
33.Srinivasan P.P., Kim L.A., Mettu P.S., Cousins S.W., Comer G.M., Izatt J.A., Farsiu S. Fully automated detection of diabetic macular edema and dry age-related macular degeneration from optical coherence tomography images. Biomed. Opt. Express. 2014;5:3568–3577. doi: 10.1364/BOE.5.003568. [DOI] [PMC free article] [PubMed] [Google Scholar]
34.Fang L., Li S., Nie Q., Izatt J.A., Toth C.A., Farsiu S. Sparsity based denoising of spectral domain optical coherence tomography images. Biomed. Opt. Express. 2012;3:927–942. doi: 10.1364/BOE.3.000927. [DOI] [PMC free article] [PubMed] [Google Scholar]
35.He Y., Carass A., Solomon S.D., Saidha S., Calabresi P.A., Prince J.L. Retinal layer parcellation of optical coherence tomography images: Data resource for multiple sclerosis and healthy controls. Data Brief. 2019;22:601–604. doi: 10.1016/j.dib.2018.12.073. [DOI] [PMC free article] [PubMed] [Google Scholar]
36.Ye X., He S., Zhong X., Yu J., Yang S., Shen Y., Chen Y., Wang Y., Huang X., Shen L. OIMHS: An Optical Coherence Tomography Image Dataset Based on Macular Hole Manual Segmentation. Sci. Data. 2023;10:769. doi: 10.1038/s41597-023-02675-1. [DOI] [PMC free article] [PubMed] [Google Scholar]
37.Bogunović H., Venhuizen F., Klimscha S., Apostolopoulos S., Bab-Hadiashar A., Bagci U., Beg M.F., Bekalo L., Chen Q., Ciller C., et al. RETOUCH: The Retinal OCT Fluid Detection and Segmentation Benchmark and Challenge. IEEE Trans. Med. Imaging. 2019;38:1858–1874. doi: 10.1109/TMI.2019.2901398. [DOI] [PubMed] [Google Scholar]
38.Karn P.K., Abdulla W.H. On Machine Learning in Clinical Interpretation of Retinal Diseases Using OCT Images. Bioengineering. 2023;10:407. doi: 10.3390/bioengineering10040407. [DOI] [PMC free article] [PubMed] [Google Scholar]
39.Mukherjee S., De Silva T., Grisso P., Wiley H., Tiarnan D.L.K., Thavikulwat A.T., Chew E., Cukras C. Retinal layer segmentation in optical coherence tomography (OCT) using a 3D deep-convolutional regression network for patients with age-related macular degeneration. Biomed. Opt. Express. 2022;13:3195–3210. doi: 10.1364/BOE.450193. [DOI] [PMC free article] [PubMed] [Google Scholar]
40.Sun Z., Sun Y. Automatic detection of retinal regions using fully convolutional networks for diagnosis of abnormal maculae in optical coherence tomography images. J. Biomed. Opt. 2019;24:056003. doi: 10.1117/1.JBO.24.5.056003. [DOI] [PMC free article] [PubMed] [Google Scholar]
41.Yan Q., Gu Y., Zhao J., Wu W., Ma Y., Liu J., Zhang J., Zhao Y. Automatic choroid layer segmentation in OCT images via context efficient adaptive network. Appl. Intell. 2023;53:5554–5566. doi: 10.1007/s10489-022-03723-w. [DOI] [Google Scholar]
42.Cabaleiro P., de Moura J., Novo J., Charlón P., Ortega M. Automatic Identification and Representation of the Cornea–Contact Lens Relationship Using AS-OCT Images. Sensors. 2019;19:5087. doi: 10.3390/s19235087. [DOI] [PMC free article] [PubMed] [Google Scholar]
43.Kulyabin M., Zhdanov A., Nikiforova A., Stepichev A., Kuznetsova A., Borisov V., Ronkin M., Bogachev A., Korotkich S., Maier A. OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods. Mendeley Data V4. 2024 doi: 10.17632/sncdhf53xc.4. [DOI] [PMC free article] [PubMed] [Google Scholar]
44.Shweikh Y., Sekimitsu S., Boland M.V., Zebardast N. The Growing Need for Ophthalmic Data Standardization. Ophthalmol. Sci. 2023;3:100262. doi: 10.1016/j.xops.2022.100262. [DOI] [PMC free article] [PubMed] [Google Scholar]
45.Wong W.L., Su X., Li X., Cheung C.M.G., Klein R., Cheng C.-Y., Wong T.Y. Global prevalence of age-related macular degeneration and disease burden projection for 2020 and 2040: A systematic review and meta-analysis. Lancet Glob. Health. 2014;2:e106–e116. doi: 10.1016/S2214-109X(13)70145-1. [DOI] [PubMed] [Google Scholar]
46.Teo Z.L., Tham Y.-C., Yu M., Chee M.L., Rim T.H., Cheung N., Bikbov M.M., Wang Y.X., Tang Y., Lu Y., et al. Global prevalence of diabetic retinopathy and projection of burden through 2045: Systematic review and meta-analysis. Ophthalmology. 2021;128:1580–1591. doi: 10.1016/j.ophtha.2021.04.027. [DOI] [PubMed] [Google Scholar]
47.Ting D.S.W., Peng L., Varadarajan A.V., Keane P.A., Burlina P.M., Chiang M.F., Schmetterer L., Pasquale L.R., Bressler N.M., Webster D.R., et al. Deep learning in ophthalmology: The technical and clinical considerations. Prog. Retin. Eye Res. 2019;72:100759. doi: 10.1016/j.preteyeres.2019.04.003. [DOI] [PubMed] [Google Scholar]
48.Kang T.S., Lee W., Park S.H., Han Y.S. Asymmetry between right and left optical coherence tomography images identified using convolutional neural networks. Sci. Rep. 2022;12:9925. doi: 10.1038/s41598-022-14140-x. [DOI] [PMC free article] [PubMed] [Google Scholar]
49.Chen Y.-M., Huang W.-T., Ho W.-H., Tsai J.-T. Classification of age-related macular degeneration using convolutional-neural-network-based transfer learning. BMC Bioinform. 2021;22:99. doi: 10.1186/s12859-021-04001-1. [DOI] [PMC free article] [PubMed] [Google Scholar]
50.Najeeb S., Sharmile N., Khan M.S., Sahin I., Islam M.T., Bhuiyan M.I.H. Classification of retinal diseases from OCT scans using convolutional neural networks; Proceedings of the 2018 10th International Conference on Electrical and Computer Engineering (ICECE); Xi’an, China. 10–12 December 2018; New York, NY, USA: IEEE; 2018. pp. 465–468. [Google Scholar]
51.Yoo T.K., Choi J.Y., Kim H.K. Feasibility study to improve deep learning in OCT diagnosis of rare retinal diseases with few-shot classification. Med. Biol. Eng. Comput. 2021;59:401–415. doi: 10.1007/s11517-021-02321-1. [DOI] [PMC free article] [PubMed] [Google Scholar]
52.Koseoglu N.D., Grzybowski A., Liu T.Y.A. Deep learning applications to classification and detection of age-related macular degeneration on optical coherence tomography imaging: A review. Ophthalmol. Ther. 2023;12:2347–2359. doi: 10.1007/s40123-023-00775-0. [DOI] [PMC free article] [PubMed] [Google Scholar]
53.Korot E., Guan Z., Ferraz D., Wagner S.K., Zhang G., Liu X., Faes L., Pontikos N., Finlayson S.G., Khalid H., et al. Code-free deep learning for multi-modality medical image classification. Nat. Mach. Intell. 2021;3:288–298. doi: 10.1038/s42256-021-00305-2. [DOI] [Google Scholar]
54.Koresh H., Deva J., Chacko S. Classification of noiseless corneal image using capsule networks. Soft Comput. 2020;24:16201–16211. doi: 10.1007/s00500-020-04933-5. [DOI] [Google Scholar]
55.Sotoudeh-Paima S., Jodeiri A., Hajizadeh F., Soltanian-Zadeh H. Multi-scale convolutional neural network for automated AMD classification using retinal OCT images. Comput. Biol. Med. 2022;144:105368. doi: 10.1016/j.compbiomed.2022.105368. [DOI] [PubMed] [Google Scholar]
56.Maetschke S., Antony B., Ishikawa H., Wollstein G., Schuman J., Garnavi R. A feature agnostic approach for glaucoma detection in OCT volumes. PLoS ONE. 2019;14:e0219126. doi: 10.1371/journal.pone.0219126. [DOI] [PMC free article] [PubMed] [Google Scholar]
57.Chen Y., Niu C., Ye C., Jin S., Li Y., Xu C., Liu K., Gao H., Hu J., Zou Y. Multimodality semisupervised learning for ophthalmic biomarkers detection. Int. Workshop Adv. Imaging Technol. (IWAIT) 2024;13164:622–627. [Google Scholar]
58.Das S.D., Dutta S., Shah N.A., Mahapatra D., Ge Z. Anomaly detection in retinal images using multi-scale deep feature sparse coding; Proceedings of the 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI); Kolkata, India. 28–31 March 2022; New York, NY, USA: IEEE; 2022. pp. 1–5. [Google Scholar]
59.Khalil T.M., Akram U., Raja H., Jameel A., Basit I. Detection of glaucoma using cup to disc ratio from spectral domain optical coherence tomography images. IEEE Access. 2018;6:4560–4576. doi: 10.1109/ACCESS.2018.2791427. [DOI] [Google Scholar]
60.He Y., Carass A., Liu Y., Jedynak B.M., Solomon S.D., Saidha S., Calabresi P.A., Prince J.L. Structured layer surface segmentation for retina OCT using fully convolutional regression networks. Med. Image Anal. 2021;68:101856. doi: 10.1016/j.media.2020.101856. [DOI] [PMC free article] [PubMed] [Google Scholar]
61.Huang X., Huang J., Zhao K., Zhang T., Li Z., Yue C., Chen W., Wang R., Chen X., Zhang Q., et al. SASAN: Spectrum-Axial Spatial Approach Networks for Medical Image Segmentation. IEEE Trans. Med. Imaging. 2024 doi: 10.1109/TMI.2024.3383466. [DOI] [PubMed] [Google Scholar]
62.Mahapatra D., Bozorgtabar B., Shao L. Pathological retinal region segmentation from oct images using geometric relation based augmentation; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition; Seattle, WA, USA. 14–19 June 2020; pp. 9611–9620. [Google Scholar]
63.Shi D., Zhang W., Chen X., Liu Y., Yang J., Huang S., Tham Y.C., Zheng Y., He M. EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging. arXiv. 20242405.11338 [Google Scholar]
64.Jain R., Yoo T.K., Ryu I.H., Song J., Kolte N., Nariani A. Deep transfer learning for ethnically distinct populations: Prediction of refractive error using optical coherence tomography. Ophthalmol. Ther. 2024;13:305–319. doi: 10.1007/s40123-023-00842-6. [DOI] [PMC free article] [PubMed] [Google Scholar]
Associated Data
This section collects any data citations, data availability statements, or supplementary materials included in this article.

Data Availability Statement
This study did not involve the creation or analysis of new data; thus, data sharing does not apply to this article.

Articles from Diagnostics are provided here courtesy of Multidisciplinary Digital Publishing Institute (MDPI)

ACTIONS
View on publisher site
PDF (918.5 KB)

Cite

Collections

Permalink
RESOURCES
Similar articles
Cited by other articles
Links to NCBI Databases
On this page
Abstract
1. Introduction
2. Materials and Methods
3. Results
4. Discussion
5. Conclusions
Abbreviations
Appendix A
Author Contributions
Data Availability Statement
Conflicts of Interest
Funding Statement
Footnotes
References
Associated Data

Follow NCBI
NCBI on X (formerly known as Twitter)
NCBI on Facebook
NCBI on LinkedIn
NCBI on GitHub
NCBI RSS feed
Connect with NLM

NLM on X (formerly known as Twitter)
NLM on Facebook
NLM on YouTube
National Library of Medicine
8600 Rockville Pike
Bethesda, MD 20894

Web Policies
FOIA
HHS Vulnerability Disclosure
Help
Accessibility
Careers
NLM
NIH
HHS
USA.gov
Tell us what you think!
```

```
Skip to main content

An official website of the United States government

Here's how you know

                                  NCBI home page
                              
Search

Log in
Primary site navigation
Search PMC Full-Text Archive
Search PMC Full-Text Archive

Search in PMC
Advanced Search 
Journal List 
User Guide
As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.
Learn more: PMC Disclaimer | PMC Copyright Notice
PLOS One logo
PLoS One. 2024 Nov 5;19(11):e0309085. doi: 10.1371/journal.pone.0309085
A detailed analysis of game statistics of professional tennis players: An inferential and machine learning approach
Michal Bozděch 1,*,#, Dominik Puda 1,#, Pavel Grasgruber 2,#
Editor: Qichun Zhang3
Author information
Article notes
Copyright and License information
PMCID: PMC11537396  PMID: 39499678
Abstract
Tennis, a widely enjoyed sport, motivates athletes and coaches to optimize training for competitive success. This retrospective predictive study examines anthropometric features and statistics of 1990 tennis players in the 2022 season, using 20,040 data points retrospectively obtained from the ATP official source after the end of the season. These data were cross-verified with information from other sources before categorisation to address any discrepancies. Employing various analytical methods, the results emphasize the strategic importance of tournament participation and gameplay for financial gains and higher rankings. Prize money analysis reveals a significant disparity favoring top players. Multivariate Analysis of Variance highlights the need to consider multiple variables for understanding ATP rankings. Multinomial Logistic Regression identifies age, height, and specific service-related metrics as key determinants, with older and taller players more likely to secure top positions. Neural Network models exhibit potential in predicting ATP Rank outcomes, particularly for ATP Rank (500). Our results argue for the use of Artificial Intelligence (AI), specifically Neural Networks, in handling complex interactions and emphasize that AI is a supportive tool in decision-making, requiring careful consideration by experienced individuals. In summary, this study enhances our understanding of ATP ranking factors, providing actionable insights for coaches, players, and stakeholders in the tennis community.

Introduction
Analyzing one’s own as well as the opponent’s game statistics is a crucial aspect of player preparation. This preparation also aids in formulating a strategy and tactics based on one’s strengths and the opponent’s weaknesses, enabling the tennis player to better anticipate the opponent’s moves and performance during the game [1, 2]. Consequently, it is possible to reduce the negative outcomes of performance that could be caused by one’s own shortcomings or the actions of the opponent [3–5]. For these reasons, coaches and players analyze physical fitness, technical and psychical factors, good and bad performances of players according to performance indicators that include biomechanics, successful game patterns, physiological and psychological techniques [6–9]. These factors are used to distinguish the successful from the less successful players in a single game, tournament, and season, which makes them particularly relevant for training purposes throughout the season. These analyzes are time-, expert-, and financial-intensive, and only selected individuals can afford them.

There are five main goals in tennis performance analysis, also known as notational analysis: assessing tactics, evaluating technique, analyzing movement, building a database and models, and providing educational tools for both coaches and players [10]. These objectives, initially proposed by Hughes [10], were further developed by O’Donoghue [11]. He emphasized the future prospects of transforming match analysis through advanced techniques and the importance of practical match analysis within coaching contexts. The development of analytical techniques was previously discussed by Liebermann et al. [12]. When describing analytical methods for sports performance using the latest IT technology at the time, Liebermann et al. [12] proposed that these technologies should be utilized in everyday coaching. In relation to this definition, it can be stated that the mentioned methods are fully applicable today, and thus coaches, athletes, and stakeholders now have at their disposal more modern methods for obtaining, analyzing, and interpreting results than those to which the above definitions were related. One of these advanced methods is Big Data analytics using Artificial Intelligence (AI), more precisely Machine Learning [13]. These advanced AI methods have been utilized in various ways within tennis. For example, it has been found that tennis strokes can be classified using data from a personal wristband [14]. Additionally, predictions of match winners can be made before the start of a match by analysing data from players’ previous performances, capturing their short, medium, and long-term performances, as well as their affinity for different types of surfaces [15]. More precisely, the success depends on the serve direction (serves directed more than 5.88° away from the receiving player have a higher chance of ace), the proximity of the ball’s landing spot to the nearest service box line (a ball landing less than 15.27 cm away from the service box line has a greater chance of becoming an ace), and the serve speed. Although serve speed is less significant than accuracy, it still plays a crucial role in matches [16]. Our study aims to process a relatively large and specific volume of data from which it will be possible to predict practically applicable and significant factors. These factors could then be used by coaches, athletes and stakeholders, saving them from having to go through the time-consuming data analysis and decision-making process themselves.

As was evident from the previous information, we can monitor and analyze many variables in tennis. One of the most important variables is Serve. The significance of serving stems from the fact that it constitutes the first action in the game. Subsequently, each return is dependent on this initial action. These interactions often serve as indicators for specific technical and conditioning training programs [17], especially the serve velocity [18]. Tennis return, but most importantly serve are the two most essential strokes in tennis, and their level improves with professional ranking [19–22]. An increasing serve speed reduces the time for the opponent to return the ball successfully and increases the probability of the server’s superiority in the following game or of gaining a direct point [16, 20, 23]. Therefore, we also expect a relatively greater importance for this variable.

There are many ways and methods to acquire, process and analyze data [13]. Data collection methods encompass the use of specially designed computer systems, mathematical models, and video analysis [24–30]. The studies address a wide range of tennis match aspects, including player statistics, technical characteristics, match durations, and tactical strategies. Some studies concentrate on predicting tennis match outcomes through mathematical models and player performance analysis [31–41]. These studies emphasize the importance of detailed data, such as serving success, return success, probabilities of rare events, and other specific match statistics [27, 42–49]. Several studies explore relationships between players’ physical characteristics, such as height, and their performance, e.g. serve speed [23, 50]. Some studies have looked at long-term trends and changes in players’ performance over the years and the impact of age on their rankings [51, 52]. Therefore, performance analysis is a very wide term with a wide range of combinable options for a detailed and practically applicable analysis. However, we have chosen a procedure (using publicly available secondary data) that would enable coaches, athletes and stakeholders to make better decisions about strategies and tactics. On selected and important data that emerged from the findings of this study.

It is important to note, that tennis is significantly influenced by rapidly evolving trends, including the increasing speed of serves [34]. Modern tennis stands out for its high dynamism, speed in thinking and action, precision, and high technical and tactical skills [49, 53]. Therefore, the conclusions drawn from our study are not definitive and may evolve over time. For accuracy, it is essential to base decisions on these findings and individualise them rather than generalise. The authors emphasize the importance of the return of serve as one of the key shots in tennis, along with the serve, as the first action in the game. They have shown that the player with the highest percentage of successful service returns is the one who wins the match, once again highlighting its significance. Even on slow surfaces like clay [27], serves and service returns remain the strokes that most influence match outcomes in modern tennis [54]. This gameplay dynamics and the pivotal role of serves and service returns underscore the current trajectory of tennis and therefore had a significant role in the preparation of the research plan for this project.

This study aims to analyse the performance (service, return) and anthropometric characteristics of professional tennis players to define and quantify the significance of the main factors influencing rankings, points, and prize money at the end of the season. The findings of this study can help coaches, players, and stakeholders better understand these factors. Moreover, by comparing individual player statistics, the existing training plans can be updated to enhance the likelihood of achieving a better ranking at the conclusion of the current tennis season.

Materials and methods
To achieve our research objectives, we conducted meticulous data collection and analysis. The data used to verify our retrospective research premises were sourced from the official website of men’s professional tennis, specifically https://atptour.com. Due to publicly available access to the data, all ATP-registered tennis players were required to sign informed consent to share personal data. After the culmination of the 2022 player season, data regarding player characteristics were acquired in July 2023. This data is maintained, updated, and monitored by the Association of Tennis Professionals (ATP). During data collection, no author had access to the entire file. After the conclusion of data collection, the data were anonymized. Our analysis focused exclusively on singles tennis matches, excluding doubles. The acquired data underwent a rigorous cleansing process, which involved the removal of typographical errors and outliers. Outliers were individually identified through cross-referencing with other official online sources, and values were either revised based on verified evidence or removed from the database altogether. Subsequently, these cleansed data were classified according to our research criteria and evaluated in alignment with our research objectives.

In this study, a total of 31 independent and dependent variables were processed, which were both ordinal and continuous in nature. The data from all 1990 ATP tennis players pertaining to the 2022 season were acquired after its conclusion. Data collection involved the participation of all authors, and the principal author subsequently performed data quality control and corrections. The research encompassed all registered tennis players in the ATP rankings for the 2022 season. No player was excluded, except for individual unrealistic values.

Study criteria
ATP rank
Based on players’ end-of-season rankings, the tennis players were divided into intervals below 100 (ATP (100)), 300 (ATP (300)), and 500 (ATP (500)). For instance, a player ranked 604th was categorized into 7, 3, and 2, respectively. Players with lower rankings were merged into a single research category due to the low prevalence of data, especially in the case of player game statistics (see Table 1). More precisely, ATP (100) consisted of 10 independent categories, with rankings 1 to 9 falling within intervals of 100 ranks in each category, and the 10th category including players ranked beyond 900. ATP (300) consisted of 4 independent categories, with rankings 1 to 3 falling within intervals of 300 ranks in each category, and the 4th category including players ranked beyond 900. ATP (500) consisted of 3 independent categories, with rankings 1 to 2 falling within intervals of 500 ranks in each category, and the 3rd category including players ranked beyond 1000.

Table 1. Basic descriptive statistic of all registered ATP players from 2022 season.
Variable	n	Mean	SD	Min	Max	γ1	γ2	Med (x25 −x75)
Age, year	1978	23.70	4.48	15.00	44.00	0.86	0.59	23.00 (20.00–26.00)
Points, n	1989	123.82	428.18	1.00	6820.00	8.81	100.20	11.00 (2.00–72.00)
Tournament Played, n	1989	12.54	8.85	1.00	38.00	0.43	-1.05	11.00 (5.00–20.00)
Weight, kg	1399	77.99	6.79	56.00	110.00	0.22	0.66	78.00 (73.00–82.00)
Height, cm	1379	184.06	6.86	132.00	211.00	-0.19	2.38	183.00 (180.00–188.00)
Win, n	1952	1.53	6.33	0.00	61.00	5.48	33.18	0.00 (0.00–0.00)
Lose, n	1952	1.50	4.89	0.00	30.00	3.94	15.19	0.00 (0.00–0.00)
Prize money, $	1931	105442.49	509849.09	0.00	9934581	10.83	151.76	4222.00 (1527.00–17534.00)
Aces, n	304	106.75	162.26	0.00	895.00	2.48	6.93	34.00 (6.00–148.5)
Double Faults, n	304	50.69	65.52	0.00	439.00	2.14	6.33	18.00 (6.00–76.00)
1st Serve, %	304	0.62	0.05	0.41	0.80	-0.37	1.08	0.63 (0.59–0.66)
1st Serve Points Won, %	304	0.69	0.07	0.45	0.91	-0.61	1.04	0.69 (0.65–0.73)
2nd Serve Points Won, %	304	0.48	0.07	0.18	0.64	-1.15	2.63	0.49 (0.45–0.52)
Break Points Faced, n	304	119.86	133.21	1.00	602.00	1.09	0.08	51.00 (14.00–205.75)
Break Points Saved, %	304	0.57	0.13	0.00	0.79	-2.19	6.45	0.60 (0.53–0.63)
Service Games Played, n	304	215.54	251.97	1.02	912.00	1.13	0.02	85.00 (19.00–362.75)
Service Games Won, %	304	0.73	0.13	0.14	0.93	-1.96	5.91	0.75 (0.68–0.81)
Total Service Points Won, %	304	0.61	0.06	0.37	0.74	-1.00	2.04	0.61 (0.58–0.64)
1st Serve Return Points Won, %	304	0.27	0.06	0.04	0.43	-0.94	2.04	0.27 (0.24–0.30)
2nd Serve Return Points Won, %	304	0.47	0.07	0.22	0.65	-0.84	1.78	0.48 (0.44–0.51)
Break Points Oppor., n	304	119.08	151.78	0.00	684.00	1.40	0.96	40.50 (9.75–184)
Break Points Conver., %	304	0.36	0.17	0.00	1.00	0.45	3.36	0.38 (0.31–0.42)
Return Games Played, n	304	218.98	255.36	1.05	996.00	1.14	0.07	87.00 (20.50–364.25)
Return Games Won, %	304	0.17	0.08	0.00	0.43	-0.25	0.33	0.18 (0.13–0.22)
Return Points Won, n	304	0.34	0.05	0.16	0.47	-1.01	1.55	0.35 (0.32–0.37)
Total Points Won, n	304	0.48	0.04	0.33	0.55	-1.47	2.76	0.48 (0.46–0.50)
Open in a new tab
γ1, Skewness; γ2, Kurtosis; x25, 25th percentile; Med (x50), median (50th percentile); x75, 75th percentile.

Anthropometric characteristics
For the sake of clarity, we included variables Age (in years), Height (in cm), and Weight (in kg) in this category.

Serve
This category encompassed 10 player statistics from the single service record, specifically: Aces (sum of integers), Double Faults (sum of integers), 1st Serve (percentage), 1st Serve Points Won (percentage), 2nd Serve Points Won (percentage), Break Points Faced (sum of integers), Break Points Saved (percentage), Service Games Played (sum of integers), Service Games Won (percentage), Total Service Points Won (sum of integers).

Serve (%)
This subset included all percentage variables from the Serve category.

Return
This category encompassed eight player statistics from the single return record, specifically: 1st Serve Return Points Won (percentage), 2nd Serve Return Points Won (percentage), Break Points Opportunities (sum of integers), Break Points Converted (percentage), Return Games Played (sum of integers), Return Games Won (percentage), Return Points Won (percentage), Total Points Won (percentage).

Return (%)
This subset included all percentages variables from the Return category.

Service, Return
This subset included all integer variables from the Service and Return categories.

Service, Return (%)
This subset included all percentage variables from the Service and Return categories.

Variables Prize money (in dollars), Points (sum of integers), and Tournaments Played (sum of integers) were used only in descriptive statistics or predictive Neural Network models due to their high multicollinearity with independent variables (ATP Ranks).

Statistical analysis
Utilizing the multivariate analysis of variance
Multivariate Analysis of Variance (MANOVA) was used as a powerful statistical technique employed to investigate the impact of one or more independent variables (IVs) on multiple dependent variables (DVs) simultaneously. Within this study, the primary objective was to assess the influence of different levels of ATP ranks (Fixed factor or independent variable, IV), specifically ATP (100), ATP (300), and ATP (500), on a set of DVs. These DVs were categorized into three groups: Anthropometric measurements, Service-related metrics, and Return-related metrics. The characteristics of these grouped IVs and DVs have been described in detail above. Notably, only DVs exhibiting a ratio or percentage scale were considered in our analysis, excluding integer-based variables. Prior to conducting MANOVA, the data were screened for missing values, outliers, and adherence to the scale requirements (ratio/percentage). Given the inherent assumptions associated with MANOVA, it is crucial to note that our data did not meet these assumptions fully. Specifically, the assumptions of multivariate normality, homogeneity of variance-covariance matrices, and linearity were violated. To address these violations, we utilized Pillai’s Trace as an alternative test statistic, which is robust to these assumption violations. To gain further insights into the intergroup differences resulting from the various ATP levels, we employed a combination of post hoc tests. Specifically, we utilized Scheffe’s Post Hoc test (selected for its flexibility and robustness in handling multiple comparisons), and Bonferroni correction (applied to control for Type I error across multiple pairwise comparisons). Furthermore, to gauge the magnitude of the observed effects, we employed Partial eta squared (η2p) as an effect size measure. The thresholds for interpreting effect sizes, as defined by Cohen [55], were categorized as follows: small (η2p = 0.01), medium (η2p = 0.06), and large (η2p = 0.14) effects.

Utilizing the Multinomial Logistic Regression
In this section, we will discuss the application of Multinomial Logistic Regression (MLR) as part of our statistical analysis. MLR was employed to predict categorical outcomes when dealing exclusively with metric data. We will elucidate the predictors and explanatory variables used in our models, along with the process of model evaluation and assumption verification.

Our predictive model centres around the following metric variables, which are used to predict categorical outcomes: ATP (100), ATP (300) and ATP (500). The explanatory variables considered in our analysis encompass the following factors: Anthropometric measurements, Service-related metrics, and Return-related metrics. To enhance the relevance and interpretability of our findings, we incorporated reference data, specifically, the categories (ranks) of the lowest-scoring players in the ATP ranking system.

To ascertain whether the full model demonstrates a substantial improvement in fit over the null model, model fitting information was rigorously evaluated. Statistically significant results (p < .001) were obtained for all nine models, each encompassing three types of IV (ATP levels: ATP (100), ATP (300), and ATP (500)) and three types of DV (Anthropometric, Service, Return). A goodness-of-fit assessment was conducted to determine whether the model fits the observed data. Both the Pearson and Deviance tests yielded statistically non-significant results, except for the Deviance test in the case of ATP (500) and the anthropometric model (χ2(2030) = 2270.55, p < .001). Since the Pearson test did not reach statistical significance (χ2(2030) = 2045.48, p = .400), we retained the model.

Subsequently, in the results, we include information about the Likelihood Ratio tests used to assess the overall contribution of each IV to the model. Variables that were statistically significant predictors in the model were determined using the conventional alpha level of 0.05. Furthermore, the Parameter estimates, with the Bonferroni correction, was applied.

Utilizing the artificial intelligence
In this section, we explore the application of artificial intelligence within the context of our research. We outline the research criteria, including IVs, predictors, and the architecture of our models, all of which utilize artificial intelligence techniques. The file with exported AI code with synaptic weight estimates, activation function et cetera of the best-performing Neural Network model is available on the public repository; named NN 3.1 model [56].

Research criteria. Our analysis encompasses five independent response variables: ATP (100), ATP (300), ATP (500), Prize money, Points. Predictors in our models encompass various combinations, including the aggregation of all predictors, service-related variables, return-related variables, and combinations of Service with Return as well as Service (%) with Return (%). Additionally, the All model, in contrast to the others, incorporates anthropometric (Age, Weight, Height) and additional factor Tournament Played.

Input and output layers. The input and output layers of our models vary in terms of the number of units and the types of variables they encompass. Specifically, in the case of models incorporating all predictors, the input layer consists of 22 units accommodating a comprehensive set of predictors, including anthropometric measurements (Age, Height, Weight), service-related variables (Service, Service (%)), and return-related variables (Return, Return (%)). Meanwhile, the output layer for categorical response variables, such as ATP (100), ATP (300), and ATP (500), comprises a specific number of units corresponding to the categories within each variable. For continuous response variables like Prize money and Points, the output layer consists of continuous (scale) variables, allowing for regression-style predictions. These input and output layer configurations are consistent across all models, facilitating the application of artificial intelligence techniques for predictive modeling and analysis.

Data splitting. To ensure consistency and comparability, all models applied were of the Neural Network type (NN), specifically multilayer perceptron. Cases were randomly assigned based on the relative number of cases, with 70% allocated to training and 30% to testing. The model architecture comprised two hidden layers, employing hyperbolic tangent as the activation function and Identity as the output activation function. Batch training and the Scaled Conjugate Optimization algorithm were utilized.

Receiver Operating Characteristics analysis. The Receiver Operating Characteristics (ROC) curve illustrates the sensitivity against 1-specificity. The Area Under the Curve (AUC) is an interpretation of this probability and serves as an indicator of the overall model quality when dealing solely with categorical responses. While there is no universally accepted threshold classification paradigm, in our research, we utilized the following interpretations: fail (.50-.60), poor (.60-.70), fair (.70-.80), good (.80-.90), and excellent (.90–1.00) [57].

Software utilization
Given the extensive and intricate nature of our data analysis and the imperative need for rigorous data evaluation and result control, we utilized the capabilities of three distinct statistical software programs. Specifically, IBM SPSS Statistics (IBM Corp, v. 29.0.0.0) played a central role in our data analysis process, serving as the linchpin for critical calculations, including MANOVA, MLR, NN modelling and generating graphs. Complementing SPSS, we leveraged the open-source software JASP (v. 0.17.2.1) for initial descriptive statistical analyses. Additionally, MATLAB, equipped with machine learning toolboxes (MathWorks, R2022a), contributed significantly to our artificial intelligence-based modeling and analysis. This multifaceted software approach ensured the comprehensive and reliable examination of our data. JASP was employed for initial descriptive statistical analyses and nonparametric correlation (Spearman’s rho with 95% confidence interval) to provide a fundamental overview of our dataset, while MATLAB was instrumental in implementing artificial intelligence techniques, notably Cross-Validation with a 5-fold approach. The combination of these statistical software tools ensured the comprehensive and reliable analysis of our data.

Ethical considerations
As the data used in this study were publicly available, there was no need to seek ethical approval from a review board. While our study did not directly involve human subjects, we upheld ethical standards in the analysis of secondary data. We followed established data ethics principles, ensuring data privacy, confidentiality, and responsible data use. Although primarily designed for research with human participants, the Helsinki Declaration’s ethical guidelines served as a reference point for our broader ethical framework. These guidelines emphasize privacy, data security, and research integrity, principles we incorporated into our data analysis to maintain ethical standards even in a non-human subject context.

Results
In Table 1, the results of descriptive statistics for all 26 research variables can be seen. The Win and Lose variables will not be further examined in this study. From the table, it is evident that the youngest player was 15 years old. There was a total of 5 players ranked from 1373rd to 1726th who participated in 1–3 tournaments, earning 1–3 points and thereby making $258-$1024. Conversely, the oldest player (Toshihide Matsui) was 44 years old, achieved a rank of 1517, played in 3 tournaments, earned 2 points, and made $2015.

We can thus conclude that there is a certain parallel between these extreme examples. The highest-ranked player (Carlos Alcaraz) has earned the most points despite only participating in 17 tournaments, while two players with ranks 572 and 872 participated in 38 tournaments, earning 17–55 points and $8044-$15707. Hence, we were interested in the association between rank and the ratio of points earned per tournament played. A very strong and negative association was found (rho = -.912; p < .001; 95% CI = -.919, -.904). The relationship between rank and tournaments played alone exhibited a lower level of association (rho = -.831; p < .001; 95% CI = -.844, -.816), as did the positive association between the number of tournaments played and points earned (rho = .853; p < .001; 95% CI = .841, .865). Therefore, we can conclude that the strategy of gaining a minimum number of points over multiple tournaments (instead of thorough preparation) might be suitable for gaining experience but, according to the data, is not conducive to achieving a higher ranking in the ATP. It should be noted that the association between rank and points was the highest among these variables (rho = -.9971, p < .001; 95% CI = -.9973, -.9967). This conclusion is logical and stems from the fact that Rank in tennis is formed using Points.

Furthermore, it would be logical to assume that the top player (Carlos Alcaraz) earned the most Prize money. However, even though he ranked second (in terms of Prize money earned), he earned $2,306,969 (23.22%) less than Novak Djokovic. The disparity in prize money between these two highest values is evident throughout the dataset, as confirmed by the Skewness (γ1) and Kurtosis (γ2) findings, which reached relatively higher values compared to other observed variables. Specifically, the Skewness confirmed a strong positive (right-skewed) asymmetry in the data distribution, indicating that the majority of research data falls below the mean. Using the Kurtosis coefficient, it can be stated that the frequency distribution is more peaked than a normal distribution (known as Leptokurtic). From these conclusions, it can be inferred that most tennis players in the 2022 season earned less Prize money than the stated $105,442.49±509,849.09. More precisely, out of a total of 1931 valid values of prize money, 237 tennis players (12.27%) received more than the average prize money, while 1694 players (87.73%) from the 2022 season received less than the average prize money.

In the following subsections, these data on DVs will be further analyzed and compared according to the predetermined IVs for the research.

Differences in ATP rank effects on anthropometric, service, and return metrics
We used MANOVA as an extension of the univariate analysis of variance for examining the group differences of a singular IV across multiple outcome variables.

From Table 2, it is evident that a statistically significant difference exists across the levels of the IV in a linear combination of the DV. As a result, it is appropriate to proceed with a detailed statistical analysis. Furthermore, since Partial Eta Squared indicates the variance in the DV that can be explained by the IV, we can infer that the DV can explain variations ranging from small (η2p = .027) to large (η2p = .178) in ATP status (the IV). In other words, considering the example of the strongest effect, we can conclude that 17.8% of the variance in the variable Service (%) can be attributed to ATP (500). Unlike p-values, it is permissible to compare effect size values among themselves. Therefore, it is worth noting that the variable Service (%) also consistently explained the largest variation within each IV; ATP (100), ATP (300) and ATP (500). These are logical conclusions that indicate the game begins with the serve; hence, these variables are considerably more critical. It also suggests that in today’s professional league, while anthropometric characteristics are important, gaming-related characteristics are even more significant.

Table 2. Summary results of multivariate test for MANOVA.
IV	DV	Value	F	Hyp. df	Error df	p	η2P	NCP	1-β
ATP (100)	Anthropometric	0.08	4.16	27	4098	< .001	.027*	112.379	1.00
Service (%)	0.75	4.68	54	1764	< .001	.125**	252.825	1.00
Return (%)	0.71	4.36	54	1764	< .001	.118**	235.497	1.00
ATP (300)	Anthropometric	0.05	8.36	9	4116	< .001	.018*	75.249	1.00
Service (%)	0.46	8.93	18	891	< .001	.153***	160.700	1.00
Return (%)	0.31	5.79	18	891	< .001	.105**	104.239	1.00
ATP (500)	Anthropometric	0.06	13.11	6	2744	< .001	.028*	78.664	1.00
Service (%)	.36	10,75	12	594	< .001	.178***	128.953	1.00
Return (%)	0.18	5.03	12	594	< .001	.092**	60.342	1.00
Open in a new tab
η2P, Partial Eta Squared; NCP, Non-Centrality Parameter; 1-β, Observed Power.

*small effect size; **medium effect size; ***large effect size.

As the effects of all the research-dependent variables were confirmed across all IVs, our interest was piqued regarding which individual DV influences the various levels of ATP status. An overview of the results of these univariate tests can be found in Table 3.

Table 3. Summary of the univariate tests results for different MANOVAs.
IV	DV	Sum of Squares	df	Mean Square	F	p	η2P	NCP	1-β
Rank100	Age	1487.78	9	165.31	8.26	< .001	.052	74.35	1.00
Weight	1016.98	9	113.00	2.40	.011	.016	21.55	.93
Height	1925.75	9	213.97	4.67	< .001	.030	42.04	1.00
Rank 300	Age	1151.10	3	383.70	19.03	< .001	.040	57.08	1.00
Weight	591.39	3	197.13	4.17	.006	.009	12.51	.86
Height	1000.08	3	333.36	7.20	< .001	.016	21.61	.98
Rank 500	Age	1160.17	2	580.09	28.79	< .001	.040	57.59	1.00
Weight	702.85	2	351.42	7.45	< .001	.011	14.90	.94
Height	1136.86	2	568.43	12.32	< .001	.018	24.64	1.00
Rank 100	1st Serve	0.04	9	0.01	1.63	.107	.047	14.64	.75
1st Serve Points Won	0.24	9	0.03	6.17	< .001	.159	55.53	1.00
2nd Serve Points Won	0.29	9	0.03	9.19	< .001	.220	82.75	1.00
Break Points Saved	261.03	9	29.00	7.47	< .001	.186	67.26	1.00
Service Games Won	1.33	9	0.15	12.78	< .001	.281	115.05	1.00
Total Service Points Won	0.25	9	0.03	10.94	< .001	.251	98.42	1.00
Rank 300	1st Serve	0.03	3	0.01	3.44	.017	.033	10.33	.77
1st Serve Points Won	0.17	3	0.06	12.30	< .001	.110	36.90	1.00
2nd Serve Points Won	0.13	3	0.05	11.58	< .001	.104	34.73	1.00
Break Points Saved	260.84	3	86.95	22.86	< .001	.186	68.57	1.00
Service Games Won	1.01	3	0.34	27.14	< .001	.213	81.43	1.00
Total Service Points Won	0.16	3	0.06	19.81	< .001	.165	59.43	1.00
Rank 500	1st Serve	0.01	2	0.01	1.88	.155	.012	3.76	.39
1st Serve Points Won	0.13	2	0.06	13.73	< .001	.084	27.45	1.00
2nd Serve Points Won	0.08	2	0.04	9.80	< .001	.061	19.59	.98
Break Points Saved	327.70	2	163.85	45.91	< .001	.234	91.82	1.00
Service Games Won	0.56	2	0.28	20.11	< .001	.118	40.21	1.00
Total Service Points Won	0.11	2	0.06	18.57	< .001	.110	37.13	1.00
Rank 100	1st Serve Return Points Won	0.22	9	0.02	8.92	< .001	.214	80.24	1.00
2nd Serve Return Points Won	0.01	9	0.01	3.03	.002	.085	27.27	.97
Break Points Converted	1.13	9	0.13	4.65	< .001	.125	41.82	1.00
Return Games Won	0.50	9	0.06	10.16	< .001	.237	91.41	1.00
Return Points Won	0.15	9	0.02	8.51	< .001	.207	76.61	1.00
Total Points Won	0.15	9	0.02	20.92	< .001	.390	188.24	1.00
Rank 300	1st Serve Return Points Won	0.06	3	0.02	6.67	< .001	.063	20.02	.97
2nd Serve Return Points Won	0.06	3	0.02	4.39	.005	.042	13.18	.87
Break Points Converted	0.20	3	0.07	2.25	.083	.022	6.74	.57
Return Games Won	0.02	3	0.07	10.43	< .001	.094	31.29	1.00
Return Points Won	0.05	3	0.02	7.03	< .001	.066	21.09	.98
Total Points Won	0.09	3	0.03	28.36	< .001	.221	85.07	1.00
Rank 500	1st Serve Return Points Won	0.02	2	0.01	2.52	.082	.016	5.04	.50
2nd Serve Return Points Won	0.03	2	0.01	2.94	.054	.019	5.88	.57
Break Points Converted	0.08	2	0.04	1.34	.263	.009	2.68	.29
Return Games Won	0.05	2	0.03	3.92	.021	.025	7.83	.70
Return Points Won	0.01	2	0.01	2.16	.117	.014	4.32	.44
Total Points Won	0.04	2	0.00	17.42	< .001	.104	34.85	1.00
Open in a new tab
NCP, Non-Centrality Parameter; 1-β, Observed Power.

Table 3 reveals that the majority of univariate test results for different MANOVAs remained statistically significant even after applying the Bonferroni correction. Consequently, it is plausible to assert that individual DV were influenced by the IVs within the context of MANOVA. For a more intricate examination of the specific effects of each IV on each DV individually, rather than considering them as a collective group, as performed in the MANOVA, we can denote effects ranging from trivial (.009) to substantial (.390) in terms of the IV’s contribution to the variance in the DV. Eta-squared (η2p) aids in gauging the magnitude of this influence. Therefore, we can affirm that we have identified precisely 14 large, 12 medium, and 17 small effects. Among the 14 variables that exhibited large effects, none were among the anthropometric DVs, five pertained to return percentages (Return % DV), and nine were associated with service-related variables (Service DV). To illustrate it, variables such as Weight (for Rank 100) and Break Points Converted (for Rank 500) explained very little variance in the DVs (0.9%), whereas Total Points Won explained 39.0% of the variance in the DVs. After obtaining these positive and statistically significant findings, it is common to conduct a post hoc test to further explore the statistically significant observations. Based on the Scheffe post hoc test, the application of the Bonferroni correction, and an assessment of descriptive statistics, the following conclusions can be drawn.

In case of Anthropometric-base variables, it was found that tennis players ranked 1–100 (26.86±4.22 years) are older than those ranked above 900 (22.56±4.12 years), and players ranked 1–300 (26.21±4.37 years) are older than players in the range of 601–900 (24.03±4.43 years) and above 900 (22.56±4.12 years). Furthermore, players ranked 1–100 (25.87±4.53 years) are older than players who achieved rankings of 501–1000 (23.95±4.27 years) and above 1000 in the ATP rankings (22.47±4.11 years). This finding can be interpreted as an indication that with increasing age, the probability of achieving a better ranking also increases. Tennis players ranked 1–500 (78.95±6.64 kg) had a higher weight than players ranked above 1000 (77.39±7.02 kg). This was the only statistically significant result in the case of the Weight variable. Players ranked 1–100 (187.77±7.12) were taller than players ranked above 900 (183.43±6.74); likewise, players ranked 1–300 (185.39±6.76) were taller than players ranked above 900 (183.43±6.74). Since players ranked 1–500 (185.25±6.81) were taller than players ranked 501–1000 (183.58±6.89) and above 1000 (183.25±6.72), it can be inferred that player height may be a suitable factor for predicting their ranking. The four variables with the strongest effects were selected and displayed in Fig 1.

Fig 1. Comparison of selected ATP rank and anthropometric-based characteristics.
Fig 1

Open in a new tab
After Anthropometric-base variables, Service-based variables were analysed. Interestingly, the variable 1st serve (%) did not yield statistically significant results, possibly due to the fact that most players focus on this variable during their training, and as a result, there are no significant differences among the various categorical variations of the ATP ranking. In the case of 1st service points won (%), players ranked 1–100 (0.72±0.05) achieved better results than players ranked above 1000 (0.54±0.09). This trend continues even for players ranked 1–300 (0.70±0.06), who achieved better results than players ranked above 900 (0.54±0.09). Therefore, this appears to be a variable with a significantly predictive value. Break Points Saved is one of the variables where differences were not visible between the first and last research categories. Players ranked 1–100 (0.51±0.03) had better results than players ranked 201–300 (0.45±0.07) and 401–500 (0.42±0.09). However, it is important to note that this lack of difference is primarily due to statistical significance, as the worst values were achieved by tennis players ranked above 900 (0.40±0.04), but this is based on only five valid data points. A similar pattern was observed in the case of differences between players ranked 1–300 (0.49±0.06) and 301–600 (0.45±0.08), where players ranked above 900 (0.40±0.04) were not included in the calculations due to the low number of data points. Regarding Service Games Played, a significant separation can be observed among players’ ranks. Players ranked above 900 (0.32±0.32) had inferior results compared to players ranked 1–100 (0.62±0.4), 101–200 (0.58±0.10), 201–300 (0.57±0.13), 301–400 (0.49±0.18), 401–500 (0.46±0.22), 501–600 (0.56±0.16), and 701–800 (0.37±0.24). A similar trend can also be observed when dividing the data according to ATP (300) and ATP (500), where the last categories achieved the lowest results. The variable Service games won provided interesting insights into player statistics and ATP ranking. Players ranked 1–100 (0.80±0.06) exhibited better results than players ranked 301–400 (0.67±0.016), 401–500 (0.64±0.17), and those ranked above 900 (0.46±0.16). Additionally, players ranked 101–200 (0.74±0.10) achieved superior results compared to players ranked above 900 (0.46±0.16). Therefore, it was not surprising to observe a noticeable downward trend when dividing the data by ATP (300). More precisely, players ranked 1–300 (0.76±0.09) demonstrated better results than players ranked 301–600 (0.66±0.15), 601–900 (0.59±0.22), and even those ranked above 900 (0.46±0.16). A similar trend emerged when dividing the data by ATP (500), with players ranked 1–500 (0.74±0.11) achieving superior results than players ranked 501–1000 (0.63±0.17) and those ranked above 1000 (0.45±0.18). Consequently, this variable also exhibits great potential for prediction. The variable Total service points won exhibited the trend described above, where players ranked 1–100 (0.64±0.05) achieved better results than players ranked above 900 (0.49±0.06). Further analysis revealed that players ranked 1–100 (0.64±0.05) achieved superior results than players ranked 101–200 (0.58±0.07) and those ranked above 900 (0.49±0.06). While tennis players ranked 201–300 exhibited a similar trend (i.e., worse results than the top players), due to the high degree of uncertainty (given the significant variability in the data), this effect was not statistically significant. Nonetheless, players ranked 1–500 (0.61±0.05) achieved better results than players ranked above 1000 (0.48±0.07). The four variables with the strongest effects were selected and displayed in Fig 2.

Fig 2. Comparison of selected ATP rank and service-base characteristics.
Fig 2

Open in a new tab
In the case of variables falling under the category of Return %, fewer statistically significant variables were identified compared to the previously studied areas (Anthropometric and Service %). As one of the two main variables (along with Total Points Won), 1st Serve Return Points Won had the largest differences not between top and bottom ranks, but between ranks 1–100 (0.29±0.03) and 201–300 (0.23±0.07), as well as between players from 101–200 (0.28±0.04) and 301–400 (0.24±0.06). However, it is important to note that this variable, despite being identified as one of the main variables, has low predictive power, as its mean values exhibit oscillating tendencies. Other statistically significant values were observed in the variables Return Games Won and Return Points Won rank, where in both cases, players ranked 1–100 (0.21±0.05 and 0.37±0.03, respectively) outperformed those ranked above 900 (0.06±0.13 and 0.31±0.06). Another main variable in this section with greater predictive capability than the previously mentioned variable was Total Points Won, where players from 1–100 (0.50±0.02) achieved better results than tennis players from 101–200 (0.48±0.03), 201–300 (0.46±0.04), 301–400 (0.46±0.04), 401–500 (0.45±0.04), and those ranked above 900 (0.40±0.06). Notably, players from 101–200 (0.48±0.03) achieved better values than those ranked above 900 (0.40±0.06). This trend was also evident between ranks 1–300 (0.49±0.03) and 301–600 (0.46±0.04), 601–900 (0.43±0.05), and those ranked above 900 (0.40±0.06). In this context, this variable stands out as having the best predictive capability, as the mean values for this variable (Total Points Won) exhibit a linear decreasing tendency, after deleting outliers from the dataset. It is worth noting that even among the top 5 players (e.g., Novak Djokovic), there was an outlier value, indicating significantly better performance compared to other players (0.55). However, this outlier value was not evident in the last division, where players ranked 1–500 (0.48±0.03) achieved better values than players ranked above 1000 (0.40±0.07). The four variables with the strongest effects were selected and displayed in Fig 3.

Fig 3. Comparison of selected ATP rank and return-base characteristics.
Fig 3

Open in a new tab
Multinomial Logistic Regression results for ATP rank outcomes
To evaluate the overall contribution of each IV to the model, Likelihood Ratio tests were used in which variables Age, Height in ATP 10, ATP (300) and ATP (500) were statistically significant predictors in the model focusing on anthropometric characteristics. In case of Service, we found statistically significant results in variables 1st Serve Points Won, 2nd Serve Points Won at ATP (100); 1st Serve Points Won, 2nd Serve Points Won, Service Games Played at ATP (300); 1st Serve Points Won, Service Games Played at ATP (500). In case of Return we found only one statistically significant result, more precisely in variable Total Points Won for data categorization according to ATP (100). The Bonferroni correction was applied to all reported results.

The final results of MLR, based on Parameter Estimates (After Bonferroni correction), reveal five statistically significant variables, more precisely Age at ATP 100, 300 and 500 categorizations; Height at ATP (100) and Total Points Won at ATP (100), relatively to the (last) reference category. Scheffe’s Post hoc test, after the Bonferroni correction, reveals statistically significant results for players Age at 1.-100. rank (OR = 1.16; 95% CI = 1.10,1.21), 101.-200. rank (OR = 1.13; 95% CI = 1.07, 1.18), 201.-300. rank (OR = 1.09; 95% CI = 1.04, 1.14), 301.-400. rank (OR = 1.11, 95% CI = 1.06, 1.16), 1.-300. rank (OR = 1.12, 95% CI = 1.09, 1.16), 301.-600. rank (OR = 1.06; 95%CI = 1.03, 1.10), 1.-500. rank (OR = 1.10; 95% CI = 1.07, 1.14); Height at 1.-100. rank (OR = 1.11, 95% CI = 1.06, 1.16). In the case of Service, no statistically significant result was found, but one statistically significant result was documented in Return players statistics, more precisely, Total Points Won at 1.-100. rank (OR = 8.53E+41; 95% CI = 4.74029E+18, 1.53E+65). Because every statistically significant result contains positive beta coefficient results. For example, in the case of the variable Age, this indicates that older ATP tennis players are more likely to be in the 1–100 rank. The Odds ratio for this variable was 1.157, indicating that for each unit increase in age, the odds of being ranked 1. to 100. change by a factor of 1.16 (95% CI = 1.10–1.21). In other words, older ATP tennis players in the 2022 season had more chance to be among top 100 ATP players at the end of season. Similar findings (with different intensity) can also be demonstrated in the case of 101.-200 rank, 201.-300. rank, 301.-400. rank, 1.-300. rank, 301.-600. rank, 1.-500. rank, as well as in the case of height, where for each unit increase in height, the probability of being among the top 100 players changes by a factor of 1.11 (95% CI = 1.06–1.16). In other words, with each 1cm, the chance increases by 11.0%. For better visualization, the above-mentioned effects are presented in Fig 4 using Odds Ratios and a 95% Confidence Interval. The graph also includes a null effect line.

Fig 4. Comprehensive overview of statistically significant results from Multinomial Logistic Regression (MLR) including Odds Ratios (OR) and 95% Confidence Intervals (CI), with reference line for none effect.
Fig 4

Open in a new tab
Neural Network analysis of multivariate outcomes associated with ATP rank
Multiple models were generated and subsequently analysed, yet only the most precise Neural Network (NN) models are depicted in Figs 5 and 6 (by results of test validation, y-axis), along with their corresponding details in Table 4. It is essential to highlight that unlike the other examined response variables, Prize Money and Points were not categorical; instead, they are continuous variables. Consequently, a lower level of validity may be anticipated for these particular variables.

Fig 5. An overview of Neural Network test validation according predictors.
Fig 5

Open in a new tab
Fig 6. An overview of Neural Network test validation according response.
Fig 6

Open in a new tab
Table 4. An overview of the most accurate Neural Network models.
Model	Response	Predictor	Validation (%)	AUC	Independent Var. Importance
Training	Test	Lowest (%)	Highest (%)
1.1	ATP (100)	All	64.3	55.6	.818-.977	Break Points Converted (.026)	Age (.078)
1.2		Service	60.3	61.4	.610-.999	2nd Serve Points Won (.075)	Service Games Played (.139)
1.3		Service (%)	44.2	39.3	.333-.999	Break Points Saved (.121)	Service Games Won (.246)
1.4		Return	59.8	62.0	.528-.972	Break Points Converted (.072)	Return Points Won (.198)
1.5		Return (%)	48.0	45.9	.677-.983	Break Points Converted (.089)	Total Points Won (.289)
1.6		Service, Return	54.5	62.9	.437-.970	Break Points Faced (.090)	Break Points Opportunities (.288)
1.7		Service, Return (%)	53.4	50.0	.609-.999	1st Serve Return Points Won (.053)	Return Games Won (.155)
2.1	ATP (300)	All	85.4	76.4	.891-.944	2nd Serve Points Won (.021)	Tournament Played (.129)
2.2		Service	81.7	84.2	.578-.999	Double Faults (.065)	Service Games Won (.207)
2.3		Service (%)	76.8	81.3	.689-.999	2nd Serve Points Won (.089)	Service Games Won (.294)
2.4		Return	82.1	78.1	.596-.960	Return Games Won (.053)	Return Points Won (.198)
2.5		Return (%)	77.9	80.2	.786-.997	Return Games Won (.092)	Total Points Won (.287)
2.6		Service, Return	77.0	84.5	.803-.954	Aces (.097)	Break Points Opportunities (.245)
2.7		Service, Return (%)	80.9	80.5	.486-.888	Break Points Converted (.048)	Break Points Saved (.196)
3.1 a	ATP (500)	All	95.2	96.8	.933-.993	Break Points Opportunities (.018)	Tournament Played (.176)
3.2		Service	90.4	94.8	.166-.999	Break Points Faced (.058)	Break Points Saved (.179)
3.3		Service (%)	91.9	91.6	.808-.999	Break Points Saved (.101)	Service Games Won (.321)
3.4		Return	92.7	90.7	.833-.892	Return Games Won (.061)	Return Points Won (.169)
3.5		Return (%)	91.0	95.1	.746-.682	Return Points Won (.113)	Return Games Won (.231)
3.6		Service, Return	93.2	88.0	.770-.926	Double Faults (.096)	Break Points Opportunities (.234)
3.7		Service, Return (%)	92.9	89.1	.786-.999	2nd Serve Points Won (.035)	Total Service Points Won (.161)
4.1	Prize money	All	86.8	39.5	-	1st Serve Points Won (.022)	Break Points Opportunities (.212)
4.2		Service	62.6	49.4	-	Service Games Played (.033)	Break Points Faced (.142)
4.3		Service (%)	26.5	28.7	-	1st Serve Points Won (.114)	2nd Serve Points Won (.283)
4.4		Return	47.3	47.3	-	Return Games Won (.028)	Total Points Won (.341)
4.5		Return (%)	47.8	61.3	-	2nd Serve Return Points Won (.033)	Total Points Won (.625)
4.6		Service, Return	91.9	51.5	-	Double Faults (.051)	Break Points Opportunities (.546)
4.7		Service, Return (%)	72.0	78.9	-	Total Points Won (.033)	Break Points Saved (.284)
5.1	Points	All	92.1	69.3		Service Games Played (.023)	Break Points Opportunities (.208)
5.2		Service	55.2	32.9	-	Service Games Won (.023)	Aces (.228)
5.3		Service (%)	21.5	31.3	-	Break Points Saved (.086)	1st Serve (.282)
5.4		Return	86.4	86.4	-	2nd Serve Return Points Won (.038)	Break Points Opportunities (.328)
5.5		Return (%)	41.0	24.2	-	Break Points Converted (.060)	Total Points Won (.413)
5.6		Service, Return	88.2	62.4	-	Double Faults (.029)	Break Points Opportunities (.567)
5.7		Service, Return (%)	67.5	54.3	-	1st Serve Points Won (.033)	1st Serve Return Points Won (.176)
Open in a new tab
Response variables Prize money and Points were treated as continuous variables (AUC results were not included); AUC is present in formed of range (minimum to maximum).

aResults after post-fine-tuning.

The average accuracy across all 35 generated models stood at 65.80±21.4. In the detailed analysis of the best generated models categorized by predictors (Fig 5), it is evident that results in the poorest models ranged from 24.2% (Return %) to 51.5% (Service, Return), while in the best models, they ranged from 88.0% (Service, Return) to 94.8% (Service). However, the predictor Return attained the best average result (72.9±18.0). Due to the inconsistency and insufficient validity of the results, we must state that we found ambiguous outcomes in the predictor-based categorization. The same, cannot be said based on the detailed analysis of the test validity results categorized by response (Fig 6). In this case, we found that the least valid models ranged from 24.2% (Points) to 88.0% (ATP 500). Models with the highest accuracy ranged from 62.9% (ATP 100) to 95.1% (ATP 500), and the model with the highest average value was ATP 500 (91.9±2.8). From this description, the clear dominance of predictive model accuracy in ATP 500 is apparent, where even the worst generated model achieved better accuracy than the best model in other generated AI models (diff = 1.6%).

When employing Service (%) and Return (%) as predictors to estimate Prize Money, this model achieved a test validity of 78.9%, albeit being an outlier value. With a larger dataset or more meticulous fine-tuning, this model could potentially attain higher accuracy. Consequently, it cannot be categorically deemed unusable, like the points predicting the model. Which, due to its considerable variability in test validity, we advise against its practical application.

When arranging all models based on their test validity, the models pertaining to ATP Rank (500) occupy the top (seven) positions, according to the test validation. These models are, therefore, unequivocally the most reliable and, in practice, the most useful models (mean = 91.91; SD = 2.83; min = 88.00; max = 95.1; γ1 = -0.18; γ2 = -1.80). The models associated with ATP (300) rank follow in the second position (mean = 80.74; SD = 2.96; min = 76.40; max = 84.50; γ1 = -0.05; γ2 = -0.86). However, it is worth noting that even the poorest-performing model within ATP (500) demonstrated better accuracy than the best-performing ATP (300) model (a difference of 1.6%), as mentioned earlier.

The AUC serves as a highly suitable metric for monitoring and interpreting results with categorical outcomes, as it quantifies predictive strength across different categories. For instance, using Model 1.4 as an example, it can be observed that the model can reliably predict categories 1 to 100 Rank based on the Return variable (AUC = .972). Conversely, for the outcome in the 801 to 900 Rank category, the prediction is unreliable (AUC = .528) and can be likened to a coin toss with a 50:50 chance of accuracy. Thus, it is important to emphasize that even though the best model achieved commendable validity (Model 3.5 with 95.1% accuracy), the AUC value could be interpreted as ranging from poor to fair. The second-most accurate model also faces a similar challenge (Model 3.2, failing to achieve excellence in AUC). It is only the third-most valid model, Model 3.1, with 94.1% accuracy, that can be classified as achieving excellent AUC across all outcome categories. The NN Model 3.1 demonstrated superior performance and was subsequently selected for fine-tuning, resulting in a training phase accuracy of 95.2% and a testing phase accuracy of 96.8%, with an AUC ranging from 0.933 to 0.993. Displayed in Fig 7 in ROC Curve form. The post-fine-tuning outcome values are presented in Table 4. The scheme of the neural network for model 3.1 after fine-tuning, illustrating the number and degree of relationship of the input variables, the number of hidden layers, types of activation functions, and the output variable, is included in the S1 Fig.

Fig 7. ROC Curve for best performing Model 3.1 (After post-fine-tuning).
Fig 7

Open in a new tab
The best NN model predicting continuous responses was Model 5.4, which predicted Points using all Return variables with an accuracy of 86.4%. Since the second least accurate model achieved only 78.9% accuracy, it can be concluded that Model 5.4 is unequivocally the best model for predicting continuous data.

Discussion
This study objectives involved employing classical and advanced statistical approach to quantify the importance of anthropometric, service-based, and return-based variables in relation to the categorized ATP rank of tennis players registered at the ATP association in season 2023.

Based on results from MANOVA testing, a strong effect size was found in the case of two DV. More precisely, 17.8% of the variance in the DV Service (%) can explained by the IV ATP (500) and 15.3% of the variance in the Service (%) can explained by the IV variable ATP (300). Service (in %) explained the largest variation in comparison with the other two DV (anthropometric characteristics and returns (in %).

A post hoc test for MANOVA reveals multiple statistically significant findings among categorized ATP ranks in the case of Age, Weight, and hand eight, where top players were older, heavier, and taller than players from other categorized ATP ranks (mostly the bottom ranks). For example, Age specificity in trainability should be considered when designing programs for long-term athlete development [8]. Analysing anthropometric variables is crucial in performance analysis because a player’s height has a significant impact on serve and return outcome [50], and also serve speed [23], which is a pivotal variable in predicting match success [31], or can be used as a predictor indicating a change in the opponent’s game strategies [33]. In addition, these variables also affect players’ fatigue and thus players’ tactics [37]. In this study, we also found that the average height of all registered ATP players in the 2022 season was 184.06±6.86 cm (max = 211 cm), with slightly negative Skewness of -0.19, indicating that players tend to have higher than average height. From a total of 1389 valid values, 473 (34.1%) players were taller than 186 cm, and 296 (21.3%) had less than 180 cm, which can negatively affect their chance to win a match [32], even if taller players had higher speed on 1st and 2nd serve [50]. Therefore, only 620 (44.6%) ATP players had the ideal height. It is important to note that there are also limits of effectiveness in the case of anthropometric characteristics and that these reference values are based on data from 1991–2008 (Grand Slam, men’s singles).

In the case of the Service-base variable, we did not find statistically significant results for 1st service (%), which contradicts the conclusions of other studies [31, 34, 35]. This can be explained by the general awareness of the importance of this variable, which tennis players become aware of and approach their game strategy and training accordingly. In contrast, we found that top tennis players have better results than others (mainly than the bottom ranked players) in the variables 1st service points won (%), Break Points Saved, Service games won, and Total service points won. These conclusions were already reported by other studies [31, 32, 38, 45, 50] and although they did not always analyze the same type of variables, we can characterize them as their alternatives. The dynamics of service variables can also be illustrated by the statistics at Wimbledon in the years 2002–2015, where service game efficiency (service games won, 1st and 2nd serve points won, and ace (%)) increased and double fault (%) decreased. At the same time, serve success (service game, 1st and 2nd serve points winning (%)) and serve performance (ace and double fault (%)) appear to be more important variables in the 2nd week of the tournament than in the 1st [51]. It is important to note that this study only dealt with service-base variables (not return-base).

In the case of the return-based variable, we found fewer statistically significant results compared to the Anthropometric-based and Service-based variables, which contradicts the study by Cui et al. [37], who observed a decreasing trend in the service-based variable and an increase in return-based variables during set-to-set variations in performance. These conclusions indicate the importance of return-based variables within one match, which, however, are less important within the analysis focused on another time period (performance). As key factors to determine the best players, we can mention the variables 1st Serve Return Points Won, Return Games Won, Return Points Won rank, Total Points Won, because in all these variables, the top players achieved better results than other tennis players from the ATP ranking. These conclusions are in agreement with other studies dealing with a similar topic [27, 34, 36, 46, 49]. It is also possible to conclude that during the match, there is a decrease in the importance of service-based (net play, running) variables and an increase in the importance of return-based variables in the last sets compared to the initial sets. This can be attributed to fatigue, the choice of tactics, and pacing [37], showing the dynamics of this variable.

However, anthropometric characteristics did not prove to be sufficiently good predictors, in the case of MLR, because we found only three statistically significant variables (in total of five different levels). Age, height, and Total Points Won are suitable variables for predicting ATP ranking. These results (compared to the results of MANOVA) can indicate that MLR is more sensitive to specific data characteristics, more complex patterns, or a strong correlation between predictors [58, 59]. Therefore, it is not appropriate to reduce the importance and practical suitability of statistically significant results from the MANOVA test on the basis of statistically insignificant results from the MLR. These are different methods by which test different things. Because inferential statistical technique such as MLR has shown problems with robustness within high-dimensional models, Machine learning techniques such as NN are more suitable for those tasks [60, 61].

Advancements in technology have enabled in-depth technical analyses. Makino et al. [40] utilized machine learning techniques to predict point winners, emphasizing the significance of specific shot analysis. Mergheş et al. [49] discussed the intricacies of technical skills, particularly focusing on the return of serve as a pivotal shot. Gillet et al. [27] emphasized the enduring importance of serves and serve-returns, even on slower surfaces like clay, in influencing match outcomes. The conclusions from this study also indicate that service-based and return-based variables are important and suitable variables for predicting outcomes. However, a much more important factor is the type and number of output variables for which the model was trained and tested, which is also pointed out by other authors [62–64]. Future NN architects should, therefore, consider the suitability and adequacy of the output variable, for which we recommend setting the smallest possible number of categorical output variables, e.g. Win/Loss; strategies initial/intermediate/intensive part of the match; ATP Rank (500). Then they can try to gradually increase the number of categories, or switch to continuous data prediction. If we compare our best-performing AI model 3.1 (predicting ATP (500) with all researched variables), which achieved 96.8% accuracy with an AUC range of 0.933 to 0.993 (after post-fine-tuning), we can claim that our AI model, utilizing Neural Networks, achieved superior predictive accuracy compared to Makino et al.’s [40] model. Makino et al. [40] employed L1-regularized logistic regression and achieved an accuracy of 66.5% with an AUC of 0.689 for predicting winners and valuable features. However, it is worth noting that our model has limited applicability early in the season, becoming more valid as the season progresses.

The popularity of tennis from the perspective of players, coaches, and stakeholders is influenced by the prospect of financial rewards in the form of prize money, which increases alongside competitiveness [65]. However, we found that 87.73% of the ATP players will not reach the average Prize money. Similar conclusions are also reported by Balliauw et al. [66], when they state that professional tennis players who are below the level of the top 250 rank have difficulty covering the financial expenses associated with their profession.

Limitations and directions for future research
Although the current study was based on 28 variables and encompassed a substantial amount of data (20,040 data points), there are numerous other approaches and variables that were not investigated in this study, such as the average serving speed or time-oriented variables. One future research direction could be the development of a predictive model that works with the game characteristics of tournament or match winners. However, this type of AI model would require training and testing using multiple variables that were not necessary to track in this study, such as the type of court, because this has a profound impact on players’ strategies. Tudor et al. [33] demonstrated varying player approaches on fast and slow courts, emphasizing adaptability. Cui et al. [36] discussed court-specific tactics, underlining the importance of baseline play and relative quality in diverse court environments. Furthermore, we recommend that variables such as tournament rounds (week), and game statistics from the initial, intermediate, and intensive part of the match should also be included in this AI model because these factors affect performance, fatigue, pacing, and game strategy and thus on the outcome of the match [37, 38]. This AI model could thus assist in determining an appropriate (initial, backup, or alternative) game strategy based on these pieces of information.

As a significant variable that could profoundly influence the accuracy and error rate of future AI models, we consider the technique of disguising strokes, a common strategy in elite-level tennis tournaments [3]. For this highly specific AI model, it would be appropriate to develop our own specialized CNN, capable of processing photographs and natural language, as well as analyzing, categorizing, and quantifying data acquired from video footage. The results from this model could subsequently serve as a control variable for another AI model and thus reduce its error rate and increase model accuracy. A similar type of AI model could also be used to predict first and second serve related to the target zone for ball impact [67].

In the current study, we focused solely on professional male tennis players and did not include women or juniors due to significant disparities in performance between professional and junior players, as emphasized by Kovalchik and Reid [35]. The research conducted by Reid et al. [46] and Kovalchik and Reid [35] showed that professional players have a significant advantage in serving, with male professionals winning 4% more points and female professionals winning 2% more points on serve compared to their junior counterparts. These differences in stroke dynamics, particularly in relation to the first serve and serve-return, and movement speeds, were highlighted by the study of Cui et al. [36], who stress the need for gender-specific training, practice designs, and AI modeling. Stare et al. [45] demonstrated that professional players focus more on offensive baseline play and achieve a higher number of aces with their first serve. Pereira et al. [47] also noted that young players spend more time in the serving phase, whereas professionals spend more time in the returning phase. These differences in gameplay and physical characteristics of shots between junior and professional tennis players underscore the necessity for differentiated training methods, gender-specific, and performance-level specific approaches, which is the primary reason for limiting this study to professional male tennis players. Otherwise, one would expect a much larger error rate in inferential statistics and a lower predictive accuracy of AI models.

Conclusion
In conclusion, our study has yielded valuable insights into predicting tennis players’ rankings on the ATP Rank through various analytical approaches.

From the results of descriptive statistics, it can be concluded that there are significant implications for tennis players. The data suggests that focusing on accumulating minimal points across multiple tournaments, without a comprehensive approach, may offer valuable experience to players. However, this strategy does not lead to substantial financial gains or higher rankings. Players aspiring to achieve higher standings in the ATP rankings should consider adopting a more strategic and focused approach to their tournament participation and gameplay. While it might seem logical to assume that the top players earn the most Prize money, the data provides evidence of a significant disparity in Prize money across the dataset. This is indicated by the Skewness and Kurtosis coefficients, reflecting a right-skewed data distribution and a more peaked frequency distribution, respectively. These results indicate that tennis can be a highly profitable sport, but only for a small percentage of the best players (%). For this select group, tournament income is sufficient. However, for the remaining players, it proved to be insufficient in the year 2022.

In the MANOVA analysis, we observed numerous statistically significant differences among various player statistics, emphasizing the need to consider multiple variables rather than focusing on a single one. This multifaceted approach allows us to categorize variables based on their importance, providing a more comprehensive understanding of their impact on ATP rankings. Notably, certain performance metrics, such as 1st Serve Return Points Won, exhibited limited predictive power due to their fluctuating nature. In contrast, other metrics, including 1st Serve Return Points Won, Return Games Won, and Return Points Won rank, consistently distinguished players in higher rankings from those in lower positions. Total Points Won emerged as a robust predictor, demonstrating a clear linear trend towards superior performance in lower-ranked players.

The MLR analysis examined the determinants of ATP Rank outcomes, focusing on anthropometric characteristics, service-related factors, and return statistics. Notably, Age and Height variables displayed statistical significance within different ATP Rank categorizations, highlighting their substantial influence on player rankings. In the realm of service-related factors, specific metrics such as 1st Serve Points Won, 2nd Serve Points Won, and Service Games Played exhibited statistical significance in various ATP categorizations (100, 300, 500), emphasizing the critical role of service performance in ATP Rank outcomes. Return statistics yielded fewer statistically significant results, with Total Points Won emerging as a significant variable in the ATP 100 category. Parameter Estimates revealed five key statistically significant findings, reinforcing the significance of Age, Height, and Total Points Won in shaping player rankings across various ATP Rank categories. These results indicate that older ATP tennis players are more likely to secure positions among the top 100 ATP players, and height positively influences ranking outcomes. In summary, the MLR analysis elucidated the pivotal roles of age and height in shaping the rankings of professional tennis players. These insights offer actionable information for coaches, players, and stakeholders, facilitating the optimization of training strategies and performance assessment within the professional tennis domain.

Our Neural Network analysis for multiple variables associated with ATP Rank assessment delivered several key insights. Models associated with ATP Rank (500) exhibited superior test validity, with the best model achieving up to 95.1% accuracy, highlighting their predictive power. Furthermore, the first two less accurate models were deemed inadequate on model performance across different outcome categories (according to AUC), while model 3.1 (utilizing all variables as predictors), with 96.8% accuracy (after post-fine-tuning), was identified as the most valid model. In conclusion, Neural Network models have demonstrated the potential to predict outcomes associated with ATP Rank assessment, with ATP Rank (500) models being particularly promising. Further refinement and optimization of these models has the potential to provide valuable insights for analysts and coaches in the tennis domain, aiding their understanding of factors influencing player rankings and improving the accuracy of predictive models.

Overall, our study contributes to a deeper understanding of the factors influencing ATP rankings and provides practical implications for enhancing training strategies and performance assessment in the realm of professional tennis. These findings underscore the significance of specific performance metrics in assessing tennis players’ success and predicting their rankings. Coaches, players and stakeholders can use these insights to tailor training strategies and improve their understanding of the key factors influencing competitive performance. Furthermore, ongoing research and refinement of predictive variables have the potential to improve ranking predictions, facilitating more informed decision-making and performance optimization in professional tennis.

Because there are so many possible linear and nonlinear interactions that cannot be effectively monitored, the use of AI in tennis, which is capable of handling these complexities when properly configured and trained, is highly promising. We believe that in the future, it will be utilized more extensively, not only in tennis but also in various other domains where the outcome depends on numerous different variables, all of which are accessible and measurable. A viable solution involves combining multiple AI models that are interconnected. However, it is crucial to emphasize that while AI is a suitable and powerful tool, it always remains just that—a tool to assist decision-making. The ultimate decision should be carefully considered and made by experienced individuals.

Ethical statement
Given that this research exclusively relied on secondary (freely available) data, formal approval from an ethical review board was not deemed necessary. Nonetheless, ethical considerations remained a top priority throughout the study. The utilization of AI, AI-assisted, and Machine Learning technologies adhered to ethical guidelines and standards. The research design, data collection, and analysis processes were executed with integrity and transparency. Potential conflicts of interest were disclosed, and every effort was made to present the results objectively and without bias.

Supporting information
S1 Fig. The Neural Network diagram for 3.1 model.
(TIF)

pone.0309085.s001.tif (3.2MB, tif)
Acknowledgments
In this study, we utilized AI, AI-assisted, and Machine Learning technologies to address the research objectives. We declare that the deployment of these technologies was conducted methodically, under controlled conditions, and adhering to ethical standards, with subsequent result verification by all authors. Our commitment to transparency extends to the assurance that the ethical aspects of our approach were rigorously implemented, and the results were thoroughly scrutinized collectively by the research team.

Data Availability
The dataset supporting the study results can be found on figshare at https://doi.org/10.6084/m9.figshare.24763872.v1. The NN code of the best-performing model can be found on figshare at https://doi.org/10.6084/m9.figshare.24762705.v1.

Funding Statement
The author(s) received no specific funding for this work.

References
1.Ward P, Williams AM, Bennett SJ. Visual Search and Biological Motion Perception in Tennis. Res Q Exerc Sport. 2002;73: 107–112. doi: 10.1080/02701367.2002.10608997 [DOI] [PubMed] [Google Scholar]
2.Shim J, Carlton LG, Chow JW, Chae W-S. The Use of Anticipatory Visual Cues by Highly Skilled Tennis Players. J Mot Behav. 2005;37: 164–175. doi: 10.3200/JMBR.37.2.164-175 [DOI] [PubMed] [Google Scholar]
3.Dimic M, Furuya R, Kanosue K. Importance of disguising groundstrokes in a match between two top tennis players (Federer and Djokovic). Int J Sports Sci Coach. 2023;18: 257–269. doi: 10.1177/17479541221075728 [DOI] [Google Scholar]
4.Hoskins T. The Tennis Drill Book. Human Kinetics; 2003. [Google Scholar]
5.Mann DTY, Williams AM, Ward P, Janelle CM. Perceptual-Cognitive Expertise in Sport: A Meta-Analysis. J Sport Exerc Psychol. 2007;29: 457–478. doi: 10.1123/jsep.29.4.457 [DOI] [PubMed] [Google Scholar]
6.Bartlett R. Performance analysis: can bringing together biomechanics and notational analysis benefit coaches? Int J Perform Anal Sport. 2001;1: 122–126. doi: 10.1080/24748668.2001.11868254 [DOI] [Google Scholar]
7.O’Donoghue P. Research Methods for Sports Performance Analysis. Routledge; 2010. [Google Scholar]
8.Lambrich J, Muehlbauer T. Effects of athletic training on physical fitness and stroke velocity in healthy youth and adult tennis players: A systematic review and meta-analysis. Front Sports Act Living. 2023;4. doi: 10.3389/fspor.2022.1061087 [DOI] [PMC free article] [PubMed] [Google Scholar]
9.Kovacs MS. Tennis physiology: training the competitive athlete. Sports Medicine. 2007;37: 189–198. doi: 10.2165/00007256-200737030-00001 [DOI] [PubMed] [Google Scholar]
10.Hughes M. The application of notational analysis to racket sports. In: Hughes M, Maynard I, Lees A, Reilly T, editors. Science and Racket Sports II. London: Taylor & Francis; 1998. pp. 211–220. doi: 10.4324/9780203474617 [DOI] [Google Scholar]
11.O’Donoghue P. Match analysis in racket sports. In: Lees A, Kahn J-F, Maynard IW, editors. Science and Racket Sports III. London: Routledge; 2004. pp. 155–162. [Google Scholar]
12.Liebermann DG, Katz L, Hughes MD, Bartlett RM, McClements J, Franks IM. Advances in the application of information technology to sport performance. J Sports Sci. 2002;20: 755–769. doi: 10.1080/026404102320675611 [DOI] [PubMed] [Google Scholar]
13.Takahashi H, Mitsuhashi S, Murakami S. Performance analysis in tennis since 2000: A systematic review focused on the methods of data collection. International Journal of Racket Sports Science. 2022;4: 40–55. doi: 10.30827/Digibug [DOI] [Google Scholar]
14.Ganser A, Hollaus B, Stabinger S. Classification of Tennis Shots with a Neural Network Approach. Sensors. 2021;21: 5703. doi: 10.3390/s21175703 [DOI] [PMC free article] [PubMed] [Google Scholar]
15.Fernandes M de A. Using Soft Computing Techniques for Prediction of Winners in Tennis Matches. Machine Learning Research. 2017;2: 86–98. doi: 10.11648/j.mlr.20170203.12 [DOI] [Google Scholar]
16.Whiteside D, Reid M. Spatial characteristics of professional tennis serves with implications for serving aces: A machine learning approach. J Sports Sci. 2017;35: 648–654. doi: 10.1080/02640414.2016.1183805 [DOI] [PubMed] [Google Scholar]
17.Lambrich J, Muehlbauer T. Biomechanical analyses of different serve and groundstroke techniques in tennis: A systematic scoping review. PLoS One. 2023;18: e0290320. doi: 10.1371/journal.pone.0290320 [DOI] [PMC free article] [PubMed] [Google Scholar]
18.Colomar J, Corbi F, Baiget E. Improving Tennis Serve Velocity: Review of Training Methods and Recommendations. Strength Cond J. 2023;45: 385–394. doi: 10.1519/SSC.0000000000000733 [DOI] [Google Scholar]
19.Kovacs MS, Ellenbecker TS. A Performance Evaluation of the Tennis Serve: Implications for Strength, Speed, Power, and Flexibility Training. Strength Cond J. 2011;33: 22–30. doi: 10.1519/SSC.0b013e318225d59a [DOI] [Google Scholar]
20.O’Donoghue P, Brown E. The Importance of Service in Grand Slam Singles Tennis. Int J Perform Anal Sport. 2008;8: 70–78. doi: 10.1080/24748668.2008.11868449 [DOI] [Google Scholar]
21.Chang C-W, Qiu Y-R. Constructing a Gaming Model for Professional Tennis Players Using the C5.0 Algorithm. Applied Sciences. 2022;12: 8222. doi: 10.3390/app12168222 [DOI] [Google Scholar]
22.Avilés C, Navia JA, Ruiz LM, Martínez de Quel Ó. Do expert tennis players actually demonstrate anticipatory behavior when returning a first serve under representative conditions? A systematic review including quality assessment and methodological recommendations. Psychol Sport Exerc. 2019;43: 16–26. doi: 10.1016/j.psychsport.2018.12.015 [DOI] [Google Scholar]
23.Vaverka F, Cernosek M. Association between body height and serve speed in elite tennis players. Sports Biomech. 2013;12: 30–37. doi: 10.1080/14763141.2012.670664 [DOI] [PubMed] [Google Scholar]
24.O’Donoghue P. The Most Important Points in Grand Slam Singles Tennis. Res Q Exerc Sport. 2001;72: 125–131. doi: 10.1080/02701367.2001.10608942 [DOI] [PubMed] [Google Scholar]
25.Klaus A, Bradshaw R, Young W, O’Brien B, Zois J. Success in national level junior tennis: Tactical perspectives. Int J Sports Sci Coach. 2017;12: 618–622. doi: 10.1177/1747954117727792 [DOI] [Google Scholar]
26.O’Donoghue P, Ingram B. A notational analysis of elite tennis strategy. J Sports Sci. 2001;19: 107–115. doi: 10.1080/026404101300036299 [DOI] [PubMed] [Google Scholar]
27.Gillet E, Leroy D, Thouvarecq R, Stein J-F. A Notational Analysis of Elite Tennis Serve and Serve-Return Strategies on Slow Surface. J Strength Cond Res. 2009;23: 532–539. doi: 10.1519/JSC.0b013e31818efe29 [DOI] [PubMed] [Google Scholar]
28.Connaghan D, Moran K, O’Connor NE. An automatic visual analysis system for tennis. Proc Inst Mech Eng P J Sport Eng Technol. 2013;227: 273–288. doi: 10.1177/1754337112469330 [DOI] [Google Scholar]
29.Polk T, Yang J, Hu Y, Zhao Y. TenniVis: Visualization for Tennis Match Analysis. IEEE Trans Vis Comput Graph. 2014;20: 2339–2348. doi: 10.1109/TVCG.2014.2346445 [DOI] [PubMed] [Google Scholar]
30.Lara JPR, Vieira CLR, Misuta MS, Moura FA, Barros RML de. Validation of a video-based system for automatic tracking of tennis players. Int J Perform Anal Sport. 2018;18: 137–150. doi: 10.1080/24748668.2018.1456886 [DOI] [Google Scholar]
31.Djurovic N, Lozovina V, Pavicic L. Evaluation of Tennis Match Data—New Acquisition Model. J Hum Kinet. 2009;21: 15–21. doi: 10.2478/v10078-09-0002-9 [DOI] [Google Scholar]
32.Ma S-M, Liu C-C, Tan Y, Ma S-C. Winning matches in Grand Slam men’s singles: An analysis of player performance-related variables from 1991 to 2008. J Sports Sci. 2013;31: 1147–1155. doi: 10.1080/02640414.2013.775472 [DOI] [PubMed] [Google Scholar]
33.Tudor PB, Zeić M, Matković B. Differences between 2010 and 2011 performance indicators of tennis play at the grand slam tournaments. Kinesiology: international journal of fundamental and applied kinesiology. 2014;46: 102–107. Available: https://api.semanticscholar.org/CorpusID:141512027 [Google Scholar]
34.Filipcic A, Zecic M, Crespo M, Panjan A, Sarabon N. Differences in performance indicators of elite tennis players in the period 1991–2010. Journal of Physical Education and Sport. 2015;15: 671–677. [Google Scholar]
35.Kovalchik SA, Reid M. Comparing Matchplay Characteristics and Physical Demands of Junior and Professional Tennis Athletes in the Era of Big Data. J Sports Sci Med. 2017;16: 489–497. [PMC free article] [PubMed] [Google Scholar]
36.Cui Y, Gómez M-Á, Gonçalves B, Sampaio J. Performance profiles of professional female tennis players in grand slams. PLoS One. 2018;13: e0200591. doi: 10.1371/journal.pone.0200591 [DOI] [PMC free article] [PubMed] [Google Scholar]
37.Cui Y, Liu H, Gómez M-Á, Liu H, Gonçalves B. Set-to-set Performance Variation in Tennis Grand Slams: Play with Consistency and Risks. J Hum Kinet. 2020;73: 153–163. doi: 10.2478/hukin-2019-0140 [DOI] [PMC free article] [PubMed] [Google Scholar]
38.Damani C, Damani B, Bagchi A. Match statistics significant to win the initial and intense rounds of a tennis tournament. Trends Sport Sci. 2020;27: 225–231. [Google Scholar]
39.Fernández-Garcia AI, Gimenez-Egido JM, Torres-Luque G. Differences in Grand Slam competition statistics between professional and U-18 players according to the sex. [Diferencias en las estadísticas de competición de Grand Slam entre jugadores profesionales y Sub-18 según el género]. RICYDE Revista internacional de ciencias del deporte. 2021;17: 25–37. doi: 10.5232/ricyde2021.06303 [DOI] [Google Scholar]
40.Makino M, Odaka T, Kuroiwa J, Suwa I, Shirai H. Feature Selection to Win the Point of ATP Tennis Players Using Rally Information. Int J Comput Sci Sport. 2020;19: 37–50. doi: 10.2478/ijcss-2020-0003 [DOI] [Google Scholar]
41.Carboch J, Blau M, Sklenarik M, Siman J, Placha K. Ball change in tennis: How does it affect match characteristics and rally pace in Grand Slam tournaments? Journal of Human Sport and Exercise. 2019;15. doi: 10.14198/jhse.2020.151.14 [DOI] [Google Scholar]
42.Edelmann-Nusser A, Raschke A, Bentz A, Montenbruck S, Edelmann-Nusser J, Lames M. Validation of Sensor-Based Game Analysis Tools in Tennis. Int J Comput Sci Sport. 2019;18: 49–59. doi: 10.2478/ijcss-2019-0013 [DOI] [Google Scholar]
43.Schmidhofer S, Leser R, Ebert M. A comparison between the structure in elite tennis and kids tennis on scaled courts (Tennis 10s). Int J Perform Anal Sport. 2014;14: 829–840. doi: 10.1080/24748668.2014.11868761 [DOI] [Google Scholar]
44.Fitzpatrick A, Davids K, Stone JA. Effects of Lawn Tennis Association mini tennis as task constraints on children’s match-play characteristics. J Sports Sci. 2017;35: 2204–2210. doi: 10.1080/02640414.2016.1261179 [DOI] [PubMed] [Google Scholar]
45.Stare M, Zibrat U, Filipcic A. Stroke effectivness in professional and junior tennis [ucinkovitost udarcev v profesionalnem in mladinskem tenisu]. Kinesiologia Slovenica. 2015;21: 39–50. Available: https://www.proquest.com/scholarly-journals/stroke-effectivness-professional-junior-tennis/docview/1764881922/se-2?accountid=16531 [Google Scholar]
46.Reid M, Morgan S, Whiteside D. Matchplay characteristics of Grand Slam tennis: implications for training and conditioning. J Sports Sci. 2016;34: 1791–1798. doi: 10.1080/02640414.2016.1139161 [DOI] [PubMed] [Google Scholar]
47.Pereira TJC, van Emmerik REA, Misuta MS, Barros RML, Moura FA. Interpersonal coordination analysis of tennis players from different levels during official matches. J Biomech. 2018;67: 106–113. doi: 10.1016/j.jbiomech.2017.11.036 [DOI] [PubMed] [Google Scholar]
48.Hizan H, Whipp P, Reid M. Comparison of serve and serve return statistics of high performance male and female tennis players from different age-groups. Int J Perform Anal Sport. 2011;11: 365–375. doi: 10.1080/24748668.2011.11868556 [DOI] [Google Scholar]
49.Mergheş PE, Simion B, Nagel A. Comparative Analysis of Return of Serve as Counter-attack in Modern Tennis. Timisoara Physical Education and Rehabilitation Journal. 2014;6: 18–22. doi: 10.2478/tperj-2014-0023 [DOI] [Google Scholar]
50.Söğüt M. Stature: Does it really make a difference in match-play outcomes among professional tennis players? Int J Perform Anal Sport. 2018;18: 255–261. doi: 10.1080/24748668.2018.1466259 [DOI] [Google Scholar]
51.Grambow R O’Shannessy C, Born P, Meffert D, Vogt T. Serve efficiency developments at Wimbledon between 2002 and 2015: a longitudinal approach to impact tomorrow’s tennis practice. Human Movement. 2020;21: 65–72. doi: 10.5114/hm.2020.88155 [DOI] [Google Scholar]
52.Kim H, Cai F, Ryu J, Haddad JM, Zelaznik HN. Tennis match time Series do not exhibit long term correlations. Int J Sport Psychol. 2015;46: 542–554. [Google Scholar]
53.Wilson RS, David GK, Murphy SC, Angilletta MJ, Niehaus AC, Hunter AH, et al. Skill not athleticism predicts individual variation in match performance of soccer players. Proceedings of the Royal Society B: Biological Sciences. 2017;284: 20170953. doi: 10.1098/rspb.2017.0953 [DOI] [PMC free article] [PubMed] [Google Scholar]
54.Vaverka F, Nykodym J, Hendl J, Zhanel J, Zahradnik D. Association between serve speed and court surface in tennis. Int J Perform Anal Sport. 2018;18: 262–272. doi: 10.1080/24748668.2018.1467995 [DOI] [Google Scholar]
55.Cohen J. Statistical power analysis for the behavioral sciences. 2nd ed. Hillsdale: Lawrence Erlbaum Associates; 1988. [Google Scholar]
56.Anonymized. NN 3.1 model. Fi gshare. 2023. doi: 10.6084/m9.figshare.24762705.v1 [DOI] [Google Scholar]
57.Safari S, Baratloo A, Elfil M, Negida A. Evidence Based Emergency Medicine; Part 5 Receiver Operating Curve and Area under the Curve. Emergency. 2016;4: 111–113. Available: www.jemerg.com [PMC free article] [PubMed] [Google Scholar]
58.Hernandez J, Lobos G, Matus I, del Pozo A, Silva P, Galleguillos M. Using Ridge Regression Models to Estimate Grain Yield from Field Spectral Data in Bread Wheat (Triticum Aestivum L.) Grown under Three Water Regimes. Remote Sens (Basel). 2015;7: 2109–2126. doi: 10.3390/rs70202109 [DOI] [Google Scholar]
59.Lazaridis DC, Verbesselt J, Robinson AP. Penalized regression techniques for prediction: a case study for predicting tree mortality using remotely sensed vegetation indices. Canadian Journal of Forest Research. 2011;41: 24–34. doi: 10.1139/X10-180 [DOI] [Google Scholar]
60.Fei S, Xu D, Chen Z, Xiao Y, Ma Y. MLR-based feature splitting regression for estimating plant traits using high-dimensional hyperspectral reflectance data. Field Crops Res. 2023;293: 108855. doi: 10.1016/j.fcr.2023.108855 [DOI] [Google Scholar]
61.Wang J, Shi T, Yu D, Teng D, Ge X, Zhang Z, et al. Ensemble machine-learning-based framework for estimating total nitrogen concentration in water using drone-borne hyperspectral imagery of emergent plants: A case study in an arid oasis, NW China. Environmental Pollution. 2020;266: 115412. doi: 10.1016/j.envpol.2020.115412 [DOI] [PubMed] [Google Scholar]
62.Lin J, Short L, Sundaresan V. Predicting National Basketball Association Winners. CS 229 FINAL PROJECT. 2014; 1–5. Available: https://cs229.stanford.edu/proj2014/Jasper%20Lin,%20Logan%20Short,%20Vishnu%20Sundaresan,%20Predicting%20National%20Basketball%20Association%20Game%20Winners.pdf [Google Scholar]
63.Horvat T, Job J. The use of machine learning in sport outcome prediction: A review. Wiley Interdiscip Rev Data Min Knowl Discov. 2020;10. doi: 10.1002/widm.1380 [DOI] [Google Scholar]
64.Bozděch M, Vychodilová R. Evaluation of neural network feature and function settings on the model performance and accuracy. Journal of Physical Education and Sport. 2023;23: 983–989. doi: 10.7752/jpes.2023.04123 [DOI] [Google Scholar]
65.Feldman D, Gross ST, Long Y. Gender Competitiveness and Predictability, and Prize Money in Grand Slam Tennis Tournaments. Quarterly Journal of Finance. 2020;10: 2050006. doi: 10.1142/S2010139220500068 [DOI] [Google Scholar]
66.Balliauw M, Verlinden T, Van Den Spiegel T, Van Hecke J. How to achieve a sustainable circuit for professional tennis players? International Journal of Sport Management and Marketing. 2023;23: 391–418. doi: 10.1504%2FIJSMM.2023.133162 [Google Scholar]
67.Vacek J, Vagner M, Cleather DJ, Stastny P. A Systematic Review of Spatial Differences of the Ball Impact within the Serve Type at Professional and Junior Tennis Players. Applied Sciences. 2023;13: 3586. doi: 10.3390/app13063586 [DOI] [Google Scholar]
PLoS One. doi: 10.1371/journal.pone.0309085.r001
Decision Letter 0
Qichun Zhang
Author information
Copyright and License information
12 Jun 2024

PONE-D-24-05081A detailed Analysis of Game Statistics of professional tennis players: An Inferential and Machine Learning ApproachPLOS ONE

Dear Dr. Bozděch,

Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.

==============================

ACADEMIC EDITOR: Please address all the comments and a proof reading is highly recommended.==============================

Please submit your revised manuscript by Jul 27 2024 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at plosone@plos.org. When you're ready to submit your revision, log on to https://www.editorialmanager.com/pone/ and select the 'Submissions Needing Revision' folder to locate your manuscript file.

Please include the following items when submitting your revised manuscript:

A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.

A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.

An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.

If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.

If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at https://plos.org/protocols?utm_medium=editorial-email&utm_source=authorletters&utm_campaign=protocols.

We look forward to receiving your revised manuscript.

Kind regards,

Qichun Zhang, PhD

Academic Editor

PLOS ONE

Journal Requirements:

1. When submitting your revision, we need you to address these additional requirements.

Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at 

https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf and 

https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf.

2. Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, all author-generated code must be made available without restrictions upon publication of the work. Please review our guidelines at https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code and ensure that your code is shared in a way that follows best practice and facilitates reproducibility and reuse.

3. Thank you for uploading your study's underlying data set. Unfortunately, the repository you have noted in your Data Availability statement does not qualify as an acceptable data repository according to PLOS's standards.

At this time, please upload the minimal data set necessary to replicate your study's findings to a stable, public repository (such as figshare or Dryad) and provide us with the relevant URLs, DOIs, or accession numbers that may be used to access these data. For a list of recommended repositories and additional information on PLOS standards for data deposition, please see https://journals.plos.org/plosone/s/recommended-repositories.

Additional Editor Comments:

The main issue has been noticed by the reviewers is the writing problem. The manuscript has not been organised well and the contents are not clear. The motivation of the research work is not described well and the results lack of analysis. Thus, a proof reading is needed to clarify the concerns from the reviewers and the innovation should be highlighted clearly in the revised version.

Reviewers' comments:

Reviewer's Responses to Questions

Comments to the Author

1. Is the manuscript technically sound, and do the data support the conclusions?

The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented.

Reviewer #1: Yes

Reviewer #2: No

Reviewer #3: Yes

**********

2. Has the statistical analysis been performed appropriately and rigorously?

Reviewer #1: Yes

Reviewer #2: No

Reviewer #3: Yes

**********

3. Have the authors made all data underlying the findings in their manuscript fully available?

The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.

Reviewer #1: Yes

Reviewer #2: No

Reviewer #3: Yes

**********

4. Is the manuscript presented in an intelligible fashion and written in standard English?

PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.

Reviewer #1: Yes

Reviewer #2: No

Reviewer #3: Yes

**********

5. Review Comments to the Author

Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)

Reviewer #1: Figure 7 Writing is not clear.

language article clear, correct.

The article is in pdf version

If the word would be better for me to confirm some things, it should be more justified .

In all tables follow the same guidelines for formatting.

Reviewer #2: The abstract needs to be specific on how the data was collected with the design of the study

The introduction needs to be redone. Line 43 is not clear . what does these mean .the introduction has all mixed information which does not clearly show what the authors are focusing at. the aim of research is not clear.

Reviewer #3: I respect the effort been made from the author. The abstract introduces the significance of using Artificial Intelligence, specifically Neural Networks to help ATP ranking with using all factors of ATP's ranking, instead of going through long process. I can see this paper was written well, but the author need to add more information in (Statistical analysis section) in Utilizing the Multivariate Analysis of Variance.

Also, the section(Neural Network Analysis of Multivariate Outcomes Associated

514 with ATP Rank) lacks some details, and need to be more clear.

other than that I can see all other information been added as it should be.

**********

6. PLOS authors have the option to publish the peer review history of their article (what does this mean?). If published, this will include your full peer review and any attached files.

If you choose “no”, your identity will remain anonymous but your review may still be made public.

Do you want your identity to be public for this peer review? For information about this choice, including consent withdrawal, please see our Privacy Policy.

Reviewer #1: Yes: ALI ALOUI

Reviewer #2: No

Reviewer #3: No

**********

While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, https://pacev2.apexcovantage.com/. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at figures@plos.org. Please note that Supporting Information files do not need this step.

PLoS One. 2024 Nov 5;19(11):e0309085. doi: 10.1371/journal.pone.0309085.r002
Author response to Decision Letter 0
Article notes
Copyright and License information
25 Jun 2024

Thank you for your time and feedback. We believe that your comments make the current version of the manuscript much better than the original one.

Attachment
Submitted filename: Response to Reviewers.docx

pone.0309085.s002.docx (31.6KB, docx)
PLoS One. doi: 10.1371/journal.pone.0309085.r003
Decision Letter 1
Qichun Zhang
Author information
Copyright and License information
6 Aug 2024

A detailed Analysis of Game Statistics of professional tennis players: An Inferential and Machine Learning Approach

PONE-D-24-05081R1

Dear Dr. Bozděch,

We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.

Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.

An invoice will be generated when your article is formally accepted. Please note, if your institution has a publishing partnership with PLOS and your article meets the relevant criteria, all or part of your publication costs will be covered. Please make sure your user information is up-to-date by logging into Editorial Manager at Editorial Manager® and clicking the ‘Update My Information' link at the top of the page. If you have any questions relating to publication charges, please contact our Author Billing department directly at authorbilling@plos.org.

If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.

Kind regards,

Qichun Zhang, PhD

Academic Editor

PLOS ONE

Additional Editor Comments:

2 reviewers out of 3 returned the review reports. Both of them believe that the paper can be published while the quality has been improved after the revision. One reviewer for the original submission has declined the invitation twice, due to the time issue, the decision is made without reviewer 2's comments.

Reviewers' comments:

Reviewer's Responses to Questions

Comments to the Author

1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.

Reviewer #1: All comments have been addressed

Reviewer #3: All comments have been addressed

**********

2. Is the manuscript technically sound, and do the data support the conclusions?

The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented.

Reviewer #1: Yes

Reviewer #3: Yes

**********

3. Has the statistical analysis been performed appropriately and rigorously?

Reviewer #1: Yes

Reviewer #3: Yes

**********

4. Have the authors made all data underlying the findings in their manuscript fully available?

The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.

Reviewer #1: Yes

Reviewer #3: Yes

**********

5. Is the manuscript presented in an intelligible fashion and written in standard English?

PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.

Reviewer #1: Yes

Reviewer #3: Yes

**********

6. Review Comments to the Author

Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)

Reviewer #1: (No Response)

Reviewer #3: All comments that been sent to authors were addressed. Authors did follow all comments. I believe now the manuscript is ready to be published. Moreover, I see that the paper will be helpful in the future as reference.

**********

7. PLOS authors have the option to publish the peer review history of their article (what does this mean?). If published, this will include your full peer review and any attached files.

If you choose “no”, your identity will remain anonymous but your review may still be made public.

Do you want your identity to be public for this peer review? For information about this choice, including consent withdrawal, please see our Privacy Policy.

Reviewer #1: Yes: Dr.ALI ALOUI

Reviewer #3: No

**********

PLoS One. doi: 10.1371/journal.pone.0309085.r004
Acceptance letter
Qichun Zhang
Author information
Copyright and License information
15 Aug 2024

PONE-D-24-05081R1

PLOS ONE

Dear Dr. Bozděch,

I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now being handed over to our production team.

At this stage, our production department will prepare your paper for publication. This includes ensuring the following:

* All references, tables, and figures are properly cited

* All relevant supporting information is included in the manuscript submission,

* There are no issues that prevent the paper from being properly typeset

If revisions are needed, the production department will contact you directly to resolve them. If no revisions are needed, you will receive an email when the publication date has been set. At this time, we do not offer pre-publication proofs to authors during production of the accepted work. Please keep in mind that we are working through a large volume of accepted articles, so please give us a few weeks to review your paper and let you know the next and final steps.

Lastly, if your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.

If we can help with anything else, please email us at customercare@plos.org.

Thank you for submitting your work to PLOS ONE and supporting open access.

Kind regards,

PLOS ONE Editorial Office Staff

on behalf of

Prof. Qichun Zhang

Academic Editor

PLOS ONE

Associated Data
This section collects any data citations, data availability statements, or supplementary materials included in this article.

Supplementary Materials
S1 Fig. The Neural Network diagram for 3.1 model.
(TIF)

pone.0309085.s001.tif (3.2MB, tif)
Attachment
Submitted filename: Response to Reviewers.docx

pone.0309085.s002.docx (31.6KB, docx)
Data Availability Statement
The dataset supporting the study results can be found on figshare at https://doi.org/10.6084/m9.figshare.24763872.v1. The NN code of the best-performing model can be found on figshare at https://doi.org/10.6084/m9.figshare.24762705.v1.

Articles from PLOS ONE are provided here courtesy of PLOS

ACTIONS
View on publisher site
PDF (1.7 MB)

Cite

Collections

Permalink
RESOURCES
Similar articles
Cited by other articles
Links to NCBI Databases
On this page
Abstract
Introduction
Materials and methods
Results
Discussion
Conclusion
Ethical statement
Supporting information
Acknowledgments
Data Availability
Funding Statement
References
Decision Letter 0
Author response to Decision Letter 0
Decision Letter 1
Acceptance letter
Associated Data

Follow NCBI
NCBI on X (formerly known as Twitter)
NCBI on Facebook
NCBI on LinkedIn
NCBI on GitHub
NCBI RSS feed
Connect with NLM

NLM on X (formerly known as Twitter)
NLM on Facebook
NLM on YouTube
National Library of Medicine
8600 Rockville Pike
Bethesda, MD 20894

Web Policies
FOIA
HHS Vulnerability Disclosure
Help
Accessibility
Careers
NLM
NIH
HHS
USA.gov
Tell us what you think!
```

```
Skip to main content

An official website of the United States government

Here's how you know

                                  NCBI home page
                              
Search

Log in
Primary site navigation
Search PMC Full-Text Archive
Search PMC Full-Text Archive

Search in PMC
Advanced Search 
Journal List 
User Guide
As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.
Learn more: PMC Disclaimer | PMC Copyright Notice
Sensors (Basel, Switzerland) logo
Sensors (Basel). 2021 Aug 24;21(17):5703. doi: 10.3390/s21175703
Classification of Tennis Shots with a Neural Network Approach
Andreas Ganser 1, Bernhard Hollaus 1,*, Sebastian Stabinger 2
Editor: Anthony Fleury
Author information
Article notes
Copyright and License information
PMCID: PMC8433919  PMID: 34502593
Abstract
Data analysis plays an increasingly valuable role in sports. The better the data that is analysed, the more concise training methods that can be chosen. Several solutions already exist for this purpose in the tennis industry; however, none of them combine data generation with a wristband and classification with a deep convolutional neural network (CNN). In this article, we demonstrate the development of a reliable shot detection trigger and a deep neural network that classifies tennis shots into three and five shot types. We generate a dataset for the training of neural networks with the help of a sensor wristband, which recorded 11 signals, including an inertial measurement unit (IMU). The final dataset included 5682 labelled shots of 16 players of age 13–70 years, predominantly at an amateur level. Two state-of-the-art architectures for time series classification (TSC) are compared, namely a fully convolutional network (FCN) and a residual network (ResNet). Recent advances in the field of machine learning, like the Mish activation function and the Ranger optimizer, are utilized. Training with the rather inhomogeneous dataset led to an F1 score of 96% in classification of the main shots and 94% for the expansion. Consequently, the study yielded a solid base for more complex tennis analysis tools, such as the indication of success rates per shot type.

Keywords: deep learning, wearable computing, activity recognition, tennis shot classification

1. Introduction
In society, interest is growing in monitoring physical performance in everyday life as well as in sports. Sales of wearable devices, such as fitness trackers or chest straps, have been growing tremendously over the last decade [1]. The mainstream solutions focus on supervising heart rate and motion recognition (e.g., step counters or position tracking with the help of inertial measurement units (IMU) and global positioning systems (GPS) [2]). As stated in [3,4,5,6,7], IMUs, in particular, are frequently used to collect information about training progress and general sports analytics. Analysing this data helps with improving the training specificity and preventing injuries [8,9].

For training purposes on a competitive level, more advanced sport-specific solutions are needed. In swing based sports, such as tennis, badminton, and squash, the shot performance is valuable information to develop better training and game plans. How interesting would it be if the worn smartwatch could tell the tennis player how fast their fastest service was during the last match? If this information is combined with the success rate of the respective shot type, insights for the next training session could be obtained. The prerequisite for such a sophisticated analysis is the reliable detection and classification of tennis shots, which is the topic of this study.

1.1. Market Analysis
The market already provides several solutions for tennis shot analysis. They can be grouped into three categories:

(1)Camera-based analysis tools, such as PlaySight [10], have a high shot recognition rate and can enable detailed evaluations depending on the complexity of the algorithm. The drawback of this technology is its high price [11]. Hence, these systems are not widespread and are mostly used by players who are on a professional level. Vision recognition tools are not further considered in this study since the solution should, in the long run, be available for a broad audience.
(2)Racket integrated solutions, provided by tennis racket manufacturers, are cheaper than the previous technology, but lack in recognition accuracy [11]. An associated study [12] using the Pan Tompkins algorithm for shot detection and time warping for shot classification achieved an accuracy close to 96%. Nevertheless, the sensors were fixed to a racket and were, therefore, non-mobile. Additionally, the recognition of topspin and backspin has an accuracy of only 80%. Furthermore, the attachment of sensors to the racket changes the fine-tuned centre of mass.
(3)Wrist-worn wearables, using the dynamic time warping (DTW) algorithm [13,14], can achieve a shot classification accuracy of up to 99%, but remain close to 80% for topspin and backspin detection [15]. Another technology for wrist wearables compared neural network approaches to feature recognition and reached a success rate of 94% for groundstrokes [16]. A study published in 2017 by [17] generated data with an IMU, worn at the wrist, and also compared several approaches for shot classification. In general, the rather classical support-vector machine (SVM) performed best with an accuracy of 97.4% for the groundstrokes, specifically the forehand, backhand, service and false shot. Whiteside et al. also implemented a nine-shot type classifier with a mean accuracy of 93.2%. The SVM classifier distinguishes between forehand topspin, slice and volley; backhand topspin, slice and volley; serve; smash; and false shot. The support vector machine is followed by a deep neural network classifier, reaching an accuracy of 96.6% for the four groundstrokes. The extended version reaches 90.4% for the nine shot types classifier.
State-of-the-art deep neural networks are well suited for time series classification (TSC) [18] and give new possibilities in classifying tennis shots. Unfortunately, [17] does not give deeper insight into the creation and application of the classifier. As the literature analysis revealed, there are currently few tennis shot recognition solutions with a deep neural network classifier at the core since this combination is relatively new.

1.2. Biomechanics in Tennis
For a better understanding of the sensor signals, shown in Section 2.1, it is vital to understand tennis shots anatomically. The focus lies on the upper limb—more specifically the shot hand. The movement of the upper extremity in tennis sports can be described as a combination of four basic motions [19]:

1.Pure swing of the upper arm around the shoulder joint: ground swing.
2.Elbow joint flexion and extension: increases the swing.
3.Forearm pronation and supination: rotation around the forearm longitudinal axis, responsible for the topspin or backspin.
4.Wrist extension and flexion: tilt of the wrist, also increases the swing.
Additionally, Ref. [19] separates tennis shots into several sequential stages, which are outlined on the example of a forehand shot in Figure 1:

(I)Preparation/Backswing: the hand starts at resting position, throws the ball up; at the same time, the racket is guided upwards and down behind the back with a flexion of the shoulder and the elbow joint; the phase finishes when the racket reaches the lowest point.
(II)Action phase/Forward swing: the shot forearm and shoulder joint are extended; the racket is guided upwards and forwards; the impact of ball and racket ideally occurs at the highest point, so fully extended elbow and wrist, arm showing upwards.
(III)Follow-through: after the impact, the kinetic energy of the movement has to be dissipated, which is done by letting the momentum run out by swinging the shoulder through; usually, the racket stops at a very low point.
(IV)Retraction: bringing the shot hand back into a neutral position to be ready for the next shot.
Figure 1.
Figure 1

Open in a new tab
Sequence of a tennis forehand, subdivided in four parts.

These four phases are present in all tennis shot types, but differ in the combination of the anatomical motions, which results in distinguishable sensor signals. The tennis shots are categorized into three groundstrokes, which are expanded with the spin to five shot types in total and are described in Table 1.

Table 1.
Division of the tennis shots separated into groundstrokes and their expansion. The abbreviation for the respective shots is also noted.

Groundstrokes	Expansion
Forehand (F)	Topspin (FT)
Slice (FS)
Backhand (B)	Topspin (BT)
Slice (BS)
Service (S)	Service (S)
Open in a new tab
Slice and volley are combined into one shot as the motion is very similar. The same applies to service and smash, which are anatomically the same movement with a different location on the court.

2. Methods
2.1. Shot Detection
To enable shot detection in tennis, a platform to gather data of the shots is needed and should provide data containing information on the shot type. Other sports have used wearables successfully to gather such data [20,21,22]. We also used this approach using wearables in this paper.

2.1.1. Hardware
The wearable used for recording the dataset was the SensorTile development kit (STEVAL-STLKT01V1) of STMicroelectronics, Geneva, Switzerland, which is illustrated in Figure 2 and includes the sensors mentioned in Table 2. The development kit is chosen for the tennis shot detection task since it has already proved its abilities in a catch detection application for American Football [20]. Additionally, the sensor kit comprises all relevant sensors to monitor motion, pressure, and audio in satisfying sample rates and ranges, which is key for a later classification.

Figure 2.
Figure 2

Open in a new tab
Sensor tile displayed as (a) the board itself with numbered sensors according to Table 2, adapted from [24], and (b) the complete wearable with marked sensor axes, worn on the wrist. The axes for the accelerometer , , and the gyroscope , are displayed.

Table 2.
Sensor properties as set on the development kit. Recording sensor, output data rate (ODR) and full scale (FS) are assigned to the respective signal. For more information, we refer the reader to the relevant datasheets [23,24,25,26,27,28,29].

No.	Signal	Sensor	ODR	FS
1	Acceleration a	LSM6DSM	1660	/2
1	Angular velocity	LSM6DSM	1660	2000°/s
2	Magnetic field B	LSM303AGR	100	
3	Pressure p	LPS22HB	75	1260
4	Quantized audio signal	MP34DT05-A	8000	dBSPL
Open in a new tab
2.1.2. Shot Detection Algorithm
The shot detection algorithm is implemented in the programming language C with a finite state machine (FSM) [30]. The FSM, designed for shot detection, is visualized in Figure 3 and is composed of eight states. These states are implemented in the main as well as three timers. Figure 3 shows not only the sequential process but also where the state is realized.

Figure 3.
Figure 3

Open in a new tab
Flowchart of the state machine running on the microcontroller. Note that there is an annotation about the location of the state.

For example, the triggering procedure, responsible for recognizing the tennis shots, is located in timer 1 (TIM1), which runs with 1 . Triggering is done in the states RUNNING, READY_TO_BE_TRIGGERED, and TRIGGERED and is further described in Section 2.1.3. The basis for triggering is the accelerometer and gyroscope data, which are saved as signals in circular buffers [31]. The magnetometer and the pressure signal are collected in TIM2, which runs with 100 , since the ODRs of the respective sensors do not allow faster sampling. An exception is the audio data which is gathered in TIM3 with the highest sampling rate, namely 8 , to capture all the expected frequencies during a tennis shot.

Responsible for accessing the sensor signals and writing them into the respective circular buffer is the state COLLECT_DATA, which, therefore, has to run in all the above mentioned timers. This state is active during the states RUNNING, READY_TO_BE_TRIGGERED and TRIGGERED since samples have to be collected before and after triggering to save the complete shot sequence as mentioned in Section 1.2. Several sensor data plots, like Figure 4a,b show that 1 is sufficient to cover the whole shot. Furthermore, the plots reveal that the buffer has to be filled with 500 of data before and after the trigger.

Figure 4.
Figure 4

Open in a new tab
Jerk j (a) and angular velocity in y-direction raw and filtered (b) of a forehand topspin compared to the trigger thresholds. The time delay of the filtered is clearly visible.

2.1.3. Triggering
Searching for an adequate trigger, which is responsible for recognizing tennis shots and, therefore, starting the saving process of the sensor values, is one key aspect of this study. A selective trigger decreases the post-processing effort, since less falsely detected shots have to be discarded. Optimally, it captures every performed shot, corresponding to a high sensitivity. Since there is a conflict between sensitivity and selectivity [32,33], a suitable trigger algorithm has to be found.

The trigger is realized with two components. A combination of a value modelling the impact of the ball on the racket and another value representing the specific swing performed during tennis shots is chosen. In this way, the balance between falsely detected shots and undetected shots is optimized. On the one hand, the final trigger must capture all types of shots named in Section 1.2. On the other hand, several scenarios are considered that should not be detected:

1.A player hitting his racket on the ground to pick up a ball: high impact, low swing.
2.A player swinging his racket without hitting a ball: low impact, high swing.
3.A player sprinting or jumping: mid impact, low swing.
All in all, three triggering solutions are investigated; however, only the finally implemented method is described in more detail. The other two approaches are accessible in Appendix A.1 and Appendix A.2.

The jerk is chosen as the adequate parameter for the impact of the ball on the racket. The jerk is the change rate of the acceleration with respect to the time. The acceleration is changing with a high frequency when the ball hits the racket, consequently, with a high rate of change. Figure 4a shows the high lobes of the jerk during a forehand topspin. The derivative is taken from the absolute acceleration because the combined signal shows higher peaks during the vibrations of the racket.

We empirically determined that a jerk threshold of 18,000 /3 led to reliable triggering. The threshold is compared to a forehand topspin in Figure 4a.

The angular velocity around the y-axis might be a suitable representative of the pure swing components as is illustrated in Figure 4b. It exhibits a high peak for all shot types. Nevertheless, is also high during shocks which arise, for example, when running or hitting the racket on the ground. Hence, the threshold is compared to a low-passed signal. The finite impulse response (FIR) filter is designed to cut frequencies higher than 15 with an order of . It is designed with a Kaiser window function. The filter coefficients and the magnitude response is illustrated in Figure 5.

Figure 5.
Figure 5

Open in a new tab
(a) FIR filter coefficients and (b) frequency response of the FIR filter.

As a consequence, the vibrations caused by hard hits or the impact of the ball are vanished as can be seen in Figure 4b. This configuration adds an delay to the sensor signal according to

(1)
with as the sampling frequency. Calculation with and 1000 yields a delay 26 , which is still in an acceptable range. The threshold is set to 280 −1 and can be seen in Figure 4b.

Due to the delay of the filter, a window with a size of 50 is implemented. Both thresholds must be exceeded in the latter; otherwise, the trigger is not set. Figure 4a shows the triggering window for the first overshooting of the threshold. The window is restarted after the threshold is surpassed again.

2.2. Generation of the Dataset
Data was collected during training and games of players on a mainly competitive amateur level. In total 16 players, 6 male and 10 female, from an age of 13 to 70 years old wore the wristband to cover a wide range of playing styles. The participants were informed about the MCI ethics assessment and signed a declaration of consent. Additional to the data collection with the wristband, a camera was used to record the session and to label the datasets later on.

Before being able to use the data for training and validating the shot classifier, some pre-processing was performed on the datasets. Neural networks require a feature vector or, in this case, a tensor as input with all entries having the same amount of samples, but the collected sensor buffers have different lengths because of the varying sampling frequencies mentioned in Section 2.1.1. Therefore, the missing sensor samples were interpolated linearly to match the amount of samples of the audio signal. Moreover, the pressure signal did not show a remarkable change whenever a shot was performed. This, and the fact that it was only sampled with a frequency of 100 led to the decision to exclude the pressure data from the dataset. The remaining ten sensor buffers, which are displayed in Figure 6, were extended with the shot hand information encoded as dummy values.

Figure 6.
Figure 6

Open in a new tab
Visualisation of the 10 sensor signals of a forehand topspin with annotated sequences as mentioned in Section 1.2: (a) x, y, z component of the accelerometer, (b) x, y, z component of the gyroscope, (c) x, y, z component of the magnetometer, and (d) quantified audio signal.

The resulting input feature tensor has a dimensionality of and consists of Z-Score normalized values. The Z-Score of each sample is derived according to [34]:

(2)
with x as the current sensor value, as the standard deviation, and as the arithmetic mean value of the respective shot and sensor.

The output feature tensor contains the one-shot encoded shot type information. After the labelling process, the datasets are anonymised by shuffling them several times and renaming them incrementally.

2.3. Shot Classification with a Deep Convolutional Neural Network
Deep neural networks (DNN) have shown especially promising results in speech recognition [35] and natural language processing (NLP) [36]. NLP and speech recognition have the sequential aspect of the data in common, which is also an important feature of the time series data processed in this study. The authors in [37] saw this as an opportunity to research deep neural network performance regarding TSC problems. One main question of his review was whether DNNs could surpass standard classification processes, like the hierarchical vote collective of transformation-based ensemble (HIVE-COTE) [38] or dynamic time warping (DTW) [13,14] as used in a tennis shots classification approach by [15], in terms of computational effort and classification accuracy.

Based on the research in [37], the two best-performing architectures were adapted for the classification problem of tennis shots. The best performers, namely a fully convolutional network (FCN) and a residual network (ResNet), are categorized as discriminative end-to-end approaches [39,40,41]. End-to-end models do not require any hand-engineered features of the input training data. The particular architectures learn the feature extraction on their own while fine-tuning the classifier in the backpropagation process [42,43].

2.3.1. Architecture of the FCN
FCNs were first presented for a time series classification problem in 2016 by [44]. The FCN for the shot classification is built with four hidden layers, and the input and output layer. The main components are the three convolution blocks. The first convolution consists of 128 filters with a length of eight; the second contains 256 filters with a filter length equal to five. The last convolution reduces the number of filters back to 128 and the filter length to three. Every convolution is pursued by a batch normalization [45]. The output of the batch normalization is fed into a Mish activation function [46]. After the third convolutional block, a global average pooling (GAP) layer [47] is applied, followed by a softmax operation [48]. Furthermore, the length of the time series is kept constant with adequate zero-padding until the GAP layer. Figure 7 shows the complete architecture of the FCN.

Figure 7.
Figure 7

Open in a new tab
Schematic visualization of the FCN architecture for the three classes model.

2.3.2. Architecture of a ResNet
Residual networks, first published in an image classification competition in 2015 by [49], are convolutional networks with up to 1000 layers that are still trainable. This deepness is made possible by the so-called “identity shortcut connections”, which skip one or more layers [50]. Via these connections, the gradient can flow backwards unimpeded. Thus, the vanishing gradient problem is reduced, making it possible to use deeper networks that can mimic more complex functions.

In 2016, the researchers in [44] released a relatively deep ResNet for time series classification. This architecture consists of the indispensable input layer, nine convolutional layers, and one GAP layer that is fully connected to the output layer with the classical softmax activation. The nine convolutional layers are dividable into blocks of similar structure: The first of these three blocks consists of three convolutions with 64 filters of size eight, five, and three. Each convolution is followed by batch normalization and the Mish activation function, apart from the last one.

After the third filter and batch normalization, the interim result is added to the identity of a shortcut connection. The sum is activated with a Mish function and then fed into the next block. The consecutive blocks differ only slightly. The amount of filters is increased to 128, the rest is kept as before. The shortcut connections take the output of the latter block instead of the input layer. For a better understanding, the architecture is visualized in Figure 8.

Figure 8.
Figure 8

Open in a new tab
Visualization of the ResNet architecture for the three shot types classification. The first 9 hidden layers are divided into 3 × 3 similar blocks. Each block has a shortcut connection to the previous one.

2.3.3. Training of the Deep Neural Network Classifiers
The creation of the classifiers is implemented in Google Colaboratory [51], which is a cloud service based on Jupyter Notebooks [52]. It offers a free-of-charge use of a graphics processing unit (GPU) such as an NVIDIA Tesla T4, (NVIDIA, Santa Clara, CA, USA), which outperforms standard central processing units (CPU) by far [53]. Training sessions of the tennis shot classification are executed around 25–30-times faster. Another reason for the use of Google Colab is the out-of-the-box support of the open-source deep-learning library Keras [54], which runs on Tensorflow [55] as a backend.

A successful training is strongly dependent on the quality of the training and validation set. An important measure is that all the classes are represented as equally as possible in all sets. The used stratified K-Folds cross validator [56] splits the dataset into n folds and preserves the percentage of samples for every class. For this application, four folds are created, meaning that four different models are trained. Figure 9 illustrates the operating principle of stratified K-Folds, which swaps the training and validation sets for every iteration. The fact that more than one model is created allows creating averages and standard deviations of several metrics for checking the real capability of the model, independent from the weight initialization.

Figure 9.
Figure 9

Open in a new tab
Operating principle of the K-Folds cross validator. The shuffling of the stratified sets leads to dissimilar models per iteration.

As an optimizer, Ranger [57] is used. Ranger is a combination of three algorithms, namely RectifiedAdam (RAdam) [58], Lookahead [59] and Gradient Centralization (GC) [60]. Ranger is not yet implemented in TensorFlow nor in Keras. Nevertheless, the documentation of RAdam proposes the integration of the Lookahead optimizer to generate the Ranger optimizer. This modification is used for the shot classification training. The GC add-on is left for future work.

Another critical question is the training time, more specifically, how many training epochs should be used. An exemplary training session is displayed in Figure 10. The training finished here after 130 epochs, and the results were stable after 60. The training epochs are fixed to this empirically determined value. The duration of this exemplary training process was 13 , resulting in   per epoch. In conclusion, the settings mentioned above resulted in stable behaviour.

Figure 10.
Figure 10

Open in a new tab
Training history of (a) accuracy and (b) categorical cross entropy (CCE).

3. Results
3.1. Shot Detection Trigger
The setup described in Section 2.1.3 yielded a 91% success rate of shot detection. The other investigated solutions were abandoned due to the reasons mentioned in Appendix A.3.

False positives were very rare, only 2%. The trigger was not set in situations that are closely related to a shot, for example, when a player picks up the ball from the ground by hitting it several times. However, the time intensive data saving, which takes nearly 2 , is the reason why quick consecutive shots were not captured, for example when one player was at the net and playing volleys. Furthermore, in rare cases, the backhand slice was not detected because of the unfavourable orientation of the wearable that resulted in a lower value.

3.2. Dataset
Overall video material of 18 h resulted in 5682 labelled tennis shots. The distribution over the shot types is illustrated in Figure 11. The slice version of the shots is, with 6.35% for backhand and 2.87% for forehand, significantly under-represented, although volley and slice are already combined. For the groundstroke dataset, the two backhand types were combined, resulting in 1439 shots that had a 25% contribution to the overall training set. Additionally, the forehand shots were merged, which yielded 3344 shots or 59%. Services were the same as before. Another statistic is the division of the dataset into left and right-handed players. Here, left-handed shots are represented with only 7%.

Figure 11.
Figure 11

Open in a new tab
Distribution of the shot types in the final training set.

3.3. Shot Classification
The final results of the classifiers are shown for the three classes networks and five classes networks. First, the three classes model is compared for the FCN and ResNet. Second, the result of the five classes network is only shown for the ResNet, because of the reasons mentioned in Section 3.3.1. All following metrics are introduced in [61].

3.3.1. Three Shot Types Classification
The normalized confusion matrices of the respectively best iterations in Figure 12 indicate strong diagonals.

Figure 12.
Figure 12

Open in a new tab
Normalized confusion matrix for the FCN (a) and the ResNet (b) comparing the three classes: backhand (B), forehand (F), and service (S).

Table 3 shows the results in more detail. The F1 score for all shot types is in the range of 94–97%. The recall and precision are constantly high with values between between 93–98%.

Table 3.
Recall (R), precision (P), and F1 score (F1) for FCN and ResNet for the respective shot types of the best model.

FCN	ResNet
R	P	F1	R	P	F1
B	93%	96%	95%	96%	94%	95%
F	98%	96%	97%	98%	97%	98%
S	93%	94%	94%	93%	96%	95%
Average	96%	96%	96 %	96%	96%	96%
Open in a new tab
Both architectures are well suited for the classification task with the ResNet having a slightly better performance. Additionally, the optimization of the ResNet architecture reaches a stable state on average five epochs faster. Moreover, forehand seems to be a little easier to predict. The reason might be the higher representation of forehands in the dataset.

3.3.2. Five Shot Types Classification
The results of the five classes models are presented only by the ResNet. There is merely a slight difference in accuracy to the FCN, but the ResNet trained faster.

The confusion matrix in Figure 13 has high percentage values in the diagonal for the topspin versions and the service, i.e., the standard shots. It has to be mentioned that the slice variants are less accurately categorized. The wrongly classified samples tend to be misclassified into the topspin equivalent or as the other ground shot’s topspin. Hence, the model is overfitted to the ground shots.

Figure 13.
Figure 13

Open in a new tab
Normalized confusion matrix for the best ResNet comparing the five classes: backhand slice (BS), backhand topspin (BT), forehand slice (FS), forehand topspin (FT), and service (S).

Table 4 illustrates the main metrics for an inhomogenous dataset problem. The results of the confusion matrix are confirmed. The average is very high, with a percentage of 94%. The reason for this is the dominating influence of the forehand topspin with nearly 56% contribution to the whole dataset. Hence, also the low recognition rate of the forehand slice effects the sample average of the F1 score only a little, as it represents only 2.9% of all samples.

Table 4.
Recall, precision, and F1 score for ResNet for the respective shot types of the best model.

R	P	F1
BS	77%	82%	80%
BT	92%	94%	93%
FS	76%	68%	72%
FT	97%	97%	97%
S	94%	90%	92%
Average	94%	94%	94%
Open in a new tab
4. Discussion
4.1. Shot Detection Trigger
The shot detection trigger is accurate for the groundstrokes. Improvement lies in the recognition of the slice variants due to the unfavourable orientation of the wearable. A possible solution could be a more complex algorithm which includes another trigger value as representative of slice shots. The data saving time is another bottleneck which does not allow to capture quick consecutive shots. With these two enhancements, a detection rate of around 95% can be expected, which lies in the range of the best published research thus far [12]. As the focus of this study is more shifted towards the generation of a classifier, the reached accuracy is considered to be sufficient, and optimizations are left for future work.

4.2. Shot Classification
Compared to other approaches, such as dynamic time warping and support vector machines, mentioned in Section 1, this study reached higher classification accuracies for the groundstrokes apart from the one mentioned in [15]; however, the less complex and more module solution justifies the worse recognition rate. The additional distinction between slice and topspin worsened the performance emphasizing the importance of a homogeneous dataset.

Furthermore, the classification success was decreased by the limitations of the sensors. The full scale values of the gyroscope ( 2000 −1) and the accelerometer (  −2) were exceeded with fast shots. The clipping at the borders adds non-linearities to the sensor signals. Sensors with a wider measurement range would allow the gathering of more precise data and could consequently improve the classification accuracy.

4.2.1. Validation of the Dataset Quality
Mislabelled datasets can be a reason for falsely classified shots. During a training session with 50 iterations, the mispredicted shots were tracked and their unique identifiers noted. A stratified K-Fold in each iteration ensured that every shot is 50 times in the validation set. Figure 14 shows how often a shot is falsely classified in how many iterations. If a shot is incorrectly classified in all fifty iterations, the probability is high that the label is wrong or it is a complex shot and, therefore, hard to classify.

Figure 14.
Figure 14

Open in a new tab
The x-axis gives the amount of folds in which a shot is mispredicted. The y-axis is the amount of shots that occur in the respective bin.

Note that the histogram in Figure 14 is having its peak at the first two bins. This indicates that the network is not able to predict these shots in individual iterations. The uncertainty in the weight distribution of the network is held responsible for this. However, in 76 of the 5682 shots, located on the far right of Figure 14, the current setup is not capable of training the DNN to predict certain shots correctly. These are of the total dataset. These shots are either labelled incorrect or seldom occurring and, therefore, hard to train.

4.2.2. Ablation Study
An ablation study [62] is performed for the three-class ResNet to receive information about the significance of the input values. The objective is to optimize the input feature tensor with a simultaneous improvement of the neural network and a possible downsizing of the sensor board. The mean F1 score over four iterations for every configuration is compared. The sensor values, which are highlighted with a checkmark in Table 5, are left unchanged, whereas the others are filled with zeroes instead of real values.

Table 5.
Ablation study for the input values of the three-class ResNet.

Accelerometer	Gyroscope	Magnetometer	Audio	F-Score
✓				95.8%
✓			95.3%
✓		95.3%
✓	69.3%
✓	✓	✓		96.6%
✓	✓		✓	96.0%
✓		✓	✓	96.1%
✓	✓	✓	95.8%
✓	✓	✓	✓	96.4%
Open in a new tab
Interestingly, the ablation study indicates an independence of the DNN classifier from the audio data. In general, the audio data can be excluded from the feature tensor and, consequently, also the microphone on the sensor board. Note that the audio data is sampled with 8 to capture all the necessary information. If the audio data is not included, the feature tensor can be reduced considerably. Consequences are a smaller dataset and network yielding a faster training of the latter.

5. Conclusions and Future Work
This study found that a deep neural network approach reached high accuracies in tennis shot classification when a rich, homogenous dataset was used. The generation of the latter one is difficult to obtain when only taking data from games or training sessions since the groundstrokes are always overrepresented. Data augmentation, including averaging, amplification, dynamic time warping, addition of noise, etc. [37,63,64] is a possibility to smooth the distribution over the shot types, but was not considered in this study.

Nevertheless, high classification rates were achieved with a rather inhomogenous data set. Recent developments in the architecture of deep learning networks and the newest research on more stable activation functions and optimizers made this possible.

Furthermore, the results show another capability of deep convolutional neural networks for time series classification. The generation of a dataset can be done with much less domain knowledge because no striking features have to be extracted. Therefore, the pre-processing effort was reduced drastically.

Triggering with a combination of filtered angular velocity and jerk j yielded a reliable detection rate. Since the focus of this study was shifted toward the classification process, this result is considered sufficiently accurate. The reliability of the triggering decreased the post-processing effort for labelling the shots, as only few false positives were detected.

One recommended next step should involve the development of a wearable whose sensors have adequate full scales. Consequently, the classification accuracy could improve since the sensor signals will not be clipped. Future work can also focus on better analysis functions. One suggestion is the development of a real-time shot classification to directly see information about playing styles—for example, during training sessions or games. The information could be available in a smartphone application. The used wearable already has a BlueTooth module, which could be used for the transmission of the data. Valuable information for the players would also be the quality of the shot and the success rate per shot. For this purpose, another dataset must be generated. The position of the ball on the surface of the racket during impact and the success of the shot must be labelled for this.

Furthermore, an implementation of the wearable into a smart-watch would be a step to create a product that could be offered to a broader audience.

Acknowledgments
The authors would like to thank the MCI for providing the funds to develop the study and the part-time students for the prework and assistance. Additional thanks goes to the Tennis Clubs of Innsbruck, especially to the players of the TI Tennis, who played for several hours with the wearable to generate a vibrant dataset.

Abbreviations
The following abbreviations are used in this manuscript:

CNN	convolutional neural network
CPU	central processing unit
DNN	deep neural network
DTW	dynamic time warping
FCN	fully convolutional network
FIR	finite impulse response
FS	full scale
FSM	finite state machine
GAP	global average pooling
GPS	global positioning system
GPU	graphics processing unit
HIVE-COTE	hierarchical vote collective of transformation-based ensemble
IMU	inertial measurement unit
MCI	Management Center Innsbruck
NLP	natural language processing
ODR	output data rate
ResNet	residual network
SVM	support vector machine
TSC	time series classification
Open in a new tab
Appendix A. Alternative Triggering Methods
Additional to the triggering method described in Section 2.1.3, two more solutions were investigated on a small scale. Nevertheless, the authors want to clarify the decision to use the finally implemented trigger by explaining the other approaches as well.

Appendix A.1. Audio
The idea of triggering with the microphone data was to capture the distinct sound of the moment when the ball hits the racket. Nevertheless, the audio signal as a trigger failed because of the disturbing wind generated by the fast movements. The noisy audio signal of a forehand topspin is shown in Figure 6d. The exact moment of the racket hitting the ball is not unambiguously recognizable. Trials to protect the device from the wind with a pop filter [65] were not successful, and therefore, this solution was abandoned.

Appendix A.2. Variation of the Filtered Net Rotational Energy and Jerk
Since tennis is a swing sport, the rotational energy during a shot is relatively high, resulting in a significant lobe in the . Hence, the second idea was the triggering via a modification of the net rotational energy , which is defined as

(A1)
where I is the moment of inertia of a body around its rotational axis [16]. Therefore, also

(A2)
holds true. This result is smoothed with the filter specified in Section 2.1.3 and compared to an empirically determined threshold value.

This swing representative is combined with a threshold for the jerk in the same way as mentioned in Section 2.1.3.

Appendix A.3. Comparison of the Triggers
Table A1 gives an overview about the trigger possibilities. In the end, the combination was chosen due to its higher selectivity in comparison to the solution.

Table A1.
Advantages and drawbacks of the previously introduced solutions for triggering.

Audio		
Advantage	-	high sensitivity, most of the shots are detected as the swing in all axes is captured	high selectivity, false shots are very rare, for example grabbing a ball from the ground by hitting the racket on it
Drawback	impact not distinguishable from wind	lacks in selectivity, too many false positives	some shots are not detected due to slow angular velocities in the y-direction
Open in a new tab
Author Contributions
Conceptualization, A.G. and B.H.; methodology, A.G. and B.H.; software, A.G. and B.H.; validation, A.G., B.H. and S.S.; formal analysis, A.G. and B.H.; investigation, A.G., B.H. and S.S.; resources, A.G.; data curation, A.G.; writing–original draft preparation, A.G.; writing–review and editing, A.G., B.H. and S.S.; visualization, A.G.; supervision, B.H. and S.S.; project administration, B.H.; funding acquisition, B.H. All authors have read and agreed to the published version of the manuscript.

Funding
This research received no external funding but was funded within the department of mechatronics at MCI.

Institutional Review Board Statement
The study was conducted according to the guidelines of the Declaration of Helsinki, and approved by the Institutional Ethics Commission of the MCI, Innsbruck, Austria (protocol code 2020-03-a and date of approval 13 March 2020, statement: “Thank you for submitting the ethics assessment of your work! The MCI Ethics Commission has evaluated your submission and deemed the therein-described procedure appropriate”).

Informed Consent Statement
Informed consent was obtained from all subjects involved in the study.

Data Availability Statement
Samples and code are available from the authors.

Conflicts of Interest
The authors declare no conflict of interest.

Footnotes
Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.

References
1.Shirer M., Llamas R., Ubrani J. Shipments of Wearable Devices Reach 118.9 Million Units in the Fourth Quarter and 336.5 Million for 2019, According to IDC. [(accessed on 1 July 2021)]; Available online: https://www.idc.com/getdoc.jsp?containerId=prUS46122120.
2.Universidad de Castilla-la Mancha. Universidade de Tras-Os-Montes e Alto Douro. Fondazione garagErasmus. European Network of Academic Sports Services. ONECO. Wiener Sport-Club. University of Cyprus. Comitato Olimpico Nazionale Italiano Digi-Sporting. A New Step Towards Digital Transformation through Sports Science: Guidelines on the Application of New Technologies, Professional Profiles, and Needs for the Digital Transformation of Sports Organisations. [(accessed on 1 July 2021)]; Available online: https://digi-sporting.eu/wp-content/uploads/2020/06/BriefReport_English.pdf.
3.Camomilla V., Bergamini E., Fantozzi S., Vannozzi G. Trends Supporting the In-Field Use of Wearable Inertial Sensors for Sport Performance Evaluation: A Systematic Review. Sensors. 2018;18:873. doi: 10.3390/s18030873. [DOI] [PMC free article] [PubMed] [Google Scholar]
4.Vleugels R., Van Herbruggen B., Fontaine J., De Poorter E. Ultra-Wideband Indoor Positioning and IMU-Based Activity Recognition for Ice Hockey Analytics. Sensors. 2021;21:4650. doi: 10.3390/s21144650. [DOI] [PMC free article] [PubMed] [Google Scholar]
5.Chow D.H.K., Tremblay L., Lam C.Y., Yeung A.W.Y., Cheng W.H.W., Tse P.T.W. Comparison between Accelerometer and Gyroscope in Predicting Level-Ground Running Kinematics by Treadmill Running Kinematics Using a Single Wearable Sensor. Sensors. 2021;21:4633. doi: 10.3390/s21144633. [DOI] [PMC free article] [PubMed] [Google Scholar]
6.Clemente F.M., Akyildiz Z., Pino-Ortega J., Rico-González M. Validity and Reliability of the Inertial Measurement Unit for Barbell Velocity Assessments: A Systematic Review. Sensors. 2021;21:2511. doi: 10.3390/s21072511. [DOI] [PMC free article] [PubMed] [Google Scholar]
7.Horenstein R.E., Goudeau Y.R., Lewis C.L., Shefelbine S.J. Using Magneto-Inertial Measurement Units to Pervasively Measure Hip Joint Motion during Sports. Sensors. 2020;20:4970. doi: 10.3390/s20174970. [DOI] [PMC free article] [PubMed] [Google Scholar]
8.Rein R., Memmert D. Big data and tactical analysis in elite soccer: Future challenges and opportunities for sports science. SpringerPlus. 2016;5:1410. doi: 10.1186/s40064-016-3108-2. [DOI] [PMC free article] [PubMed] [Google Scholar]
9.O’donoghue P. Research Methods for Sports Performance Analysis. Routledge; London, UK: 2009. [Google Scholar]
10.Wiggers K. PlaySight Trained AI on Thousands of Hours of Videos to Understand Sports. [(accessed on 1 July 2021)];2020 Available online: https://venturebeat.com/2020/02/14/playsight-ai-machine-learning-sports-analytics/
11.Edelmann-Nusser A., Raschke A., Bentz A., Montenbruck S., Edelmann-Nusser J., Lames M. Validation of Sensor-Based Game Analysis Tools in Tennis. Int. J. Comput. Sci. Sport. 2019;18:49–59. doi: 10.2478/ijcss-2019-0013. [DOI] [Google Scholar]
12.Pei W., Wang J., Xu X., Wu Z., Du X. An embedded 6-axis sensor based recognition for tennis stroke; Proceedings of the 2017 IEEE International Conference on Consumer Electronics (ICCE); Las Vegas, NV, USA. 8–10 January 2017; pp. 55–58. [DOI] [Google Scholar]
13.Bagnall A., Lines J., Bostrom A., Large J., Keogh E. The great time series classification bake off: A review and experimental evaluation of recent algorithmic advances. Data Min. Knowl. Discov. 2017;31:606–660. doi: 10.1007/s10618-016-0483-9. [DOI] [PMC free article] [PubMed] [Google Scholar]
14.Kate R. Using dynamic time warping distances as features for improved time series classification. Data Min. Knowl. Discov. 2015;30 doi: 10.1007/s10618-015-0418-x. [DOI] [Google Scholar]
15.Srivastava R., Patwari A., Kumar S., Mishra G., Kaligounder L., Sinha P. Efficient characterization of tennis shots and game analysis using wearable sensors data; Proceedings of the 2015 IEEE SENSORS; Busan, Korea. 1–4 November 2015; pp. 1–4. [DOI] [Google Scholar]
16.Anand A., Sharma M., Srivastava R., Kaligounder L., Prakash D. Wearable Motion Sensor Based Analysis of Swing Sports; Proceedings of the 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA); Cancun, Mexico. 18–21 December 2017; pp. 261–267. [DOI] [Google Scholar]
17.Whiteside D., Cant O., Connolly M., Reid M. Monitoring Hitting Load in Tennis Using Inertial Sensors and Machine Learning. Int. J. Sport. Physiol. Perform. 2017;12:1212–1217. doi: 10.1123/ijspp.2016-0683. [DOI] [PubMed] [Google Scholar]
18.Ismail Fawaz H., Forestier G., Weber J., Idoumghar L., Muller P.A. Deep learning for time series classification: A review. Data Min. Knowl. Discov. 2019;33:917–963. doi: 10.1007/s10618-019-00619-1. [DOI] [Google Scholar]
19.Bartlett R. Introduction to Sports Biomechanics: Analysing Human Movement Patterns. Routledge; London, UK: 2007. [Google Scholar]
20.Hollaus B., Stabinger S., Mehrle A., Raschner C. Using Wearable Sensors and a Convolutional Neural Network for Catch Detection in American Football. Sensors. 2020;20:6722. doi: 10.3390/s20236722. [DOI] [PMC free article] [PubMed] [Google Scholar]
21.Roell M., Mahler H., Lienhard J., Gehring D., Gollhofer A., Roecker K. Validation of Wearable Sensors during Team Sport-Specific Movements in Indoor Environments. Sensors. 2019;19:3458. doi: 10.3390/s19163458. [DOI] [PMC free article] [PubMed] [Google Scholar]
22.Qi W., Su H., Yang C., Ferrigno G., De Momi E., Aliverti A. A Fast and Robust Deep Convolutional Neural Networks for Complex Human Activity Recognition Using Smartphone. Sensors. 2019;19:3731. doi: 10.3390/s19173731. [DOI] [PMC free article] [PubMed] [Google Scholar]
23.STMicroelectronics . STM32L476xx: Ultra-Low-Power Arm® Cortexr®-M4 32-bit MCU+FPU, 100DMIPS, up to 1MB Flash, 128 KB SRAM, USB OTG FS, LCD, ext. SMPS. STMicroelectronics; Geneva, Switzerland: 2019. [Google Scholar]
24.STMicroelectronics . Data Brief: SensorTile connectable Sensor Node: Plug or Solder. STMicroelectronics; Geneva, Switzerland: 2019. [Google Scholar]
25.STMicroelectronics . NUCLEO-F401RE: STM32 Nucleo-64 Development Board with STM32F401RE MCU, Supports Arduino and ST Morpho Connectivity. STMicroelectronics; Geneva, Switzerland: 2019. [Google Scholar]
26.STMicroelectronics . LSM6DSM: INEMO Inertial Module: Always-on 3D Accelerometer and 3D Gyroscope. STMicroelectronics; Geneva, Switzerland: 2017. [Google Scholar]
27.STMicroelectronics . LSM303AGR: Ultra-Compact High-Performance eCompass Module: Ultra-Low Power 3D Accelerometer and 3D Magnetometer. STMicroelectronics; Geneva, Switzerland: 2018. [Google Scholar]
28.STMicroelectronics . LPS22HB: MEMS Nano Pressure Sensor: 260-1260 hPa Absolute Digital Output Barometer. STMicroelectronics; Geneva, Switzerland: 2017. [Google Scholar]
29.STMicroelectronics . MP34DT05-A: MEMS Audio Sensor Omnidirectional Stereo Digital Microphone. STMicroelectronics; Geneva, Switzerland: 2019. [Google Scholar]
30.Ribas-Xirgo L. Universitat Autònoma de Barcelona (UAB); Barcelona, Spain: 2014. How to Code Finite State Machines (FSMs) in C. A Systematic Approach. [DOI] [Google Scholar]
31.Dobson C. How To Implement A Simple Circular Buffer In C. [(accessed on 1 July 2021)];2019 Available online: https://medium.com/@charlesdobson/how-to-implement-a-simple-circular-buffer-in-c-34b7e945d30e.
32.Hurot C., Scaramozzino N., Buhot A., Hou Y. Bio-Inspired Strategies for Improving the Selectivity and Sensitivity of Artificial Noses: A Review. Sensors. 2020;20:1803. doi: 10.3390/s20061803. [DOI] [PMC free article] [PubMed] [Google Scholar]
33.Dey A. Semiconductor metal oxide gas sensors: A review. Mater. Sci. Eng. B. 2018;229:206–217. doi: 10.1016/j.mseb.2017.12.036. [DOI] [Google Scholar]
34.Li S.Z., Jain A. Score Normalization. In: Li S.Z., Jain A., editors. Encyclopedia of Biometrics. Springer; Boston, MA, USA: 2009. pp. 1134–1135. [Google Scholar]
35.Hinton G., Deng L., Yu D., Dahl G.E., Mohamed A., Jaitly N., Senior A., Vanhoucke V., Nguyen P., Sainath T.N., et al. Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups. IEEE Signal Process. Mag. 2012;29:82–97. doi: 10.1109/MSP.2012.2205597. [DOI] [Google Scholar]
36.Sutskever I., Vinyals O., Le Q.V. Sequence to Sequence Learning with Neural Networks. In: Ghahramani Z., Welling M., Cortes C., Lawrence N.D., Weinberger K.Q., editors. Advances in Neural Information Processing Systems 27. Curran Associates, Inc.; Red Hook, NY, USA: 2014. pp. 3104–3112. [Google Scholar]
37.Fawaz H.I., Forestier G., Weber J., Idoumghar L., Muller P.A. Data augmentation using synthetic data for time series classification with deep residual networks. arXiv. 20181808.02455 [Google Scholar]
38.Lines J., Taylor S., Bagnall A. Time Series Classification with HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based Ensembles. ACM Trans. Knowl. Discov. Data. 2018;12 doi: 10.1145/3182382. [DOI] [Google Scholar]
39.Ng A.Y., Jordan M.I. Advances in Neural Information Processing Systems. MIT Press; Cambridge, MA, USA: 2002. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes; pp. 841–848. [Google Scholar]
40.Joshi P.M. Generative VS Discriminative Models. [(accessed on 1 July 2021)];2018 Available online: https://medium.com/@mlengineer/generative-anddiscriminative-models-af5637a66a3.
41.Abid M., Mitiche A., Ouakrim Y., Vendittoli P.A., Fuentes A., Hagemeister N., Mezghani N. A Comparative Study of End-To-End Discriminative Deep Learning Models for Knee Joint Kinematic Time Series Classification; Proceedings of the 2019 IEEE Signal Processing in Medicine and Biology Symposium (SPMB); Philadelphia, PA, USA. 7 December 2019; pp. 1–6. [DOI] [Google Scholar]
42.Nweke H., Wah T., Al-Garadi M., Alo U. Deep Learning Algorithms for Human Activity Recognition using Mobile and Wearable Sensor Networks: State of the Art and Research Challenges. Expert Syst. Appl. 2018;105 doi: 10.1016/j.eswa.2018.03.056. [DOI] [Google Scholar]
43.Roza F. End-to-End Learning, the (Almost) Every Purpose ML Method. [(accessed on 1 July 2021)];2020 Available online: https://towardsdatascience.com/e2e-the-every-purpose-ml-method-5d4f20dafee4.
44.Wang Z., Yan W., Oates T. Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline. arXiv. 20161611.06455 [Google Scholar]
45.Santurkar S., Tsipras D., Ilyas A., Madry A. How Does Batch Normalization Help Optimization? arXiv. 20181805.11604 [Google Scholar]
46.Misra D. Mish: A Self Regularized Non-Monotonic Activation Function. arXiv. 20191908.08681 [Google Scholar]
47.Zhou B., Khosla A., Lapedriza A., Oliva A., Torralba A. Learning Deep Features for Discriminative Localization. arXiv. 20151512.04150 [Google Scholar]
48.Nwankpa C., Ijomah W., Gachagan A., Marshall S. Activation Functions: Comparison of trends in Practice and Research for Deep Learning. arXiv. 20181811.03378 [Google Scholar]
49.He K., Zhang X., Ren S., Sun J. Deep Residual Learning for Image Recognition. arXiv. 20151512.03385 [Google Scholar]
50.He K., Zhang X., Ren S., Sun J. Identity Mappings in Deep Residual Networks. arXiv. 20161603.05027 [Google Scholar]
51.Bisong E. Building Machine Learning and Deep Learning Models on Google Cloud Platform: A Comprehensive Guide for Beginners. Apress; Berkeley, CA, USA: 2019. Google Colaboratory; pp. 59–64. [Google Scholar]
52.Kluyver T., Ragan-Kelley B., Pérez F., Granger B., Bussonnier M., Frederic J., Kelley K., Hamrick J., Grout J., Corlay S., et al. Jupyter Notebooks—A publishing format for reproducible computational workflows. In: Loizides F., Schmidt B., editors. Positioning and Power in Academic Publishing: Players, Agents and Agendas. IOS Press; Amsterdam, The Netherlands: 2016. pp. 87–90. [Google Scholar]
53.Carneiro T., Medeiros Da NóBrega R.V., Nepomuceno T., Bian G., De Albuquerque V.H.C., Filho P.P.R. Performance Analysis of Google Colaboratory as a Tool for Accelerating Deep Learning Applications. IEEE Access. 2018;6:61677–61685. doi: 10.1109/ACCESS.2018.2874767. [DOI] [Google Scholar]
54.Chollet F. Keras. [(accessed on 1 July 2021)];2015 Available online: https://github.com/fchollet/keras.
55.Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G.S., Davis A., Dean J., Devin M., et al. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems Software. [(accessed on 1 July 2021)];2015 Available online: tensorflow.org.
56.Refaeilzadeh P., Tang L., Liu H. Cross-Validation. In: Liu L., Özsu M.T., editors. Encyclopedia of Database Systems. Springer; Boston, MA, USA: 2009. pp. 532–538. [Google Scholar]
57.Wright L., Lowe S., Pariente M., Holderbach S., Parodi F. Ranger-Deep-Learning-Optimizer. [(accessed on 23 August 2021)];2020 Available online: https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer.
58.Liu L., Jiang H., He P., Chen W., Liu X., Gao J., Han J. On the Variance of the Adaptive Learning Rate and Beyond. arXiv. 20191908.03265 [Google Scholar]
59.Zhang M.R., Lucas J., Hinton G., Ba J. Lookahead Optimizer: K steps forward, 1 step back. arXiv. 20191907.08610 [Google Scholar]
60.Yong H., Huang J., Hua X., Zhang L. Gradient Centralization: A New Optimization Technique for Deep Neural Networks. arXiv. 20202004.01461 [Google Scholar]
61.Sammut C., Webb G.I., editors. Encyclopedia of Machine Learning and Data Mining. Springer; Boston, MA, USA: 2017. [Google Scholar]
62.Meyes R., Lu M., de Puiseau C.W., Meisen T. Ablation Studies in Artificial Neural Networks. arXiv. 20191901.08644 [Google Scholar]
63.Iwana B.K., Uchida S. Time Series Data Augmentation for Neural Networks by Time Warping with a Discriminative Teacher. arXiv. 20202004.08780 [Google Scholar]
64.Wen Q., Sun L., Yang F., Song X., Gao J., Wang X., Xu H. Time Series Data Augmentation for Deep Learning: A Survey. arXiv. 20212002.12478 [Google Scholar]
65.Power R. Microphone Pop Filter. US8369556B2. 2013 Feb 5;
Associated Data
This section collects any data citations, data availability statements, or supplementary materials included in this article.

Data Availability Statement
Samples and code are available from the authors.

Articles from Sensors (Basel, Switzerland) are provided here courtesy of Multidisciplinary Digital Publishing Institute (MDPI)

ACTIONS
View on publisher site
PDF (75.4 MB)

Cite

Collections

Permalink
RESOURCES
Similar articles
Cited by other articles
Links to NCBI Databases
On this page
Abstract
1. Introduction
2. Methods
3. Results
4. Discussion
5. Conclusions and Future Work
Acknowledgments
Abbreviations
Appendix A. Alternative Triggering Methods
Author Contributions
Funding
Institutional Review Board Statement
Informed Consent Statement
Data Availability Statement
Conflicts of Interest
Footnotes
References
Associated Data

Follow NCBI
NCBI on X (formerly known as Twitter)
NCBI on Facebook
NCBI on LinkedIn
NCBI on GitHub
NCBI RSS feed
Connect with NLM

NLM on X (formerly known as Twitter)
NLM on Facebook
NLM on YouTube
National Library of Medicine
8600 Rockville Pike
Bethesda, MD 20894

Web Policies
FOIA
HHS Vulnerability Disclosure
Help
Accessibility
Careers
NLM
NIH
HHS
USA.gov
Tell us what you think!
```

```
Stanford CS 229 Fall 2017
Final Project Report:
Real Time Tennis Match Prediction Using Machine Learning
Yang "Eddie" Chen, Yubo Tian, Yi Zhong
December 15, 2017
This project adopts an innovative data model by combining both historical match data and real-time stats, and
apply machine learning to predict tennis match outcomes.
Specifically, we explore and compare four data models mixing historical data and real-time stats, while applying machine learning techniques such as logistic regression, support
vector classification (SVC) with linear, RBF and polynomial
kernels, and Naive Bayes classification. Feature selection
techniques such as recursive feature elimination and principal component analysis were employed as well. We find that
applying SVC with a RBF kernel on historical data alone
gives the best prediction. More importantly, a thorough
analysis on results was done to reveal and understand the
predominant challenge in this hybrid approach - high bias,
as our extracted feature set does not cover edge cases and
"comback" situations. TTL (total points won) is found to
be the most dominant and predictive feature for linear models, with other standout features also revealed. From there,
the project outlines the future work needed to combat the
high bias issue by proposing other features that could be
used but not included in the current project.
1 Introduction
In the 2017 Stuttgart Open, 18-time grand slam champion
Roger Federer lost to the world No. 302 player Tommy Haas
on a grass court, which hadn’t happened since 2002. Based
on past performance alone, almost any model would have
predicted a Federer win, perhaps with large margin too.
This surprise event motivated us to apply machine learning
to predict tennis matches in real time; in particular, we want
to apply a hybrid model that combines historical and realtime, in-game information, in an attempt to better existing
predictions.
2 Related Work
Extensive research has been done on tennis as it is an ideal
sport to apply hierarchical probability models: tennis match
consists of a sequence of sets, which in turn consist of several games, which in turn consist of a sequence of points.
Knottenbelt [5] proposed a common opponent model to extract features between two players that is found to be very
predcitve in his stochastic models, while James [3] has done
thorough study on probability formulas and statistical analysis on tennis matches. Recent researchers began to apply machine learning on tennis pre-game predictions based
on past performance (including previous encounter, current
ranking, etc), such as Sipko [9], and Madurska[6] - whose
by-set method inspired us.
Our project seeks to apply classification algorithms from
machine learning to model men’s professional singles matches
by using both pre-game, historical performance calcualted
via a common opponent model [5], and real-time, in-game
stats [4] [6]. As pointed out by Sipko [9], this in-game approach "allows the model to capture the change in a player’s
performance over the course of the match. For example,
different players fatigue during a match in different ways."
We hope that results from our predictions can be extended
to give real-time coaching advice to support game strategy
decision.
3 Dataset and Features
3.1 Dataset & pre-processing
This project employs two open source datasets for labels
and features, authored by Jeff Sackmann [8][4]: the Match
Charting Project, which contains set level data from 1442
matches spanning from 1974 to 2017; and the Tennis ATP
dataset which contains match level data from 1969 to 2017.
There are a few pre-processing steps needed to make the
data useful, such as:
• Picking date range: Matches from 2000 - 2017 are
used as samples (1415 matches) to focus on the comtemporary game of Tennis.
• Removing duplicates via match id: Since both
datasets are manually entered via crowdsourcing, there
are some inaccuracy and duplication that require our
pre-processing.
• Removing Davis Cup: Davis Cup is the World Cup
of tennis, where players play for their country. We
decided to remove all Davis Cup entries since group
matches may include strategic moves that are considerably different from individual tournaments.
1
• Merging Tennis ATP & Match Charting Project:
Real-time stats are only found in the Match Charting
Project dataset whereas historical performance can be
computed from Tennis ATP. Two datasets need to be
merged to give us necessary flexibility and features
to test our ideas. They are merged on player’s first
and last names, with the rare cases of players with
duplicate names removed manually.
• Standardizing Features We are unable to extract
all features listed in Sipko [9]. While extracting features from the Tennis ATP was easy, the Match Charting Project data proves non-trivial with its detailed
stats and fragmented file structure. We managed to
extract a subset of all possible features from processing the point-by-point data, and standardized across
the historical and current features.
3.2 Feature Extraction
The original dataset denotes Player 1 as the winner and
Player 2 as the loser. While processing, we decide to represent each set in each match with two rows, one from each
player’s perspective, and label the match result accordingly
(1 and -1 for win and loss, respectively). Thus we have
one row per player per set per match, containing features
from historical data and real time data. Historical data
includes match details and player’s past performance; realtime data, for the scope of this project, will be defined as
the performance from all previous sets in the match:
1. A vector of input features (X), describing the performance in previous set and historical performance from
one player’s perspective
2. A target value (y), indicating the match outcome. y ∈
{1, −1}
3.2.1 Symmetric Feature Representation
There are two approaches to represent features from two
players. First, we can have two features for the same metric
(e.g. RANK1 and RANK2). This approach doubles the
number of features, but also provides a quantitative measure
that we can compare across all players. Second, we can look
at differences between two players (e.g. RANKDIF F =
RANK1 − RANK2). This would reduce the number of
features, but does not allow the model to compare across
players. Previous research has shown that the difference
variables are predictive enough [9] [3] for past performance
(on match level). For current performance (on set level),
we evaluated the performance of both approaches. There
was no difference in terms of accuracy, hence the difference
model was used for current match as well for consistency.
3.2.2 Common Opponent Model for Past Performance
We use a method proposed by Knottenbelt [5] and extended
by Sipko [9] to construct difference variables capturing player
characteristics and past performance, by using their common opponents to achieve a fair comparison. The detailed
code can be found in our codebase, while the process works
as follows:
• Identify a set of common opponents between the two
players of a given match.
• Compute the average performance of both players against
the common opponent.
• Take the difference between average performance for
each extracted feature.
3.2.3 Edge Cases for Common Opponents
We have run into 2 edge cases: (1) when at least one of the
players is new; (2) when two players do not have any common opponents. Upon investigation, our solution is: (1)
when the player is new with no historical data, we remove
the samples, which consist of 84 data points out of 1421
matches; (2) when two players do not have any common
opponents, we compute the average for each player (regardless of opponents) and take the difference, which consist of
74 out of 1421 matches. Note, as described in Section 3.2,
our final sample size will contain 2x ∗ 1421 rows, where x is
the number of sets played in each match.
It’s worth noting that whenever we encounter NULLs
in the feature dataset, we remove the entire row to avoid
the confusion introduced by potentially using different nullfilling options, and to be consistent and rigorous. This reduces available data points for training and evaluation, and
could potentially impact model performance.
3.3 Feature Lists
3.3.1 Features from historical matches
Features are the difference variables averaged for both players obtained from a common opponent model [5], unless
otherwise noted. They are:
• Performance Features: Number of aces, double
faults, break points faced and saved; Percentages of
winning on first and second serves, and first serve in
rate.
• Match Details: Match duration in minutes, number
of serve games, number of serve points per game
• Player Bio: ATP Rank, ATP Rank Points, same
handedness, height
We also extracted and added two more features to the models after the first pass of the project and diagnostics that reveal high bias as our main hindrance of performance, which
we will elaborate further in Section 5. The two added features are duration win/loss rate which calculates the average difference in duration (in minutes) of the past matches
each player won or lost respectively, using the Common Opponent Model, and age diff win/loss rate, which calculates the average age difference of the past matches each
player won or lost respectively, using the same Common
Opponent Model.
3.3.2 Features from current match performance
• Performance Features Number of aces, double faults,
winners and total points won; Percentage of winning
on first and second serve, return points won, first serve
in
• Match Details Surface (hard, grass, or clay), match
type
• Player Bio Same handedness
2
4 Method
4.1 Logistic Regression
As a start, we applied logistic regression on the data using
Scikit-Learn’s implementation[7]. The L2-penalized model
minimizes the cost function below:
min
w,c
Xn
i=1
log(e
−yi(XT
i w+c) + 1) + 1
2
w
T w
The solver implemented in the code uses a coordinate descent algorithm, and the detailed proof can be found in
Hsieh 2008 [2]
4.2 Support Vector Machine
Next, we used a linear support vector classifier from ScikitLearn [7] to predict the tennis match outcome. Given the
training vectors xi ∈ R
n and the label vector y = {1, −1}
where 1 represents a win and -1 a loss, we can formulate
the support vector machine as solving the following primal
problem:
minw,b,ς Xn
i=1
ςi +
1
2
w
T w
s.t.yi(w
T
θ(xi) + b) ≥ 1 − ςi
, ςi ≥ 0
Its dual is
min
α
1
2
α
T Qα − e
T α
s.t.yT α = 0, 0 ≤ α ≤ 1
where e is the vector of all ones, and Qi,j = yiyjK(xi
, xj ),
and K(xi
, xj ) is the kernel here. We tried different kernels including linear, RBF (where K(xi
, xj ) = exp(−γ||xi−
xj ||2
)), and polynomial (where K(xi
, xj ) = (x
T
i xj + c)
d
),
and have documented performance below in Section 5.
4.3 Other algorithms
Moreover, we implemented Naive Bayes as a classifier, to
check the model performance. We were curious to test if
Naive Bayes classifier works well; and if so, whether this
indicates that the features are conditionally independent -
i.e. break point percentage, rank difference, and all other
features don’t really relate to each other as long as I win
the matches. Given a class variable y = {1, −1} and a
dependent feature vector x1 through xn, Bayes’ theorem
states the following relationship:
P(y|x1, ..., xn) = P(y)P(x1, ..., xn|y)
P(x1, ..., xn)
In particular, we have chosen the Gaussian Naive Bayes algorithm following the assumption that X with respect to
y = {1, −1} is distributed according to a Gaussian distribution. This gives us the feature likelihood as
P(xi
|y) = 1
q
2πσ2
y
exp(−
(xi − µy)
2
2σ
2
y
)
And we use the following classification rule:
yˆ = arg max
y
P(y)Πn
i=1P(xi
|y)
We mainly used Naive Bayes to benchmark model performance against logistic regression and SVC, as it is extremely
fast to run.
5 Experiments, Results, Discussion
We organized discussionin the following 4 questions. While
a preliminary set of results were presented during the poster
session, we had major overhauls in the past few days as we
tried more models and fine-tuned parameters within existing algorithm choices. In particular, we found that SVC
with a RBF kernel actually outperforms all our hybrid data
models, albeit with a slightly bigger variance. As a result
of this more thorough ad rigorous exploration, the results
presented here will be different from the preliminary look
from the poster session.
5.1 Parameters, Metrics
For logistic regression, we chose L2 regularization with the
liblinear Algorithm [2] to use in the optimization solver.
For small datasets, liblinear is shown to perform really well.
The penalty function makes sure that we don’t overfit. For
SVC, we explored multiple options such as linear, poly and
RBF based on empirical performance on dev set, and used
RBF (Gaussian) kernel for historical only data model and
linear kernel for the rest. We think this choice makes sense
as RBF kernels are general purpose and usually the first
thing to try when we are not processing text. We also used
squared hinge loss (max(0, −)
2
) to penalize violated margins more strongly, based on emprical evidence on our particular dataset. Moreover, we used L2 regularization as
well, as penalizing large weights tends to improve generalization (because it means that no input dimension can
have a very large influence on the scores all by itself) and
thus avoids overfitting. As evident by results presented below, this is part of our effort to encourage models to prefer
smaller and more diffuse weight vectors (to counteract the
fact that a very small subset of features account for most
predictive power). The classifier is thus "encouraged" to
take into account all input dimensions to small amounts
rather than a few input dimensions and very strongly, ideally. Lastly, we set the max iteration count to 100,000 as
SVM may not converge.
Cross-validation (10-fold) is done on all the results to ensure robustness. The general random split of train-dev-test
(60:20:20) is also observed. We compared different models using the dev set for evaluation; once we had the best
model, we passed that through the test set for a final model
accuracy score.
We mainly looked at accuracy as our success criterion,
which calculates how many labels our model predicts correctly out of all the dev/test labels. We used the term
"score" interchangeably with accuracy in this report.
5.2 How well can we predict tennis matches?
To evaluate model performance, it’s important to note that
for linear SVC and logistic regression, we capped the number of features to 15 - due to the penalty functions in place,
we observed that accuracy drops sharply after we exceed
15 features using RFE. This can be clearly seen in Figure 5.1. Our best model, which uses only historical with a
RBF-kernel SVC predicts with 94.6% accuracy on test set,
after being trained using cross-validation on the train set.
The detailed performance comparison of each data method
on test score (with best performing machine learning algorithm, after being trained on the train set) can be seen in
Table 5.1. We have included the detailed dev set accuracy
3
Figure 5.1: Accuracy vs. Number of Features
information in the appendix. This is a surprising learnTable 5.1: Different Modeling Method Test Accuracy
Comparison
Data Model Best Performing Algorithm
Test Accuracy
Historical
Data Only
SVC with RBF
kernel
86.5%, std.dev
= 4.2%
Real-Time
Data Only,
After Set 1
Logistic Regression, capped at
15 features
79.0%, std.dev
= 0%
Historical +
Current Data
(after Set 1)
Linear SVC,
capped at 15
features
80.1%, std.dev
= 0.7%
Historical +
Current Data
(after Set 2)
Linear SVC,
capped at 15
features
86.0%, std.dev
= 3.7%
ing to us: using past performance alone really gives the
best prediction. It also suggests that bringing in more data
in the form of real-time stats actually worsens the model
performance, due partly to the presence of penalty functions. However, once we bring in real-time stats after set 2,
we almost have the on-par model performance again (with
smaller variance). Thus, using real-time info seems to reduce variances, as models built on only historical data show
a greater variance compared to any hybrid data models.
Moreover, as RBF kernel’s performance is largely determined by γ (the spread of the kernel, determining the decision boundary) and C (penalty), we tested lower C values
to be more tolerant of misclassified points in order to reduce
variance, at the expense of bias. Once we found a good C
value, we picked a γ that’s near C and also close to 1
n
as
suggested by conventional wisdom. In the end, the optimal
pair we find is γ = 0.25, C = 0.27. Our eventual learning
curve of the SVC-RBF is included in Figure 5.2. Given the
particular kernel choice of RBF, the results generated new
hypotheses for us: could it mean that tennis match features,
at least those we extracted, are not linearly separable but
become separable on a higher dimension? Is using hinge loss
strictly better than logistic loss? Our findings land support
to these initial guesses that we can extend in our future
work, to understand more about tennis match data.
Figure 5.2: SVC-RBF Learning Curve
5.3 Does using current, real-time info
improve accuracy?
No, it does not. Historical data alone, when coupled with
SVC on RBF kernel, gives by far the best performance in
all our runs. We have included confusion matrices below to
to further compare performances (Tables 5.2, 5.3).
Table 5.2: Historical Only
TRUE FALSE
POSITIVE 52.7% 0.1%
NEGATIVE 47.1% 0.1%
Table 5.3: Historical + After Set 2
TRUE FALSE
POSITIVE 42.9% 6.3%
NEGATIVE 44.4% 6.4%
5.4 What features are the most predictive,
for linear models?
Using recursive feature elimination (RFE) across our data
models and linear algorithms, we find that TTL (total points
won), which indicates how many points one player has won
in the match up till our cut-off point, is the most important feature. Adding more features only leads to minimal
improvement at best, for linear algorithms. In most cases,
having TTL alone almost always yields the best performance, especially with penalty function enabled. Other top
features include: RCV (% of return points won) from realtime data, BPP (breaking point saving %) if only historical
match data are used. The graphs of how accuracy changes
with number of features are included below in Figure 5.1;
notice how it drops over time due to L2 regularization in
both methods.
5.5 Diagnostics
While fine-tuning our hybrid data models (in an effort to
beat historical only data model), we observed the problem
of high bias manifested as the small gap between training
and test errors after plotting the learning curves for logistic
regression model in Figure 5.3, corroborated by learning
curves from linear SVC in Figure 5.4.
4
Figure 5.3: Logistic Regression Learning Curve
Figure 5.4: Linear SVC Learning Curve
To combat high bias, we turn to unimplemented new features as this is the best solution outlined in Andrew Ng’s
error analysis slides. Despite other available features, our
models learned that the information contained in other additional features (such as number of double faults or aces,
etc.) is mostly already captured by TTL. Therefore, we
need to find features that are complementary to TTL, revealing information that could let to a "comeback" even if
the player is at the moment behind, in order to get a more
accurate prediction. Naturally, we think of a player’s endurance and resillience, and look for features that could reflect similar traits. The two features added after the poster
session for this purpose were:
1. duration win/loss rate: Average duration of games
won - average duration of games lost
2. age diff win/loss rate: Average age of opponent
beaten - average age of opponent lost to
However, we realized only the historical data model benefited slightly after adding these two features, using the original "best" algorithm. We do not observe any change in
performance or top features’ relative rankings when using
other algorithms.
6 Future Work
For future work, there are still unimplemented features that
we think will improve the model accuracy, such as: the (relative) importance of tournaments/matches for player, the
number of matches a player had in the days before this
match (as a proxy for fatigue), the tightness in schedule and
intensity of those matches, number of matches the player
played before in similar environment (location, weather,
surface), time decaying factor, etc. It will also be interesting
to see if historical + current data give better performance
with updated feature lists.
7 Conclusion
The use of common opponent model and difference variables
already offer high predictive power when coupled with SVC
with a RBF kernel. And it’s insightful to learn that for realtime prediction and linear models, total points won from before can really tell who is more likely to win, and a player’s
performance when faced with break points directly indicates
his chance of winning. We also learnt that when making ingame predictions, historical performance data matter the
most for accuracy and in-game stats hardly matter - i.e.
most players actually carry some kind of "memory" when
playing. Moreover, we showed that high bias is the main
issue for tennis prediction models, and any future model
should take this into consideration by coming up with creative features derived from detailed point-by-point data for
the maximal gain in accuracy.
8 Appendix
8.1 Results: Dev set score for all algorithms
Values subject to random seed and fluctuations.
• Historical data only: logistic 0.705, linear SVC
0.512, SVC + RBF kernel for 15 features 0.869, SVC
+ poly kernel for 15 features 0.455, SVC + linear kernel for 15 features 0.583, SVC + RBF kernel for
all features 0.891, SVC + poly kernel for all features 0.476, SVC + linear kernel for all features 0.470,
Naive Bayes with 15 features 0.676, Naive Bayes with
all features 0.673
• Real-time data only: logistic 0.786, linear SVC
0.606, SVC + RBF kernel for 15 features 0.642, SVC +
poly kernel for 15 features 0.529, SVC + linear kernel
for 15 features 0.663, SVC + RBF kernel for all features 0.642, SVC + poly kernel for all features 0.529,
SVC + linear kernel for all features 0.663, Naive Bayes
with 15 features 0.786, Naive Bayes with all features
0.786
• Historical + After 1st set: logistic 0.790, linear
SVC 0.805, SVC + RBF kernel for 15 features 0.776,
SVC + poly kernel for 15 features 0.765, SVC + linear kernel for 15 features 0.805, SVC + RBF kernel for all features 0.505, SVC + poly kernel for all features 0.587, SVC + linear kernel for all features 0.554,
Naive Bayes with 15 features 0.780, Naive Bayes with
all features 0.772
• Historical + After 2nd set: logistic 0.855, linear
SVC for 15 features 0.860, SVC + RBF kernel for
15 features 0.789, SVC + poly kernel for 15 features
0.815, SVC + RBF kernel for all features 0.504, SVC
+ poly kernel for all features 0.454, SVC + linear kernel for all features 0.570, Naive Bayes with 15 features
0.831, Naive Bayes with all features 0.831
5
9 Contributions
9.1 Yang "Eddie" Chen
• Researched, reviewed and synthesized relevant literature for applicable ideas and the Related Work section, such as Clarke and Dyte [1] and O’Malley [3] for
difference variable, and Knottenbelt [5] for the common opponent model
• Implemented the Common Opponent Model to look
up players stats from common opponents
• Generated ATP Match results for labels
• Applied math fomulations from machine learning models & techniques learned from class, namely logistic
regression, SVM and Naive Bayes.
• Conducted error analyses along with Yi & Yubo to
understand the root cause of our performance curve,
and proposing new checks and solutions.
• Typsetted (LATEX) the project milestone report, contributed in the poster making, and wrote, typesetted
& synthesized the final report.
9.2 Yubo Tian
• Feature extraction: generated real-time set-level performance data from Sackmann’s MCP [4]
• Data labeling: extracted set level match results from
player points information from Sackmann’s MCP [4]
• Data processing: joined match-general information,
historical data and real-time match data; fixed various
issues encountered during the process; wrote scripts to
generate all data and labels upon one click
• Initial modeling/error analysis: trained logistic regression model on joined data
• Feature analysis and improvement: after initial modeling, analyzed feature selection results and train/dev
errors, designed and extracted additional features in
an attempt to fix the high bias problem exposed
• Plot and Report: wrote scripts to plot learning curves;
contributed to milestone/ final report contents.
9.3 Yi Zhong
• Feature extraction: get match details related features
from MatchChartingProject,
• Data processing: Joined data by linking real-time match
data from MCP [4] to match details data from ATPMatches [8] (methods: playerID, playerName etc) (with
Yubo).
• Modeling: Wrote the script for logistic, SVC and other
model exploration for different data model
• Error analysis: Wrote the graph script for recursive
feature elimination, confusion matrix, feature ranking
References
[1] Stephen R. Clarke and David Dyte. Using official ratings to simulate major tennis tournaments. International Transactions in Operational Research, 7(6):585 –
594, 2010.
[2] Cho-Jui Hsieh, Kai-Wei Chang, Chih-Jen Lin, S Sathiya
Keerthi, and Sellamanickam Sundararajan. A dual coordinate descent method for large-scale linear svm. In
Proceedings of the 25th international conference on Machine learning, pages 408–415. ACM, 2008.
[3] O’Malley A. James. Probability formulas and statistical
analysis in tennis. Journal of Quantitative Analysis in
Sports, 4(2):1–23, April 2008.
[4] et al. Jeff Sackmann. The tennis abstract match charting
project, 2017.
[5] William J. Knottenbelt, Demetris Spanias, and Agnieszka M. Madurska. A common-opponent stochastic
model for predicting the outcome of professional tennis matches. Computers and Mathematics with Applications, 64(12):3820 – 3827, 2012. Theory and Practice of
Stochastic Modeling.
[6] Agnieszka M. Madurska. A set-by-set analysis method
for predicting the outcome of professional singles tennis
matches. MEng computing- final year project, Imperial
College London, amm208@doc.ic.ac.uk, June 2012.
[7] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. ournal
of Machine Learning Research, 12:2825–2830, 2011.
[8] Jeff Sackmann. Atp tennis rankings, results, and stats,
2017.
[9] Michal Sipko. Machine learning for the prediction of
professional tennis matches. MEng computing - final
year project, Imperial College London, June 2015.
6
```