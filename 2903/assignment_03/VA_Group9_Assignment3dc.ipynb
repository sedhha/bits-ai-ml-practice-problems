{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - 03\n",
    "### Group ID: 09\n",
    "### Group Members Name with Student ID:\n",
    "\n",
    "| Student Name       | Student ID    | Contribution |\n",
    "|--------------------|---------------|--------------|\n",
    "| Shivam Sahil            | 2023aa05280   | 100%         |\n",
    "| Gali Jahnavi       | 2023aa05684   | 100%         |\n",
    "| Michael Joshua     | 2023aa05023   | 100%         |\n",
    "\n",
    "## Subject - Video Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context # To avoid SSL error checks\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from re import search as search_regex\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, TimeDistributed, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.patches import Rectangle\n",
    "import kagglehub\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "from matplotlib import gridspec\n",
    "from collections import defaultdict\n",
    "from matplotlib.collections import LineCollection\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Utilities\n",
    "def get_dataset_path():\n",
    "    return r'tennis_player_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_environment_and_shot_name_from_file_name(file_name):\n",
    "    environment_name = \"outdoor\"\n",
    "    shot_name = \"straight\"\n",
    "    if(\"virtual field\" in file_name.lower()):\n",
    "        environment_name = \"virtual\"\n",
    "    if(\"crosscourt shot\" in file_name.lower()): # File name comes as - tennis_player_dataset/Virtual Field - Crosscourt Shot.csv\n",
    "        shot_name = \"cross\"\n",
    "    \n",
    "    return environment_name, shot_name\n",
    "\n",
    "def get_environment_from_video_file_path(path_parts):\n",
    "    environment = \"outdoor\"\n",
    "    shot_name = \"straight\"\n",
    "    view_name = \"top\"\n",
    "    # Extract metadata\n",
    "    envID = path_parts[0]  # \"outdoor field\" or \"virtual field\"\n",
    "    shotID = path_parts[1]  # \"cross court shot\" or \"straight shot\"\n",
    "    viewID = path_parts[2]  # \"side view\" or \"top view\"\n",
    "    fileID = path_parts[3][0:3] # OCT / OCS / OSS etc\n",
    "    \n",
    "    if \"virtual\" in envID.lower():\n",
    "        environment = \"virtual\"\n",
    "    if \"cross-court\" in shotID.lower():\n",
    "        shot_name = \"cross\"\n",
    "    if \"side\" in viewID.lower():\n",
    "        view_name = \"side\"\n",
    "        \n",
    "    return environment, shot_name, view_name, fileID\n",
    "    \n",
    "def load_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Load video files and annotations from the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    data_path (str): Path to the root folder containing the dataset\n",
    "    \n",
    "    Returns:\n",
    "    videos (list): List of dictionaries containing video information\n",
    "    annotations (list): List of dictionaries containing annotation information\n",
    "    \"\"\"\n",
    "    videos = []\n",
    "    annotations = []\n",
    "    \n",
    "    # Define video file extensions\n",
    "    video_extensions = ['.mp4', '.avi', '.mov']\n",
    "    \n",
    "    # Find all CSV files at the root level\n",
    "    csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Dictionary to store loaded CSV data\n",
    "    csv_data = {}\n",
    "    \n",
    "    # Load all CSV files\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(data_path, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        environment, shot_type = get_environment_and_shot_name_from_file_name(csv_path)        \n",
    "        # Store the dataframe with a key that we can match to video folders\n",
    "        key = f\"{environment}/{shot_type}\"\n",
    "        csv_data[key] = df\n",
    "    \n",
    "    # Walk through all directories\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            # Check if file is a video\n",
    "            if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "                # Get the full path to the video\n",
    "                video_path = os.path.join(root, file)\n",
    "                \n",
    "                # Extract metadata from path\n",
    "                rel_path = os.path.relpath(video_path, data_path)\n",
    "                path_parts = rel_path.split(os.sep)                \n",
    "                # Skip if not enough path parts to determine metadata\n",
    "                if len(path_parts) < 4:\n",
    "                    continue\n",
    "                \n",
    "                # Extract metadata\n",
    "                environment, shot_folder, view_type, shot_descriptor = get_environment_from_video_file_path(path_parts)\n",
    "                \n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                match = search_regex(r'\\d+', file_name)\n",
    "                if not match:\n",
    "                    raise ValueError(f'Got Invalid file name: %s, Expected in OCS/OCT format' % file_name)\n",
    "                video_index = int(match.group())                \n",
    "                # Create a lookup key for CSV data\n",
    "                lookup_key = f\"{environment}/{shot_folder}\"\n",
    "                # print('kk<-',lookup_key)\n",
    "                \n",
    "                \n",
    "                # Check if we have annotations for this video\n",
    "                annotation_data = None\n",
    "                if lookup_key in csv_data and 0 <= video_index - 1 < len(csv_data[lookup_key]):\n",
    "                    # Get the annotation row for this video (index-1 because CSV is 1-indexed)\n",
    "                    annotation_data = csv_data[lookup_key].iloc[video_index - 1].to_dict()\n",
    "                else: \n",
    "                    print(f'Lookup key: {lookup_key} || {video_index}')\n",
    "                \n",
    "                # Load video metadata\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                cap.release()\n",
    "                \n",
    "                # Create video info dictionary\n",
    "                video_info = {\n",
    "                    'path': video_path,\n",
    "                    'environment': environment,\n",
    "                    'shot_type': shot_folder,\n",
    "                    'view_type': view_type,\n",
    "                    'shot_descriptor': shot_descriptor,\n",
    "                    'index': video_index,\n",
    "                    'frame_count': frame_count,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'fps': fps\n",
    "                }\n",
    "                \n",
    "                videos.append(video_info)\n",
    "                \n",
    "                # If we have annotation data, add it\n",
    "                if annotation_data is not None:\n",
    "                    annotation_info = {\n",
    "                        'video_path': video_path,\n",
    "                        'index': video_index,\n",
    "                        'to_sideline_distance': annotation_data['To-Closest-Doubles-Sideline-Distance (m)'],\n",
    "                        'to_baseline_distance': annotation_data['To-Baseline-Distance (m)']\n",
    "                    }\n",
    "                    annotations.append(annotation_info)\n",
    "    \n",
    "    print(f\"Loaded {len(videos)} videos and {len(annotations)} annotations\")\n",
    "    return videos, annotations\n",
    "\n",
    "def visualize_annotations(frame, annotation, court_dimensions=None):\n",
    "    \"\"\"\n",
    "    Draw annotations on a tennis court frame\n",
    "    \n",
    "    Parameters:\n",
    "    frame (numpy.ndarray): The video frame to annotate\n",
    "    annotation (dict): Annotation data containing court positions\n",
    "    court_dimensions (tuple, optional): (width, height) of court in meters for scaling\n",
    "    \n",
    "    Returns:\n",
    "    annotated_frame (numpy.ndarray): Frame with annotations drawn\n",
    "    \"\"\"\n",
    "    # Make a copy of the frame to avoid modifying the original\n",
    "    annotated_frame = frame.copy()\n",
    "    \n",
    "    # If no annotation, return the original frame\n",
    "    if annotation is None:\n",
    "        return annotated_frame\n",
    "    \n",
    "    # Get frame dimensions\n",
    "    h, w = annotated_frame.shape[:2]\n",
    "    \n",
    "    # Default court dimensions if not provided\n",
    "    if court_dimensions is None:\n",
    "        # Standard tennis court: 23.77m x 10.97m (singles)\n",
    "        court_dimensions = (23.77, 10.97)\n",
    "    \n",
    "    # Extract distances from annotation\n",
    "    sideline_distance = annotation['to_sideline_distance']\n",
    "    baseline_distance = annotation['to_baseline_distance']\n",
    "    \n",
    "    # Calculate approximate player position in the frame\n",
    "    # This is a simplification and will need to be adjusted for your specific setup\n",
    "    \n",
    "    # For side view (adjust these constants based on your specific videos)\n",
    "    if 'side' in annotation['video_path']:\n",
    "        # In side view, x corresponds to baseline distance and y is fixed\n",
    "        x_ratio = baseline_distance / court_dimensions[0]\n",
    "        x_pos = int(w * (1 - x_ratio))  # Assuming baseline is on the right\n",
    "        y_pos = int(h * 0.8)  # Fixed height for side view (adjust as needed)\n",
    "    \n",
    "    # For top view\n",
    "    else:\n",
    "        # In top view, x corresponds to sideline distance and y to baseline distance\n",
    "        x_ratio = sideline_distance / court_dimensions[1]\n",
    "        y_ratio = baseline_distance / court_dimensions[0]\n",
    "        \n",
    "        x_pos = int(w * x_ratio)\n",
    "        y_pos = int(h * y_ratio)\n",
    "    \n",
    "    # Draw the player position (red circle)\n",
    "    cv2.circle(annotated_frame, (x_pos, y_pos), 20, (0, 0, 255), -1)\n",
    "    \n",
    "    # Add text with distances\n",
    "    text = f\"Sideline: {sideline_distance:.2f}m, Baseline: {baseline_distance:.2f}m\"\n",
    "    cv2.putText(annotated_frame, text, (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Draw court grid (optional, for better visualization)\n",
    "    # Horizontal lines (baselines and service lines)\n",
    "    cv2.line(annotated_frame, (0, int(h*0.2)), (w, int(h*0.2)), (0, 255, 0), 1)  # Far baseline\n",
    "    cv2.line(annotated_frame, (0, int(h*0.8)), (w, int(h*0.8)), (0, 255, 0), 1)  # Near baseline\n",
    "    \n",
    "    # Vertical lines (sidelines and center line)\n",
    "    cv2.line(annotated_frame, (int(w*0.25), 0), (int(w*0.25), h), (0, 255, 0), 1)  # Left sideline\n",
    "    cv2.line(annotated_frame, (int(w*0.5), 0), (int(w*0.5), h), (0, 255, 0), 1)    # Center line\n",
    "    cv2.line(annotated_frame, (int(w*0.75), 0), (int(w*0.75), h), (0, 255, 0), 1)  # Right sideline\n",
    "    \n",
    "    return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Video Annotations\n",
    "data_path = get_dataset_path()\n",
    "videos, annotations = load_dataset(data_path)\n",
    "# Docs reference - https://www.perplexity.ai/search/what-is-oct-ocs-oss-ost-in-ten-Dj9bu0BIT7axbNk6r7rOSg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Player Detection and Tracking\n",
    "Implement algorithms to detect and track tennis players throughout a match.\n",
    "\n",
    "a) Develop a player detection model using a deep learning approach (e.g., YOLO, Faster R-CNN).\n",
    "\n",
    "b) Implement a tracking algorithm to maintain player identities across frames.\n",
    "\n",
    "c) Handle occlusions and camera movement typical in broadcast footage.\n",
    "\n",
    "d) Evaluate your algorithm's performance against the provided ground truth annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a player detection model using a deep learning approach (e.g., YOLO, Faster R-CNN).\n",
    "# We're using YOLO along with Kalman Detector to detect and track person\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Implement a tracking algorithm to maintain player identities across frames.\n",
    "# Kalman Filter for 2D tracking\n",
    "# ---------------------------\n",
    "class KalmanFilter2D:\n",
    "    def __init__(self, x, y, vx=0, vy=0):\n",
    "        self.state = np.array([[x], [y], [vx], [vy]], dtype=np.float32)\n",
    "        self.F = np.array([[1, 0, 1, 0],\n",
    "                           [0, 1, 0, 1],\n",
    "                           [0, 0, 1, 0],\n",
    "                           [0, 0, 0, 1]], dtype=np.float32)\n",
    "        self.H = np.array([[1, 0, 0, 0],\n",
    "                           [0, 1, 0, 0]], dtype=np.float32)\n",
    "        self.Q = np.eye(4, dtype=np.float32) * 0.01\n",
    "        self.R = np.eye(2, dtype=np.float32) * 5.0\n",
    "        self.P = np.eye(4, dtype=np.float32)\n",
    "\n",
    "    def predict(self):\n",
    "        self.state = np.dot(self.F, self.state)\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "        return self.state\n",
    "\n",
    "    def update(self, z):\n",
    "        y = z.reshape(-1, 1) - np.dot(self.H, self.state)\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "        self.state += K @ y\n",
    "        I = np.eye(self.P.shape[0], dtype=np.float32)\n",
    "        self.P = (I - K @ self.H) @ self.P\n",
    "\n",
    "def get_center(box):\n",
    "    cx = (box[0] + box[2]) / 2\n",
    "    cy = (box[1] + box[3]) / 2\n",
    "    return np.array([cx, cy], dtype=np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# Handle occlusions and camera movement typical in broadcast footage.\n",
    "# Track class for strongest detection\n",
    "# ---------------------------\n",
    "class Track:\n",
    "    def __init__(self, track_id, box):\n",
    "        cx, cy = get_center(box)\n",
    "        self.kf = KalmanFilter2D(cx, cy)\n",
    "        self.box = box\n",
    "        self.id = track_id\n",
    "        self.misses = 0\n",
    "\n",
    "    def predict_and_update(self, box=None):\n",
    "        self.kf.predict()\n",
    "        if box is not None:\n",
    "            cx, cy = get_center(box)\n",
    "            self.kf.update(np.array([cx, cy], dtype=np.float32))\n",
    "            self.box = box\n",
    "            self.misses = 0\n",
    "        else:\n",
    "            self.misses += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Running tracking in one of the sample videos\n",
    "# ---------------------------\n",
    "video = videos[8]\n",
    "path = video['path']\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "track = None\n",
    "next_id = 0\n",
    "MAX_MISSES = 10\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.predict(frame, conf=0.5, imgsz=640)[0]\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()\n",
    "    confs = results.boxes.conf.cpu().numpy() if hasattr(results.boxes, 'conf') else [1.0] * len(boxes)\n",
    "    \n",
    "    detections = []\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        conf = confs[i]\n",
    "        detections.append([x1, y1, x2, y2, conf])\n",
    "    \n",
    "    # Find the strongest detection only if we haven't set a track yet.\n",
    "    if track is None and detections:\n",
    "        strongest_detection = max(detections, key=lambda d: d[4])\n",
    "        strongest_box = strongest_detection[:4]\n",
    "        track = Track(next_id, strongest_box)\n",
    "        next_id += 1\n",
    "    else:\n",
    "        # Once the track is set, ignore new detections and simply predict.\n",
    "        track.predict_and_update(None)\n",
    "        if track.misses > MAX_MISSES:\n",
    "            track = None\n",
    "\n",
    "    # Visualization\n",
    "    if track is not None:\n",
    "        x1, y1, x2, y2 = track.box\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Player\", (int(x1), int(y1) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shot Classification and Analysis\n",
    "\n",
    "Develop a system to classify different tennis shots and analyze their characteristics.\n",
    "\n",
    "a) Implement a machine learning model to classify shot types (e.g., serve, forehand, backhand, volley).\n",
    "\n",
    "b) Extract relevant features for each shot (e.g., player pose, racket position, ball trajectory).\n",
    "\n",
    "c) Analyze shot patterns and their effectiveness based on court position and game context.\n",
    "\n",
    "d) Visualize shot distributions and success rates for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_video_and_annotations():\n",
    "    # Assumes that video and annotations are already processed\n",
    "    combined_data = []\n",
    "    for index, video in enumerate(videos):\n",
    "        combined_data.append({\n",
    "            **video,\n",
    "            **{\n",
    "                'to_sideline_distance': annotations[index]['to_sideline_distance'],\n",
    "                'to_baseline_distance': annotations[index]['to_baseline_distance'],\n",
    "            }\n",
    "        })\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define a function to load and process video frames.\n",
    "def extract_frames(video_path, num_frames=20):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    \n",
    "    for i in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = frame / 255.0  # Normalize\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Cell 4: Prepare the dataset using the video_data list.\n",
    "# Cell: Prepare the dataset as before\n",
    "def prepare_shot_classification_data(video_data):\n",
    "    X = []\n",
    "    y = []\n",
    "    # Map shot descriptors to numerical labels\n",
    "    shot_types = {'forehand': 0, 'backhand': 1, 'serve': 2, 'volley': 3}\n",
    "    env_set = set()\n",
    "    \n",
    "    for data in tqdm(video_data, desc=\"Processing videos\"):\n",
    "        # Normalize the shot descriptor to ensure consistent matching\n",
    "        shot_desc = data['shot_descriptor'].strip().upper()\n",
    "        \n",
    "        # Map shot descriptor to shot type\n",
    "        if 'OCT' in shot_desc:  # Example mapping - adjust as needed\n",
    "            shot_type = 'forehand'\n",
    "        elif 'OST' in shot_desc:\n",
    "            shot_type = 'backhand'\n",
    "        elif 'OCS' in shot_desc:\n",
    "            shot_type = 'volley'\n",
    "        else:\n",
    "            shot_type = 'serve'\n",
    "            \n",
    "        # Extract frames using your function (ensure extract_frames is defined)\n",
    "        frames = extract_frames(data['path'])\n",
    "        X.append(frames)\n",
    "        \n",
    "        # Track environment information\n",
    "        env = data['environment'].strip().lower()\n",
    "        env_set.add(env)\n",
    "        \n",
    "        # Append the corresponding label\n",
    "        y.append(shot_types.get(shot_type, 0))\n",
    "    \n",
    "    return np.array(X), np.array(y), list(env_set)\n",
    "\n",
    "# Create the shot classification model\n",
    "def create_shot_classification_model(num_frames=20, num_classes=4):\n",
    "    # Base model for feature extraction\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Create a time-distributed model to process each frame\n",
    "    model = Sequential([\n",
    "        TimeDistributed(base_model, input_shape=(num_frames, 224, 224, 3)),\n",
    "        TimeDistributed(Flatten()),\n",
    "        LSTM(256, return_sequences=True),\n",
    "        LSTM(128),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train shot classification model\n",
    "def train_shot_classifier(X, y, env_list):\n",
    "    train_indices = [i for i, env in enumerate(env_list) if env.lower() == 'virtual']\n",
    "    test_indices = [i for i, env in enumerate(env_list) if env.lower() == 'outdoor']\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    print('Test Train Split done')\n",
    "    \n",
    "    model = create_shot_classification_model()\n",
    "    print('Model Created')\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=10,\n",
    "        batch_size=8\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "video_data = combine_video_and_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "X, y, env_list = prepare_shot_classification_data(video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_shot_classifier(X, y, env_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Feature Extraction for Shot Analysis\n",
    "Let's implement feature extraction for tennis shots, including player pose, racket position, and ball trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-trained model for pose estimation\n",
    "def load_pose_model():\n",
    "    model_path = kagglehub.model_download(\"google/movenet/tensorFlow2/singlepose-lightning\")\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    movenet = model.signatures['serving_default']\n",
    "    return movenet\n",
    "\n",
    "# Function to detect player pose\n",
    "def detect_pose(frame, pose_model):\n",
    "    # Prepare input frame\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_resized = tf.image.resize_with_pad(np.expand_dims(frame_rgb, axis=0), 192, 192)\n",
    "    input_img = tf.cast(frame_resized, dtype=tf.int32)\n",
    "    \n",
    "    # Get pose results\n",
    "    results = pose_model(input_img)\n",
    "    keypoints = results['output_0'].numpy()[0, 0, :, :2]  # Taking only x, y coordinates\n",
    "    \n",
    "    return keypoints\n",
    "\n",
    "# Function to track ball trajectory\n",
    "def track_ball(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Parameters for ball detection\n",
    "    ball_positions = []\n",
    "    \n",
    "    # Define the lower and upper bounds for tennis ball color (adjust based on your video)\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert frame to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Create mask for yellow color\n",
    "        mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Find largest contour (assuming it's the ball)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            if cv2.contourArea(largest_contour) > 30:  # Minimum area threshold\n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(largest_contour)\n",
    "                ball_positions.append((int(x), int(y)))\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Smooth trajectory using Savitzky-Golay filter if enough points\n",
    "    if len(ball_positions) > 10:\n",
    "        x_coords = [pos[0] for pos in ball_positions]\n",
    "        y_coords = [pos[1] for pos in ball_positions]\n",
    "        \n",
    "        x_smooth = savgol_filter(x_coords, 15, 2)\n",
    "        y_smooth = savgol_filter(y_coords, 15, 2)\n",
    "        \n",
    "        smooth_positions = [(int(x), int(y)) for x, y in zip(x_smooth, y_smooth)]\n",
    "        return smooth_positions\n",
    "    \n",
    "    return ball_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect racket position and shot types\n",
    "def detect_racket(frame):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply threshold\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours by area and aspect ratio to find the racket\n",
    "    racket_contour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 1000:  # Minimum area threshold\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = float(w) / h\n",
    "            \n",
    "            if 0.2 < aspect_ratio < 1.5:  # Aspect ratio for a tennis racket\n",
    "                racket_contour = contour\n",
    "                break\n",
    "    \n",
    "    if racket_contour is not None:\n",
    "        return cv2.boundingRect(racket_contour)\n",
    "    return None\n",
    "\n",
    "# Main function to extract features from a shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Shot Pattern Analysis\n",
    "Now, let's analyze shot patterns and their effectiveness based on court position and game context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_shot_features(video_data):\n",
    "    features = []\n",
    "    pose_model = load_pose_model()\n",
    "    \n",
    "    for data in video_data:\n",
    "        video_path = data['path']\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # Extract frames for analysis\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        sample_indices = np.linspace(0, total_frames-1, 10, dtype=int)\n",
    "        \n",
    "        # Features for this video\n",
    "        video_features = {\n",
    "            'shot_type': data['shot_type'],\n",
    "            'environment': data['environment'],\n",
    "            'to_sideline_distance': data['to_sideline_distance'],\n",
    "            'to_baseline_distance': data['to_baseline_distance'],\n",
    "            'pose_keypoints': [],\n",
    "            'racket_positions': [],\n",
    "        }\n",
    "        \n",
    "        # Extract pose and racket positions from sample frames\n",
    "        for idx in sample_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Detect pose\n",
    "                keypoints = detect_pose(frame, pose_model)\n",
    "                video_features['pose_keypoints'].append(keypoints)\n",
    "                \n",
    "                # Detect racket\n",
    "                racket_pos = detect_racket(frame)\n",
    "                if racket_pos:\n",
    "                    video_features['racket_positions'].append(racket_pos)\n",
    "        \n",
    "        # Track ball trajectory\n",
    "        ball_trajectory = track_ball(video_path)\n",
    "        video_features['ball_trajectory'] = ball_trajectory\n",
    "        \n",
    "        # Calculate additional features\n",
    "        video_features['shot_speed'] = calculate_shot_speed(ball_trajectory, data['fps'])\n",
    "        video_features['shot_angle'] = calculate_shot_angle(ball_trajectory)\n",
    "        \n",
    "        features.append(video_features)\n",
    "        cap.release()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Calculate shot speed from ball trajectory\n",
    "def calculate_shot_speed(ball_trajectory, fps):\n",
    "    if len(ball_trajectory) < 2:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate distances between consecutive points\n",
    "    distances = []\n",
    "    for i in range(1, len(ball_trajectory)):\n",
    "        x1, y1 = ball_trajectory[i-1]\n",
    "        x2, y2 = ball_trajectory[i]\n",
    "        dist = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        distances.append(dist)\n",
    "    \n",
    "    # Convert to speed (pixels per second)\n",
    "    avg_distance = np.mean(distances)\n",
    "    speed = avg_distance * fps\n",
    "    \n",
    "    # This would need calibration to convert to real-world units\n",
    "    return speed\n",
    "\n",
    "# Calculate shot angle from ball trajectory\n",
    "def calculate_shot_angle(ball_trajectory):\n",
    "    if len(ball_trajectory) < 2:\n",
    "        return 0\n",
    "    \n",
    "    # Take first and last points to calculate overall direction\n",
    "    x1, y1 = ball_trajectory[0]\n",
    "    x2, y2 = ball_trajectory[-1]\n",
    "    \n",
    "    angle = np.arctan2(y2-y1, x2-x1) * 180 / np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shot_features(video_data):\n",
    "    features = []\n",
    "    pose_model = load_pose_model()\n",
    "    \n",
    "    for data in video_data:\n",
    "        video_path = data['path']\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # Extract frames for analysis\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        sample_indices = np.linspace(0, total_frames-1, 10, dtype=int)\n",
    "        \n",
    "        # Features for this video\n",
    "        video_features = {\n",
    "            'shot_type': data['shot_type'],\n",
    "            'environment': data['environment'],\n",
    "            'to_sideline_distance': data['to_sideline_distance'],\n",
    "            'to_baseline_distance': data['to_baseline_distance'],\n",
    "            'pose_keypoints': [],\n",
    "            'racket_positions': [],\n",
    "        }\n",
    "        \n",
    "        # Extract pose and racket positions from sample frames\n",
    "        for idx in sample_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Detect pose\n",
    "                keypoints = detect_pose(frame, pose_model)\n",
    "                video_features['pose_keypoints'].append(keypoints)\n",
    "                \n",
    "                # Detect racket\n",
    "                racket_pos = detect_racket(frame)\n",
    "                if racket_pos:\n",
    "                    video_features['racket_positions'].append(racket_pos)\n",
    "        \n",
    "        # Track ball trajectory\n",
    "        ball_trajectory = track_ball(video_path)\n",
    "        video_features['ball_trajectory'] = ball_trajectory\n",
    "        \n",
    "        # Calculate additional features\n",
    "        video_features['shot_speed'] = calculate_shot_speed(ball_trajectory, data['fps'])\n",
    "        video_features['shot_angle'] = calculate_shot_angle(ball_trajectory)\n",
    "        \n",
    "        features.append(video_features)\n",
    "        cap.release()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Calculate shot speed from ball trajectory\n",
    "def calculate_shot_speed(ball_trajectory, fps):\n",
    "    if len(ball_trajectory) < 2:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate distances between consecutive points\n",
    "    distances = []\n",
    "    for i in range(1, len(ball_trajectory)):\n",
    "        x1, y1 = ball_trajectory[i-1]\n",
    "        x2, y2 = ball_trajectory[i]\n",
    "        dist = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        distances.append(dist)\n",
    "    \n",
    "    # Convert to speed (pixels per second)\n",
    "    avg_distance = np.mean(distances)\n",
    "    speed = avg_distance * fps\n",
    "    \n",
    "    # This would need calibration to convert to real-world units\n",
    "    return speed\n",
    "\n",
    "# Calculate shot angle from ball trajectory\n",
    "def calculate_shot_angle(ball_trajectory):\n",
    "    if len(ball_trajectory) < 2:\n",
    "        return 0\n",
    "    \n",
    "    # Take first and last points to calculate overall direction\n",
    "    x1, y1 = ball_trajectory[0]\n",
    "    x2, y2 = ball_trajectory[-1]\n",
    "    \n",
    "    angle = np.arctan2(y2-y1, x2-x1) * 180 / np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIsualising Racket Position for top N players in random video\n",
    "# Extract key frame and detect racket position\n",
    "racket_positions = []\n",
    "# Extract the video\n",
    "paths = [x['path'] for x in video_data[:9]] # 9 is picked randomly as it corresponds to group number\n",
    "for path in paths:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    while True: # Show for first 5 frames\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        racket_pos = detect_racket(frame)\n",
    "        if racket_pos:\n",
    "            racket_positions.append(racket_pos)\n",
    "\n",
    "    # Visualize the racket positions\n",
    "    if racket_positions:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for idx, (x, y, w, h) in enumerate(racket_positions):\n",
    "            plt.scatter(x + w / 2, y + h / 2, label=f\"Frame {idx+1}\")  # Mark racket center\n",
    "        plt.xlabel(\"X Position\")\n",
    "        plt.ylabel(\"Y Position\")\n",
    "        plt.title(\"Detected Racket Positions Across Frames\")\n",
    "        # plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No racket detected in the frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_features = extract_shot_features(video_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Visualize shot distributions and success rates for each player.\n",
    "In this section we would visualize shot distributions and success rates for different players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to a pandas DataFrame for easier analysis\n",
    "def create_shot_dataframe(shot_features):\n",
    "    # Extract relevant information for each shot\n",
    "    data = []\n",
    "    for feat in shot_features:\n",
    "        # Basic shot info\n",
    "        shot_info = {\n",
    "            'shot_type': feat['shot_type'],\n",
    "            'environment': feat['environment'],\n",
    "            'to_sideline_distance': feat['to_sideline_distance'],\n",
    "            'to_baseline_distance': feat['to_baseline_distance'],\n",
    "            'shot_speed': feat['shot_speed'],\n",
    "            'shot_angle': feat['shot_angle']\n",
    "        }\n",
    "        \n",
    "        # Add average pose information (e.g., average hip and shoulder positions)\n",
    "        if feat['pose_keypoints']:\n",
    "            avg_keypoints = np.mean(feat['pose_keypoints'], axis=0)\n",
    "            shot_info['right_shoulder_x'] = avg_keypoints[6, 0]\n",
    "            shot_info['right_shoulder_y'] = avg_keypoints[6, 1]\n",
    "            shot_info['left_shoulder_x'] = avg_keypoints[5, 0]\n",
    "            shot_info['left_shoulder_y'] = avg_keypoints[5, 1]\n",
    "            shot_info['right_hip_x'] = avg_keypoints[12, 0]\n",
    "            shot_info['right_hip_y'] = avg_keypoints[12, 1]\n",
    "            shot_info['left_hip_x'] = avg_keypoints[11, 0]\n",
    "            shot_info['left_hip_y'] = avg_keypoints[11, 1]\n",
    "            \n",
    "            # Calculate body rotation (angle between shoulders)\n",
    "            if len(avg_keypoints) > 6:\n",
    "                right_shoulder = avg_keypoints[6]\n",
    "                left_shoulder = avg_keypoints[5]\n",
    "                shoulder_angle = np.arctan2(\n",
    "                    right_shoulder[1] - left_shoulder[1],\n",
    "                    right_shoulder[0] - left_shoulder[0]\n",
    "                ) * 180 / np.pi\n",
    "                shot_info['shoulder_angle'] = shoulder_angle\n",
    "        \n",
    "        data.append(shot_info)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Analyze shot patterns\n",
    "def analyze_shot_patterns(shot_df):\n",
    "    # 1. Analyze shot distribution by court position\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(\n",
    "        shot_df['to_sideline_distance'], \n",
    "        shot_df['to_baseline_distance'],\n",
    "        c=shot_df['shot_type'].astype('category').cat.codes,\n",
    "        alpha=0.7,\n",
    "        s=100\n",
    "    )\n",
    "    plt.colorbar(label='Shot Type')\n",
    "    plt.xlabel('Distance to Sideline (m)')\n",
    "    plt.ylabel('Distance to Baseline (m)')\n",
    "    plt.title('Shot Distribution by Court Position')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Cluster shots based on position and characteristics\n",
    "    features_for_clustering = shot_df[['to_sideline_distance', 'to_baseline_distance', 'shot_speed', 'shot_angle']]\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features_for_clustering)\n",
    "    \n",
    "    # Apply KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    shot_df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "    \n",
    "    # Visualize clusters\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x='to_sideline_distance',\n",
    "        y='to_baseline_distance',\n",
    "        hue='cluster',\n",
    "        style='shot_type',\n",
    "        palette='viridis',\n",
    "        data=shot_df,\n",
    "        s=100\n",
    "    )\n",
    "    plt.title('Shot Clusters by Court Position')\n",
    "    plt.xlabel('Distance to Sideline (m)')\n",
    "    plt.ylabel('Distance to Baseline (m)')\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Analyze shot effectiveness by court position\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x='shot_type', y='shot_speed', data=shot_df)\n",
    "    plt.title('Shot Speed by Type')\n",
    "    plt.xlabel('Shot Type')\n",
    "    plt.ylabel('Speed')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x='shot_type', y='shot_angle', data=shot_df)\n",
    "    plt.title('Shot Angle by Type')\n",
    "    plt.xlabel('Shot Type')\n",
    "    plt.ylabel('Angle (degrees)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Cross-court vs down-the-line analysis\n",
    "    shot_df['shot_direction'] = shot_df['shot_angle'].apply(\n",
    "        lambda angle: 'Cross-court' if (angle > 30 and angle < 150) or (angle < -30 and angle > -150) else 'Down-the-line'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shot_direction_counts = shot_df.groupby(['shot_type', 'shot_direction']).size().unstack()\n",
    "    shot_direction_counts.plot(kind='bar', stacked=True)\n",
    "    plt.title('Shot Direction Distribution by Shot Type')\n",
    "    plt.xlabel('Shot Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Direction')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return shot_df\n",
    "\n",
    "# Analyze shot effectiveness based on game context\n",
    "def analyze_shot_effectiveness(shot_features, match_data=None):\n",
    "    # Note: This function would ideally use match data that contains information about\n",
    "    # point outcomes, but we'll simulate it for demonstration purposes\n",
    "    \n",
    "    # Create a DataFrame for shot analysis\n",
    "    shot_df = create_shot_dataframe(shot_features)\n",
    "    \n",
    "    # Simulate shot success (in a real implementation, this would come from match data)\n",
    "    np.random.seed(42)\n",
    "    shot_df['success'] = np.random.choice([0, 1], size=len(shot_df), p=[0.3, 0.7])\n",
    "    \n",
    "    # 1. Shot success rate by type\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    success_by_type = shot_df.groupby('shot_type')['success'].mean()\n",
    "    success_by_type.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Shot Success Rate by Type')\n",
    "    plt.xlabel('Shot Type')\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.ylim(0, 1)\n",
    "    for i, v in enumerate(success_by_type):\n",
    "        plt.text(i, v + 0.02, f'{v:.2f}', ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Shot success by court position (heatmap)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create position bins\n",
    "    shot_df['sideline_bin'] = pd.cut(shot_df['to_sideline_distance'], bins=5)\n",
    "    shot_df['baseline_bin'] = pd.cut(shot_df['to_baseline_distance'], bins=5)\n",
    "    \n",
    "    # Calculate success rate for each position bin\n",
    "    position_success = shot_df.groupby(['sideline_bin', 'baseline_bin'])['success'].mean().reset_index()\n",
    "    position_success_pivot = position_success.pivot(\n",
    "        index='baseline_bin',\n",
    "        columns='sideline_bin',\n",
    "        values='success'\n",
    "    )\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(\n",
    "        position_success_pivot,\n",
    "        annot=True,\n",
    "        cmap='YlGnBu',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        fmt='.2f'\n",
    "    )\n",
    "    plt.title('Shot Success Rate by Court Position')\n",
    "    plt.xlabel('Distance to Sideline')\n",
    "    plt.ylabel('Distance to Baseline')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Success rate by shot speed and angle\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    shot_df['speed_bin'] = pd.cut(shot_df['shot_speed'], bins=5)\n",
    "    success_by_speed = shot_df.groupby('speed_bin')['success'].mean()\n",
    "    success_by_speed.plot(kind='bar', color='lightgreen')\n",
    "    plt.title('Success Rate by Shot Speed')\n",
    "    plt.xlabel('Shot Speed')\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    shot_df['angle_bin'] = pd.cut(shot_df['shot_angle'], bins=5)\n",
    "    success_by_angle = shot_df.groupby('angle_bin')['success'].mean()\n",
    "    success_by_angle.plot(kind='bar', color='salmon')\n",
    "    plt.title('Success Rate by Shot Angle')\n",
    "    plt.xlabel('Shot Angle')\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return shot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_df = create_shot_dataframe(shot_features)\n",
    "shot_df_with_patterns = analyze_shot_patterns(shot_df)\n",
    "shot_df_with_effectiveness = analyze_shot_effectiveness(shot_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize shot distribution on a tennis court\n",
    "def visualize_shot_distribution(shot_df, player_id=None):\n",
    "    # Filter by player if provided\n",
    "    if player_id is not None:\n",
    "        shot_df = shot_df[shot_df['player_id'] == player_id]\n",
    "    \n",
    "    # Create tennis court\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Draw court\n",
    "    draw_tennis_court(ax)\n",
    "    \n",
    "    # Plot shots\n",
    "    scatter = ax.scatter(\n",
    "        shot_df['to_sideline_distance'],\n",
    "        shot_df['to_baseline_distance'],\n",
    "        c=shot_df['shot_type'].astype('category').cat.codes,\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    \n",
    "    # Add legend\n",
    "    legend_labels = shot_df['shot_type'].unique()\n",
    "    legend = ax.legend(\n",
    "        handles=scatter.legend_elements()[0],\n",
    "        labels=legend_labels,\n",
    "        title=\"Shot Types\",\n",
    "        loc=\"upper right\"\n",
    "    )\n",
    "    \n",
    "    # Set title and labels\n",
    "    title = f\"Shot Distribution for Player {player_id}\" if player_id else \"Shot Distribution for All Players\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Distance to Sideline (m)')\n",
    "    ax.set_ylabel('Distance to Baseline (m)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize success rates by shot type\n",
    "def visualize_success_rates(shot_df, player_id=None):\n",
    "    # Filter by player if provided\n",
    "    if player_id is not None:\n",
    "        shot_df = shot_df[shot_df['player_id'] == player_id]\n",
    "    \n",
    "    # Group by shot type and calculate success rate\n",
    "    success_by_type = shot_df.groupby('shot_type')['success'].agg(['mean', 'count']).reset_index()\n",
    "    success_by_type.columns = ['shot_type', 'success_rate', 'count']\n",
    "    \n",
    "    # Sort by count\n",
    "    success_by_type = success_by_type.sort_values('count', ascending=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = ax.bar(\n",
    "        success_by_type['shot_type'],\n",
    "        success_by_type['success_rate'],\n",
    "        color='skyblue'\n",
    "    )\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (_, row) in enumerate(success_by_type.iterrows()):\n",
    "        ax.text(\n",
    "            i,\n",
    "            row['success_rate'] + 0.02,\n",
    "            f\"n={int(row['count'])}\",\n",
    "            ha='center'\n",
    "        )\n",
    "    \n",
    "    # Set title and labels\n",
    "    title = f\"Shot Success Rates for Player {player_id}\" if player_id else \"Shot Success Rates for All Players\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Shot Type')\n",
    "    ax.set_ylabel('Success Rate')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add horizontal grid lines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to create a heatmap of shot distribution on the court\n",
    "def visualize_shot_heatmap(shot_df, player_id=None, shot_type=None):\n",
    "    # Filter by player and shot type if provided\n",
    "    if player_id is not None:\n",
    "        shot_df = shot_df[shot_df['player_id'] == player_id]\n",
    "    if shot_type is not None:\n",
    "        shot_df = shot_df[shot_df['shot_type'] == shot_type]\n",
    "    \n",
    "    # Create bins for court positions\n",
    "    x_bins = np.linspace(0, 10, 20)  # Adjust based on your court dimensions\n",
    "    y_bins = np.linspace(0, 10, 20)  # Adjust based on your court dimensions\n",
    "    \n",
    "    # Create 2D histogram\n",
    "    h, xedges, yedges = np.histogram2d(\n",
    "        shot_df['to_sideline_distance'],\n",
    "        shot_df['to_baseline_distance'],\n",
    "        bins=[x_bins, y_bins]\n",
    "    )\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Draw tennis court\n",
    "    draw_tennis_court(ax)\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = ax.imshow(\n",
    "        h.T,\n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n",
    "        origin='lower',\n",
    "        cmap='hot',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(heatmap, ax=ax)\n",
    "    cbar.set_label('Shot Count')\n",
    "    \n",
    "    # Set title and labels\n",
    "    title_parts = []\n",
    "    if player_id is not None:\n",
    "        title_parts.append(f\"Player {player_id}\")\n",
    "    if shot_type is not None:\n",
    "        title_parts.append(f\"{shot_type} Shots\")\n",
    "    if not title_parts:\n",
    "        title_parts.append(\"All Players and Shots\")\n",
    "    \n",
    "    title = \"Shot Heatmap for \" + \", \".join(title_parts)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Distance to Sideline (m)')\n",
    "    ax.set_ylabel('Distance to Baseline (m)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to draw a tennis court\n",
    "def draw_tennis_court(ax):\n",
    "    # Court dimensions (approximate)\n",
    "    court_width = 10.97  # meters\n",
    "    court_length = 23.77  # meters\n",
    "    \n",
    "    # Draw outer court\n",
    "    court = Rectangle((0, 0), court_width, court_length, fill=False, color='black')\n",
    "    ax.add_patch(court)\n",
    "    \n",
    "    # Draw net\n",
    "    ax.plot([0, court_width], [court_length/2, court_length/2], 'k-', linewidth=2)\n",
    "    \n",
    "    # Draw service lines\n",
    "    ax.plot([0, court_width], [court_length*0.25, court_length*0.25], 'k-', linewidth=1)\n",
    "    ax.plot([0, court_width], [court_length*0.75, court_length*0.75], 'k-', linewidth=1)\n",
    "    \n",
    "    # Draw center service line\n",
    "    ax.plot([court_width/2, court_width/2], [court_length*0.25, court_length*0.75], 'k-', linewidth=1)\n",
    "    \n",
    "    # Set limits\n",
    "    ax.set_xlim(-1, court_width + 1)\n",
    "    ax.set_ylim(-1, court_length + 1)\n",
    "    \n",
    "    # Set aspect ratio to equal\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# Main function to visualize shot statistics\n",
    "def visualize_shot_distribution(shot_df, player_id=None):\n",
    "    # Filter by player if provided\n",
    "    if player_id is not None:\n",
    "        # Check if player_id is array-like (e.g. list or np.ndarray)\n",
    "        try:\n",
    "            # Attempt to iterate over player_id; if it's a scalar, this will fail.\n",
    "            iter(player_id)\n",
    "            is_iterable = True\n",
    "        except TypeError:\n",
    "            is_iterable = False\n",
    "\n",
    "        if is_iterable:\n",
    "            shot_df = shot_df[shot_df['player_id'].isin(player_id)]\n",
    "        else:\n",
    "            shot_df = shot_df[shot_df['player_id'] == player_id]\n",
    "\n",
    "    # Create tennis court\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Draw court\n",
    "    draw_tennis_court(ax)\n",
    "    \n",
    "    # Plot shots with a categorical color mapping\n",
    "    scatter = ax.scatter(\n",
    "        shot_df['to_sideline_distance'],\n",
    "        shot_df['to_baseline_distance'],\n",
    "        c=shot_df['shot_type'].astype('category').cat.codes,\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    \n",
    "    # Add legend\n",
    "    legend_labels = list(shot_df['shot_type'].unique())\n",
    "    legend_handles = list(scatter.legend_elements()[0])\n",
    "    legend_labels = list(shot_df['shot_type'].unique())\n",
    "    legend = ax.legend(\n",
    "        handles=legend_handles,\n",
    "        labels=legend_labels,\n",
    "        title=\"Shot Types\",\n",
    "        loc=\"upper right\"\n",
    "    )\n",
    "    \n",
    "    # Set title and labels\n",
    "    title = f\"Shot Distribution for Player {player_id}\" if player_id is not None else \"Shot Distribution for All Players\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Distance to Sideline (m)')\n",
    "    ax.set_ylabel('Distance to Baseline (m)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_shot_distribution(shot_df)\n",
    "visualize_shot_heatmap(shot_df_with_patterns)\n",
    "visualize_success_rates(shot_df_with_effectiveness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Player Movement and Positioning Analysis\n",
    "Analyze player movements and court positioning to derive tactical insights.\n",
    "\n",
    "a) Implement algorithms to analyze player movement patterns (e.g., speed, acceleration, distance covered).\n",
    "\n",
    "b) Develop heatmaps to visualize player court coverage and preferred positions.\n",
    "\n",
    "c) Identify correlations between player positioning and shot selection/effectiveness.\n",
    "\n",
    "d) Analyze how player movements change in different game situations (e.g., serving, returning, baseline rallies).\n",
    "\n",
    "Deliverables:\n",
    "- Python code for movement and positioning analysis\n",
    "- A comprehensive report (max 4 pages) describing your methodology, key findings, and potential tactical implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Implement algorithms to analyze player movement patterns (e.g., speed, acceleration, distance covered).\n",
    "\n",
    "Utility Functions to visualize all kinds of movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Helpers\n",
    "# Central tennis court drawing function\n",
    "def draw_tennis_court(ax, court_dimensions=None):\n",
    "    \"\"\"\n",
    "    Draw a tennis court on the given matplotlib axis.\n",
    "    \n",
    "    Parameters:\n",
    "    ax (matplotlib.axes.Axes): The axis to draw on\n",
    "    court_dimensions (dict, optional): Dictionary with 'width' and 'length' keys in meters\n",
    "    \"\"\"\n",
    "    # Default court dimensions in meters\n",
    "    court_width = 10.97\n",
    "    court_length = 23.77\n",
    "    \n",
    "    if court_dimensions is not None:\n",
    "        court_width = court_dimensions.get('width', court_width)\n",
    "        court_length = court_dimensions.get('length', court_length)\n",
    "    \n",
    "    # Draw outer court\n",
    "    court = plt.Rectangle((0, 0), court_width, court_length, fill=False, color='black')\n",
    "    ax.add_patch(court)\n",
    "    \n",
    "    # Draw net\n",
    "    ax.plot([0, court_width], [court_length/2, court_length/2], 'k-', linewidth=2)\n",
    "    \n",
    "    # Draw service lines\n",
    "    ax.plot([0, court_width], [court_length*0.25, court_length*0.25], 'k-', linewidth=1)\n",
    "    ax.plot([0, court_width], [court_length*0.75, court_length*0.75], 'k-', linewidth=1)\n",
    "    \n",
    "    # Draw center service line\n",
    "    ax.plot([court_width/2, court_width/2], [court_length*0.25, court_length*0.75], 'k-', linewidth=1)\n",
    "    \n",
    "    # Set limits with some padding\n",
    "    ax.set_xlim(-1, court_width + 1)\n",
    "    ax.set_ylim(-1, court_length + 1)\n",
    "    \n",
    "    # Set aspect ratio to equal\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# Consolidated plotting function for all heatmap types\n",
    "def plot_court_heatmap(data, plot_type='position', court_dimensions=None, title=None, ax=None, colormap='hot', alpha=0.7):\n",
    "    \"\"\"\n",
    "    Create a heatmap on a tennis court for different types of analyses.\n",
    "    \n",
    "    Parameters:\n",
    "    data (list): List of position data dictionaries containing 'position_x', 'position_y', and other fields\n",
    "    plot_type (str): Type of plot - 'position', 'speed', 'success', or 'shot_type'\n",
    "    court_dimensions (dict, optional): Dictionary with 'width' and 'length' keys in meters\n",
    "    title (str, optional): Plot title\n",
    "    ax (matplotlib.axes.Axes, optional): The axis to draw on, if None a new one is created\n",
    "    colormap (str): Matplotlib colormap name\n",
    "    alpha (float): Transparency level for the plot\n",
    "    \n",
    "    Returns:\n",
    "    fig (matplotlib.figure.Figure): The figure containing the plot\n",
    "    ax (matplotlib.axes.Axes): The axis with the plot\n",
    "    \"\"\"\n",
    "    if not data or len(data) < 2:\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        else:\n",
    "            fig = ax.figure\n",
    "        \n",
    "        draw_tennis_court(ax, court_dimensions)\n",
    "        ax.set_title(f\"{title or 'Tennis Court Analysis'} - Not enough data points\")\n",
    "        ax.set_xlabel('Court Width (m)')\n",
    "        ax.set_ylabel('Court Length (m)')\n",
    "        return fig, ax\n",
    "    \n",
    "    # Extract position data\n",
    "    positions_x = [d.get('position_x', 0) for d in data]\n",
    "    positions_y = [d.get('position_y', 0) for d in data]\n",
    "    \n",
    "    # Create figure and axis if not provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    \n",
    "    # Draw tennis court\n",
    "    draw_tennis_court(ax, court_dimensions)\n",
    "    \n",
    "    # Different plot types\n",
    "    if plot_type == 'position':\n",
    "        # Position density heatmap using KDE\n",
    "        try:\n",
    "            heatmap = sns.kdeplot(\n",
    "                x=positions_x,\n",
    "                y=positions_y,\n",
    "                cmap=colormap,\n",
    "                fill=True,\n",
    "                alpha=alpha,\n",
    "                levels=20,\n",
    "                thresh=0.05,\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            # Add colorbar\n",
    "            if heatmap.collections:\n",
    "                cbar = fig.colorbar(heatmap.collections[0], ax=ax)\n",
    "                cbar.set_label('Position Density')\n",
    "            \n",
    "            ax.set_title(title or 'Player Court Coverage')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"KDE plot failed: {e}\")\n",
    "            # Fallback to scatter plot\n",
    "            sc = ax.scatter(positions_x, positions_y, c='red', alpha=0.6, s=50)\n",
    "            ax.set_title(f\"{title or 'Player Court Coverage'} - Scatter Plot (KDE failed)\")\n",
    "    \n",
    "    elif plot_type == 'speed':\n",
    "        # Extract speed data\n",
    "        speeds = [d.get('speed', 0) for d in data]\n",
    "        \n",
    "        # Create scatter plot with speed as color\n",
    "        scatter = ax.scatter(\n",
    "            positions_x,\n",
    "            positions_y,\n",
    "            c=speeds,\n",
    "            cmap=colormap,\n",
    "            s=50,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = fig.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Speed (m/s)')\n",
    "        \n",
    "        ax.set_title(title or 'Player Speed Distribution')\n",
    "    \n",
    "    elif plot_type == 'success':\n",
    "        # For position-success correlation plots\n",
    "        success_values = [d.get('success', 0) for d in data]\n",
    "        \n",
    "        scatter = ax.scatter(\n",
    "            positions_x,\n",
    "            positions_y,\n",
    "            c=success_values,\n",
    "            cmap='RdYlGn',  # Red-Yellow-Green colormap\n",
    "            s=80,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = fig.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Success Rate')\n",
    "        \n",
    "        ax.set_title(title or 'Shot Success by Court Position')\n",
    "    \n",
    "    elif plot_type == 'shot_type':\n",
    "        # Get unique shot types\n",
    "        shot_types = set(d.get('shot_type', 'unknown') for d in data)\n",
    "        shot_types = [st for st in shot_types if st != 'unknown']\n",
    "        \n",
    "        # Assign colors to shot types\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(shot_types)))\n",
    "        color_map = {shot_type: color for shot_type, color in zip(shot_types, colors)}\n",
    "        \n",
    "        # Plot each shot type separately\n",
    "        for shot_type in shot_types:\n",
    "            subset = [d for d in data if d.get('shot_type') == shot_type]\n",
    "            if subset:\n",
    "                subset_x = [d.get('position_x', 0) for d in subset]\n",
    "                subset_y = [d.get('position_y', 0) for d in subset]\n",
    "                \n",
    "                ax.scatter(\n",
    "                    subset_x,\n",
    "                    subset_y,\n",
    "                    c=[color_map[shot_type]] * len(subset),\n",
    "                    label=shot_type,\n",
    "                    s=80,\n",
    "                    alpha=alpha\n",
    "                )\n",
    "        \n",
    "        ax.legend(title=\"Shot Type\")\n",
    "        ax.set_title(title or 'Shot Type Distribution by Position')\n",
    "    \n",
    "    elif plot_type == 'cluster':\n",
    "        # For position clusters\n",
    "        clusters = [d.get('position_cluster', 0) for d in data]\n",
    "        unique_clusters = set(clusters)\n",
    "        \n",
    "        # Assign colors to clusters\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_clusters)))\n",
    "        \n",
    "        # Plot each cluster\n",
    "        for i, cluster in enumerate(unique_clusters):\n",
    "            subset = [d for d in data if d.get('position_cluster') == cluster]\n",
    "            if subset:\n",
    "                subset_x = [d.get('position_x', 0) for d in subset]\n",
    "                subset_y = [d.get('position_y', 0) for d in subset]\n",
    "                \n",
    "                ax.scatter(\n",
    "                    subset_x,\n",
    "                    subset_y,\n",
    "                    c=[colors[i]] * len(subset),\n",
    "                    label=f\"Cluster {cluster}\",\n",
    "                    s=80,\n",
    "                    alpha=alpha\n",
    "                )\n",
    "        \n",
    "        ax.legend(title=\"Position Cluster\")\n",
    "        ax.set_title(title or 'Position Clusters')\n",
    "    \n",
    "    # Common settings\n",
    "    ax.set_xlabel('Court Width (m)')\n",
    "    ax.set_ylabel('Court Length (m)')\n",
    "    \n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a visualization of player movement trajectory and speed profile.\n",
    "    \n",
    "**Parameters**:\n",
    "\n",
    "- **movement_data** (list): List of player movement data points\n",
    "- **court_dimensions** (dict, optional): Dictionary with 'width' and 'length' keys in meters\n",
    "- **title** (str, optional): Main title for the plot\n",
    "- **downsample_factor** (int): Factor to downsample trajectory points for cleaner visualization\n",
    "- **figsize** (tuple): Figure size (width, height) in inches\n",
    "\n",
    "**Returns**:\n",
    "fig (matplotlib.figure.Figure): The figure containing the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot player movement trajectory\n",
    "def plot_movement_trajectory(movement_data, court_dimensions=None, title=None, downsample_factor=10, figsize=(16, 6)):\n",
    "    if not movement_data or len(movement_data) < 2:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        draw_tennis_court(ax, court_dimensions)\n",
    "        ax.set_title(title or \"Player Movement - Insufficient Data\")\n",
    "        ax.set_xlabel('Court Width (m)')\n",
    "        ax.set_ylabel('Court Length (m)')\n",
    "        return fig\n",
    "\n",
    "    # Extract data\n",
    "    positions_x = np.array([d.get('position_x', 0) for d in movement_data])\n",
    "    positions_y = np.array([d.get('position_y', 0) for d in movement_data])\n",
    "    speeds = np.array([d.get('speed', 0) for d in movement_data])\n",
    "    \n",
    "    # Ensure we have timestamps (or generate them)\n",
    "    if 'timestamp' in movement_data[0]:\n",
    "        timestamps = np.array([d.get('timestamp', 0) for d in movement_data])\n",
    "    else:\n",
    "        timestamps = np.arange(len(positions_x))\n",
    "\n",
    "    # Downsample trajectory points for cleaner visualization\n",
    "    if len(positions_x) > downsample_factor:\n",
    "        sample_indices = np.linspace(0, len(positions_x) - 1, max(len(positions_x) // downsample_factor, 10), dtype=int)\n",
    "        sampled_x = positions_x[sample_indices]\n",
    "        sampled_y = positions_y[sample_indices]\n",
    "        sampled_speeds = speeds[sample_indices]\n",
    "        sampled_times = timestamps[sample_indices]\n",
    "    else:\n",
    "        sample_indices = np.arange(len(positions_x))\n",
    "        sampled_x = positions_x\n",
    "        sampled_y = positions_y\n",
    "        sampled_speeds = speeds\n",
    "        sampled_times = timestamps\n",
    "\n",
    "    # Create figure with two subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # Subplot 1: Movement Trajectory on court\n",
    "    ax[0].set_title(title or \"Player Movement Trajectory\")\n",
    "    draw_tennis_court(ax[0], court_dimensions)\n",
    "    \n",
    "    # Add trajectory path with gradient coloring by speed\n",
    "    points = np.array([positions_x, positions_y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    \n",
    "    # Create a colormap for speed\n",
    "    norm = plt.Normalize(speeds.min(), speeds.max())\n",
    "    lc = plt.matplotlib.collections.LineCollection(segments, cmap='viridis', norm=norm)\n",
    "    lc.set_array(speeds)\n",
    "    lc.set_linewidth(2)\n",
    "    line = ax[0].add_collection(lc)\n",
    "    \n",
    "    # Plot start and end points\n",
    "    ax[0].scatter(positions_x[0], positions_y[0], color='green', s=150, marker='o', label='Start', zorder=5)\n",
    "    ax[0].scatter(positions_x[-1], positions_y[-1], color='red', s=150, marker='o', label='End', zorder=5)\n",
    "    \n",
    "    # Add key points along the path\n",
    "    scatter = ax[0].scatter(\n",
    "        sampled_x, \n",
    "        sampled_y, \n",
    "        c=sampled_speeds, \n",
    "        cmap='viridis', \n",
    "        s=50, \n",
    "        edgecolors='black', \n",
    "        label=\"Key Movement Points\"\n",
    "    )\n",
    "    \n",
    "    ax[0].legend(loc='upper left')\n",
    "    fig.colorbar(scatter, ax=ax[0], label=\"Speed (m/s)\")\n",
    "\n",
    "    # Subplot 2: Speed Profile\n",
    "    ax[1].set_title(\"Speed Profile Over Time\")\n",
    "    ax[1].plot(timestamps, speeds, color='blue', alpha=0.7, linewidth=2, label=\"Speed\")\n",
    "    ax[1].scatter(sampled_times, sampled_speeds, color='red', s=50, label=\"Key Points\")\n",
    "    \n",
    "    ax[1].set_xlabel(\"Time (seconds)\" if 'timestamp' in movement_data[0] else \"Frame Index\")\n",
    "    ax[1].set_ylabel(\"Speed (m/s)\")\n",
    "    ax[1].grid(True, linestyle='--', alpha=0.7)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison Chart\n",
    "Comparative visualizations for different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_comparison_chart(data, x_key, y_key, title=None, xlabel=None, ylabel=None, figsize=(10, 6), \n",
    "                         color='skyblue', count_key=None, plot_type='bar'):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Handle dictionary input (convert to lists)\n",
    "    if isinstance(data, dict):\n",
    "        if all(isinstance(v, dict) for v in data.values()):\n",
    "            # Nested dictionary: {category: {metric1: value1, metric2: value2}}\n",
    "            x_values = list(data.keys())\n",
    "            y_values = [d.get(y_key, 0) for d in data.values()]\n",
    "            \n",
    "            if count_key:\n",
    "                counts = [d.get(count_key, 0) for d in data.values()]\n",
    "            else:\n",
    "                counts = None\n",
    "        else:\n",
    "            # Simple dictionary: {key1: value1, key2: value2}\n",
    "            x_values = list(data.keys())\n",
    "            y_values = list(data.values())\n",
    "            counts = None\n",
    "    else:\n",
    "        # List of dictionaries\n",
    "        x_values = [item.get(x_key, 'Unknown') for item in data]\n",
    "        y_values = [item.get(y_key, 0) for item in data]\n",
    "        \n",
    "        if count_key:\n",
    "            counts = [item.get(count_key, 0) for item in data]\n",
    "        else:\n",
    "            counts = None\n",
    "    \n",
    "    # Create plot based on type\n",
    "    if plot_type == 'bar':\n",
    "        bars = ax.bar(x_values, y_values, color=color)\n",
    "        \n",
    "        # Add count labels if provided\n",
    "        if counts:\n",
    "            for i, (count, bar) in enumerate(zip(counts, bars)):\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2,\n",
    "                    bar.get_height() + max(y_values) * 0.03,\n",
    "                    f\"n={count}\",\n",
    "                    ha='center'\n",
    "                )\n",
    "    \n",
    "    elif plot_type == 'line':\n",
    "        ax.plot(x_values, y_values, marker='o', linestyle='-', color=color)\n",
    "        \n",
    "        # Add count labels if provided\n",
    "        if counts:\n",
    "            for i, (x, y, count) in enumerate(zip(x_values, y_values, counts)):\n",
    "                ax.text(x, y + max(y_values) * 0.03, f\"n={count}\", ha='center')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_title(title or f\"{y_key} by {x_key}\")\n",
    "    ax.set_xlabel(xlabel or x_key)\n",
    "    ax.set_ylabel(ylabel or y_key)\n",
    "    \n",
    "    # Add grid for readability\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust tick labels if needed\n",
    "    if len(x_values) > 8:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Function to create comparative positional visualizations\n",
    "def plot_positional_comparison(data_groups, label_key, court_dimensions=None, title=None, figsize=(12, 8), \n",
    "                              show_counts=True, marker_scale=5):\n",
    "    \"\"\"\n",
    "    Plot average positions of different groups/situations on the tennis court.\n",
    "    \n",
    "    Parameters:\n",
    "    data_groups (dict): Dictionary mapping labels to lists of position data\n",
    "    label_key (str): Key in the data that contains the group/label information\n",
    "    court_dimensions (dict, optional): Dictionary with court dimensions\n",
    "    title (str, optional): Plot title\n",
    "    figsize (tuple): Figure size\n",
    "    show_counts (bool): Whether to show counts as text labels\n",
    "    marker_scale (int): Factor to scale marker size by count\n",
    "    \n",
    "    Returns:\n",
    "    fig (matplotlib.figure.Figure): The figure containing the plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Draw tennis court\n",
    "    draw_tennis_court(ax, court_dimensions)\n",
    "    \n",
    "    # Color map for different categories\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(data_groups)))\n",
    "    \n",
    "    # Plot average position for each group\n",
    "    for i, (label, group_data) in enumerate(data_groups.items()):\n",
    "        if not group_data:\n",
    "            continue\n",
    "            \n",
    "        # Extract position data\n",
    "        positions_x = [d.get('position_x', 0) for d in group_data]\n",
    "        positions_y = [d.get('position_y', 0) for d in group_data]\n",
    "        \n",
    "        # Calculate average position\n",
    "        avg_x = np.mean(positions_x)\n",
    "        avg_y = np.mean(positions_y)\n",
    "        count = len(group_data)\n",
    "        \n",
    "        # Plot average position with size based on count\n",
    "        ax.scatter(\n",
    "            avg_x, \n",
    "            avg_y,\n",
    "            s=count * marker_scale,\n",
    "            color=colors[i],\n",
    "            label=f\"{label} (n={count})\",\n",
    "            alpha=0.8,\n",
    "            edgecolors='black'\n",
    "        )\n",
    "        \n",
    "        # Add text label if requested\n",
    "        if show_counts:\n",
    "            ax.annotate(\n",
    "                f\"{label}\",\n",
    "                (avg_x, avg_y),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 10),\n",
    "                ha='center',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8)\n",
    "            )\n",
    "    \n",
    "    ax.set_title(title or f\"Average Positions by {label_key}\")\n",
    "    ax.set_xlabel(\"Court Width (m)\")\n",
    "    ax.set_ylabel(\"Court Length (m)\")\n",
    "    ax.legend(title=label_key)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Analysis Panel\n",
    "Multi-plot panel function for report generation\n",
    "Create a comprehensive panel of plots for player movement analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    movement_data (list): List of player movement data points\n",
    "    court_dimensions (dict, optional): Dictionary with court dimensions\n",
    "    figsize (tuple): Figure size\n",
    "    \n",
    "    Returns:\n",
    "    fig (matplotlib.figure.Figure): The figure containing all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multi-plot panel function for report generation\n",
    "def create_analysis_panel(movement_data, court_dimensions=None, figsize=(18, 12)):\n",
    "    if not movement_data or len(movement_data) < 2:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        draw_tennis_court(ax, court_dimensions)\n",
    "        ax.set_title(\"Player Movement Analysis - Insufficient Data\")\n",
    "        return fig\n",
    "        \n",
    "    # Create a 2x2 panel of plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    \n",
    "    # 1. Court coverage heatmap (top left)\n",
    "    plot_court_heatmap(movement_data, plot_type='position', court_dimensions=court_dimensions, \n",
    "                     title=\"Court Coverage\", ax=axes[0, 0], colormap='Blues')\n",
    "    \n",
    "    # 2. Speed heatmap (top right)\n",
    "    plot_court_heatmap(movement_data, plot_type='speed', court_dimensions=court_dimensions,\n",
    "                     title=\"Speed Distribution\", ax=axes[0, 1], colormap='viridis')\n",
    "    \n",
    "    # 3. Movement trajectory (bottom left)\n",
    "    # Extract data\n",
    "    positions_x = np.array([d.get('position_x', 0) for d in movement_data])\n",
    "    positions_y = np.array([d.get('position_y', 0) for d in movement_data])\n",
    "    speeds = np.array([d.get('speed', 0) for d in movement_data])\n",
    "    \n",
    "    # Draw tennis court\n",
    "    draw_tennis_court(axes[1, 0], court_dimensions)\n",
    "    \n",
    "    # Add trajectory path with gradient coloring\n",
    "    points = np.array([positions_x, positions_y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    norm = plt.Normalize(speeds.min(), speeds.max())\n",
    "    lc = plt.matplotlib.collections.LineCollection(segments, cmap='viridis', norm=norm)\n",
    "    lc.set_array(speeds)\n",
    "    lc.set_linewidth(2)\n",
    "    line = axes[1, 0].add_collection(lc)\n",
    "    \n",
    "    # Plot start and end points\n",
    "    axes[1, 0].scatter(positions_x[0], positions_y[0], color='green', s=100, marker='o', label='Start')\n",
    "    axes[1, 0].scatter(positions_x[-1], positions_y[-1], color='red', s=100, marker='o', label='End')\n",
    "    axes[1, 0].legend(loc='upper left')\n",
    "    axes[1, 0].set_title(\"Movement Trajectory\")\n",
    "    \n",
    "    # 4. Speed profile (bottom right)\n",
    "    if 'timestamp' in movement_data[0]:\n",
    "        timestamps = [d.get('timestamp', 0) for d in movement_data]\n",
    "        x_label = 'Time (seconds)'\n",
    "    else:\n",
    "        timestamps = range(len(movement_data))\n",
    "        x_label = 'Frame Index'\n",
    "        \n",
    "    axes[1, 1].plot(timestamps, speeds, color='blue', linewidth=2)\n",
    "    axes[1, 1].set_title(\"Speed Profile\")\n",
    "    axes[1, 1].set_xlabel(x_label)\n",
    "    axes[1, 1].set_ylabel(\"Speed (m/s)\")\n",
    "    axes[1, 1].grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add color bar for the trajectories\n",
    "    cbar = fig.colorbar(line, ax=axes[1, 0])\n",
    "    cbar.set_label('Speed (m/s)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement Analysis Functions\n",
    "Utility Functions to analyze movement of the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_pose_model():\n",
    "    # For single-pose detection\n",
    "    model_path = kagglehub.model_download(\"google/movenet/tensorFlow2/singlepose-lightning\")\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    movenet_single = model.signatures['serving_default']\n",
    "    \n",
    "    # For multi-pose detection (needed for top view with multiple people)\n",
    "    try:\n",
    "        multipose_model_path = kagglehub.model_download(\"google/movenet/tensorFlow2/multipose-lightning\")\n",
    "        multipose_model = tf.saved_model.load(multipose_model_path)\n",
    "        movenet_multi = multipose_model.signatures['serving_default']\n",
    "    except:\n",
    "        print(\"Warning: Could not load multipose model. Using single-pose model for all detections.\")\n",
    "        movenet_multi = movenet_single\n",
    "    \n",
    "    return movenet_multi\n",
    "\n",
    "# Function to check if a point is on the tennis court\n",
    "def is_on_court(point, court_params):\n",
    "    # Court parameters should include court boundaries\n",
    "    x, y = point\n",
    "    court_left = court_params.get('left', 0)\n",
    "    court_right = court_params.get('right', 1)\n",
    "    court_top = court_params.get('top', 0)\n",
    "    court_bottom = court_params.get('bottom', 1)\n",
    "    \n",
    "    return (court_left <= x <= court_right) and (court_top <= y <= court_bottom)\n",
    "\n",
    "# Function to detect multiple people in a frame and identify the player\n",
    "def detect_people(frame, pose_model, frame_index, court_params=None):\n",
    "    # Prepare input frame\n",
    "    input_image = tf.expand_dims(frame, axis=0)\n",
    "    input_image = tf.image.resize_with_pad(input_image, 256, 256)\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    \n",
    "    # Run model inference\n",
    "    outputs = pose_model(input_image)\n",
    "    keypoints_with_scores = outputs['output_0'].numpy()[:, :, :51].reshape((6, 17, 3))\n",
    "    \n",
    "    # For now, we'll focus on people with confidence above threshold\n",
    "    people = []\n",
    "    for person_idx, keypoints in enumerate(keypoints_with_scores):\n",
    "        # Check if person detection is confident enough\n",
    "        person_score = np.mean([keypoint[2] for keypoint in keypoints])\n",
    "        if person_score > 0.3:  # Adjust threshold as needed\n",
    "            # Extract keypoints with confidence scores\n",
    "            person_data = {\n",
    "                'keypoints': keypoints[:, :2],  # x, y coordinates\n",
    "                'scores': keypoints[:, 2],  # confidence scores\n",
    "                'person_id': person_idx,\n",
    "                'frame_index': frame_index,\n",
    "                'person_score': person_score\n",
    "            }\n",
    "            \n",
    "            # Calculate center position of the person\n",
    "            valid_keypoints = keypoints[keypoints[:, 2] > 0.3][:, :2]\n",
    "            if len(valid_keypoints) > 0:\n",
    "                center = np.mean(valid_keypoints, axis=0)\n",
    "                person_data['center'] = center\n",
    "                \n",
    "                # If we have court parameters, check if person is on court\n",
    "                if court_params is not None:\n",
    "                    if is_on_court(center, court_params):\n",
    "                        person_data['on_court'] = True\n",
    "                    else:\n",
    "                        person_data['on_court'] = False\n",
    "                \n",
    "                people.append(person_data)\n",
    "    \n",
    "    return people\n",
    "\n",
    "# Function to identify the main player among detected people\n",
    "def identify_main_player(people, previous_player=None, shot_info=None):\n",
    "    if not people:\n",
    "        return None\n",
    "    \n",
    "    # If we have previous player information, try to match with closest person\n",
    "    if previous_player is not None:\n",
    "        prev_center = previous_player.get('center')\n",
    "        if prev_center is not None:\n",
    "            min_dist = float('inf')\n",
    "            closest_person = None\n",
    "            \n",
    "            for person in people:\n",
    "                if 'center' in person:\n",
    "                    dist = np.linalg.norm(person['center'] - prev_center)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_person = person\n",
    "            \n",
    "            # If distance is reasonable, assume it's the same player\n",
    "            if min_dist < 0.3:  # Threshold for considering it's the same person\n",
    "                return closest_person\n",
    "    \n",
    "    # If we have shot info, use that to identify player (e.g., player near baseline for serving)\n",
    "    if shot_info is not None and 'shot_type' in shot_info:\n",
    "        # For serving, player is likely near baseline\n",
    "        if shot_info['shot_type'] == 'serve':\n",
    "            # Find person closest to baseline\n",
    "            baseline_y = 0.9  # Assuming normalized coordinates where baseline is at y=0.9\n",
    "            min_dist = float('inf')\n",
    "            closest_person = None\n",
    "            \n",
    "            for person in people:\n",
    "                if 'center' in person:\n",
    "                    dist = abs(person['center'][1] - baseline_y)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_person = person\n",
    "            \n",
    "            if closest_person is not None:\n",
    "                return closest_person\n",
    "    \n",
    "    # Default: choose person with highest confidence score\n",
    "    return max(people, key=lambda p: p['person_score']) if people else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movement Tracking across multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def track_player_movement(video_path, pose_model, court_params=None, shot_info=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    player_positions = []\n",
    "    previous_player = None\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    sample_rate = 3  # Process every 3rd frame\n",
    "    \n",
    "    for frame_idx in range(0, frame_count, sample_rate):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert frame to RGB (TensorFlow models expect RGB)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect people in the frame\n",
    "        people = detect_people(frame_rgb, pose_model, frame_idx, court_params)\n",
    "        \n",
    "        # Identify main player\n",
    "        player = identify_main_player(people, previous_player, shot_info)\n",
    "        \n",
    "        if player is not None:\n",
    "            # Add timestamp\n",
    "            player['timestamp'] = frame_idx / fps\n",
    "            player_positions.append(player)\n",
    "            previous_player = player\n",
    "    \n",
    "    cap.release()\n",
    "    return player_positions\n",
    "\n",
    "# Calculate movement metrics for the player\n",
    "def calculate_movement_metrics(player_positions, court_dimensions=None):\n",
    "    if not player_positions:\n",
    "        return {}\n",
    "    \n",
    "    # Extract centers and timestamps\n",
    "    centers = [p['center'] for p in player_positions if 'center' in p]\n",
    "    timestamps = [p['timestamp'] for p in player_positions if 'timestamp' in p]\n",
    "    \n",
    "    if len(centers) < 2:\n",
    "        return {'total_distance': 0, 'avg_speed': 0, 'max_speed': 0, 'acceleration': []}\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    centers = np.array(centers)\n",
    "    timestamps = np.array(timestamps)\n",
    "    \n",
    "    # If we have court dimensions, convert positions to real-world coordinates (meters)\n",
    "    if court_dimensions is not None:\n",
    "        court_width = court_dimensions.get('width', 10.97)  # in meters\n",
    "        court_length = court_dimensions.get('length', 23.77)  # in meters\n",
    "        \n",
    "        # Assuming normalized coordinates (0-1), scale to real-world dimensions\n",
    "        centers[:, 0] *= court_width\n",
    "        centers[:, 1] *= court_length\n",
    "    \n",
    "    # Calculate distances between consecutive positions\n",
    "    diffs = np.diff(centers, axis=0)\n",
    "    distances = np.sqrt(np.sum(diffs**2, axis=1))\n",
    "    \n",
    "    # Calculate time differences\n",
    "    time_diffs = np.diff(timestamps)\n",
    "    \n",
    "    # Calculate speed (distance/time)\n",
    "    speeds = distances / time_diffs\n",
    "    \n",
    "    # Calculate acceleration\n",
    "    acceleration = np.diff(speeds) / time_diffs[:-1] if len(speeds) > 1 else []\n",
    "    \n",
    "    # Smooth the speed values using Savitzky-Golay filter if enough points\n",
    "    if len(speeds) > 10:\n",
    "        window_length = min(11, len(speeds) - (len(speeds) % 2) - 1)  # Ensure odd window length\n",
    "        if window_length > 2:\n",
    "            speeds_smoothed = savgol_filter(speeds, window_length, 2)\n",
    "        else:\n",
    "            speeds_smoothed = speeds\n",
    "    else:\n",
    "        speeds_smoothed = speeds\n",
    "    \n",
    "    # Calculate total distance, average and max speed\n",
    "    total_distance = np.sum(distances)\n",
    "    avg_speed = np.mean(speeds_smoothed)\n",
    "    max_speed = np.max(speeds_smoothed)\n",
    "    \n",
    "    # Prepare movement data for each frame\n",
    "    movement_data = []\n",
    "    for i in range(len(centers)-1):\n",
    "        data_point = {\n",
    "            'position_x': centers[i][0],\n",
    "            'position_y': centers[i][1],\n",
    "            'timestamp': timestamps[i],\n",
    "            'speed': speeds_smoothed[i] if i < len(speeds_smoothed) else 0,\n",
    "        }\n",
    "        \n",
    "        # Add acceleration if available\n",
    "        if i < len(acceleration):\n",
    "            data_point['acceleration'] = acceleration[i]\n",
    "        \n",
    "        movement_data.append(data_point)\n",
    "    \n",
    "    # Add final position\n",
    "    if centers.shape[0] > 0:\n",
    "        movement_data.append({\n",
    "            'position_x': centers[-1][0],\n",
    "            'position_y': centers[-1][1],\n",
    "            'timestamp': timestamps[-1],\n",
    "            'speed': 0,  # Final position has no speed\n",
    "            'acceleration': 0  # Final position has no acceleration\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'total_distance': total_distance,\n",
    "        'avg_speed': avg_speed,\n",
    "        'max_speed': max_speed,\n",
    "        'movement_data': movement_data\n",
    "    }\n",
    "\n",
    "# Correlate player positions with shot effectiveness\n",
    "def analyze_position_shot_correlation(movement_data, shot_data):\n",
    "    # Merge movement data with shot data based on timestamps\n",
    "    merged_data = []\n",
    "    \n",
    "    for shot in shot_data:\n",
    "        # Find movement data closest to shot timestamp\n",
    "        shot_time = shot.get('timestamp', 0)\n",
    "        closest_movement = min(movement_data, key=lambda m: abs(m.get('timestamp', 0) - shot_time))\n",
    "        \n",
    "        merged_point = {\n",
    "            'position_x': closest_movement.get('position_x', 0),\n",
    "            'position_y': closest_movement.get('position_y', 0),\n",
    "            'shot_type': shot.get('shot_type', 'unknown'),\n",
    "            'success': shot.get('success', 0),\n",
    "            'speed': closest_movement.get('speed', 0),\n",
    "            'to_sideline_distance': shot.get('to_sideline_distance', 0),\n",
    "            'to_baseline_distance': shot.get('to_baseline_distance', 0)\n",
    "        }\n",
    "        \n",
    "        merged_data.append(merged_point)\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(merged_data)\n",
    "    \n",
    "    # Create position clusters using KMeans\n",
    "    if len(df) > 5:  # Need enough data points for clustering\n",
    "        position_data = df[['position_x', 'position_y']].values\n",
    "        kmeans = KMeans(n_clusters=min(5, len(df)), random_state=42)\n",
    "        df['position_cluster'] = kmeans.fit_predict(position_data)\n",
    "        \n",
    "        # Calculate success rate by position cluster\n",
    "        success_by_cluster = df.groupby('position_cluster')['success'].agg(['mean', 'count']).reset_index()\n",
    "        success_by_cluster.columns = ['position_cluster', 'success_rate', 'count']\n",
    "        \n",
    "        # Calculate shot type distribution by position cluster\n",
    "        shot_type_by_cluster = df.groupby(['position_cluster', 'shot_type']).size().unstack(fill_value=0)\n",
    "        \n",
    "        return {\n",
    "            'merged_data': df.to_dict('records'),  # Convert back to list of dicts for plotting\n",
    "            'success_by_cluster': success_by_cluster.to_dict('records'),\n",
    "            'shot_type_by_cluster': shot_type_by_cluster.reset_index().to_dict('records')\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'merged_data': merged_data,\n",
    "            'success_by_cluster': None,\n",
    "            'shot_type_by_cluster': None\n",
    "        }\n",
    "\n",
    "# Analyze player movement in different game situations\n",
    "def analyze_situational_movement(movement_data, shot_data):\n",
    "    # Categorize shots by situation\n",
    "    situations = {\n",
    "        'serving': [],\n",
    "        'returning': [],\n",
    "        'baseline_rally': [],\n",
    "        'net_play': []\n",
    "    }\n",
    "    \n",
    "    # Merge movement and shot data\n",
    "    merged_data = []\n",
    "    \n",
    "    for shot in shot_data:\n",
    "        # Determine situation based on shot type and position\n",
    "        shot_type = shot.get('shot_type', 'unknown')\n",
    "        baseline_distance = shot.get('to_baseline_distance', 0)\n",
    "        \n",
    "        # Find movement data closest to shot timestamp\n",
    "        shot_time = shot.get('timestamp', 0)\n",
    "        closest_movement = min(movement_data, key=lambda m: abs(m.get('timestamp', 0) - shot_time))\n",
    "        \n",
    "        # Combine shot and movement data\n",
    "        combined = {**shot, **closest_movement}\n",
    "        \n",
    "        # Categorize by situation\n",
    "        if shot_type == 'serve':\n",
    "            situation = 'serving'\n",
    "        elif shot_type == 'return':\n",
    "            situation = 'returning'\n",
    "        elif baseline_distance < 3:  # Close to net\n",
    "            situation = 'net_play'\n",
    "        else:\n",
    "            situation = 'baseline_rally'\n",
    "        \n",
    "        combined['situation'] = situation\n",
    "        situations[situation].append(combined)\n",
    "        merged_data.append(combined)\n",
    "    \n",
    "    # Calculate movement metrics for each situation\n",
    "    situation_metrics = {}\n",
    "    for situation, data in situations.items():\n",
    "        if len(data) > 0:\n",
    "            position_x = [d.get('position_x', 0) for d in data]\n",
    "            position_y = [d.get('position_y', 0) for d in data]\n",
    "            speeds = [d.get('speed', 0) for d in data]\n",
    "            \n",
    "            metrics = {\n",
    "                'avg_position_x': np.mean(position_x),\n",
    "                'avg_position_y': np.mean(position_y),\n",
    "                'avg_speed': np.mean(speeds),\n",
    "                'count': len(data)\n",
    "            }\n",
    "            \n",
    "            situation_metrics[situation] = metrics\n",
    "    \n",
    "    return {\n",
    "        'merged_data': merged_data,\n",
    "        'situation_metrics': situation_metrics,\n",
    "        'situations': situations\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification algorithm for the main player across multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identify_main_player_in_sequence(all_people_tracks, video_info):\n",
    "    if not all_people_tracks:\n",
    "        return []\n",
    "    \n",
    "    # Get information about expected ball landing position\n",
    "    to_sideline_distance = video_info.get('to_sideline_distance', None)\n",
    "    to_baseline_distance = video_info.get('to_baseline_distance', None)\n",
    "    \n",
    "    # Convert court dimensions to pixel coordinates (approximate)\n",
    "    court_width = video_info.get('width', 1920)\n",
    "    court_height = video_info.get('height', 1080)\n",
    "    \n",
    "    # Assuming the court is centered in the image and takes up most of the frame\n",
    "    expected_x = None\n",
    "    expected_y = None\n",
    "    \n",
    "    if to_sideline_distance is not None and to_baseline_distance is not None:\n",
    "        # Convert distances to approximate pixel coordinates\n",
    "        # This would need calibration for exact values\n",
    "        expected_x = court_width * (to_sideline_distance / 10.97)  # 10.97m is standard tennis court width\n",
    "        expected_y = court_height * (to_baseline_distance / 23.77)  # 23.77m is standard tennis court length\n",
    "    \n",
    "    # For each frame, calculate the likelihood of each person being the main player\n",
    "    person_scores = {}  # Track accumulated scores for each person ID\n",
    "    \n",
    "    for frame_data in all_people_tracks:\n",
    "        people = frame_data.get('people', [])\n",
    "        \n",
    "        for person in people:\n",
    "            person_id = person.get('person_id')\n",
    "            \n",
    "            if person_id not in person_scores:\n",
    "                person_scores[person_id] = 0\n",
    "            \n",
    "            # Increase score based on various factors\n",
    "            \n",
    "            # 1. Higher detection confidence means more likely to be a player\n",
    "            person_scores[person_id] += person.get('person_score', 0) * 5\n",
    "            \n",
    "            # 2. If we know expected position, closer to it means more likely to be the player\n",
    "            if expected_x is not None and expected_y is not None and 'center' in person:\n",
    "                dist_to_expected = np.sqrt(\n",
    "                    (person['center'][0] - expected_x)**2 + \n",
    "                    (person['center'][1] - expected_y)**2\n",
    "                )\n",
    "                # Inverse distance (closer = higher score)\n",
    "                proximity_score = 1000 / (dist_to_expected + 10)  # +10 to avoid division by zero\n",
    "                person_scores[person_id] += proximity_score\n",
    "            \n",
    "            # 3. If person is on court, more likely to be player\n",
    "            if person.get('on_court', False):\n",
    "                person_scores[person_id] += 10\n",
    "    \n",
    "    # Identify the person with the highest score\n",
    "    if person_scores:\n",
    "        main_player_id = max(person_scores, key=person_scores.get)\n",
    "        \n",
    "        # Extract the main player's track\n",
    "        main_player_track = []\n",
    "        \n",
    "        for frame_data in all_people_tracks:\n",
    "            timestamp = frame_data.get('timestamp')\n",
    "            \n",
    "            # Find the main player in this frame\n",
    "            main_player = None\n",
    "            for person in frame_data.get('people', []):\n",
    "                if person.get('person_id') == main_player_id:\n",
    "                    main_player = person\n",
    "                    break\n",
    "            \n",
    "            # If main player is found in this frame, add to track\n",
    "            if main_player is not None:\n",
    "                # Add timestamp if not already present\n",
    "                if 'timestamp' not in main_player:\n",
    "                    main_player['timestamp'] = timestamp\n",
    "                \n",
    "                main_player_track.append(main_player)\n",
    "        \n",
    "        return main_player_track\n",
    "    \n",
    "    # If no scores were accumulated, return empty track\n",
    "    return []\n",
    "\n",
    "# Process top-view specific data\n",
    "def analyze_top_view_movement(video_info, pose_model):\n",
    "    video_path = video_info['path']\n",
    "    \n",
    "    # Check if it's a top-view video\n",
    "    if 'view_type' in video_info and video_info['view_type'].lower() == 'top':\n",
    "        print(f\"Processing top-view video: {video_path}\")\n",
    "        \n",
    "        # Special processing for top-view\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # For top view, we need to track multiple people and identify the main player\n",
    "        all_people_tracks = []\n",
    "        sample_rate = 3  # Process every 3rd frame for efficiency\n",
    "        \n",
    "        for frame_idx in range(0, frame_count, sample_rate):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Convert frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect people in the frame\n",
    "            people = detect_people(frame_rgb, pose_model, frame_idx)\n",
    "            \n",
    "            # Add timestamp to each person\n",
    "            timestamp = frame_idx / fps\n",
    "            for person in people:\n",
    "                person['timestamp'] = timestamp\n",
    "            \n",
    "            all_people_tracks.append({\n",
    "                'frame_idx': frame_idx,\n",
    "                'timestamp': timestamp,\n",
    "                'people': people\n",
    "            })\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Now we need to identify which detections correspond to the main player\n",
    "        main_player_track = identify_main_player_in_sequence(all_people_tracks, video_info)\n",
    "        \n",
    "        return main_player_track\n",
    "    else:\n",
    "        # For side-view, use the regular tracking function\n",
    "        return track_player_movement(video_path, pose_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player movement analysis with consolidated plotting.\n",
    "    \n",
    "    Parameters:\n",
    "    video_data (list): List of dictionaries with video information\n",
    "    shot_data (list, optional): List of dictionaries with shot information\n",
    "    output_dir (str): Directory to save output files\n",
    "    \n",
    "    Returns:\n",
    "    dict: Results of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_player_movement_consolidated(video_data, shot_data=None, output_dir='./output'):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Load pose estimation model\n",
    "    pose_model = load_multi_pose_model()\n",
    "    \n",
    "    # Process each video\n",
    "    for video_info in video_data:\n",
    "        video_path = video_info['path']\n",
    "        video_id = video_info.get('index', 0)\n",
    "        \n",
    "        print(f\"Processing video: {video_path}\")\n",
    "        \n",
    "        # Check view type and process accordingly\n",
    "        view_type = video_info.get('view_type', 'side').lower()\n",
    "        \n",
    "        if view_type == 'top':\n",
    "            # Use specialized top-view processing\n",
    "            player_positions = analyze_top_view_movement(video_info, pose_model)\n",
    "        else:\n",
    "            # Use standard processing for side view\n",
    "            court_params = {\n",
    "                'left': 0,\n",
    "                'right': video_info.get('width', 1920),\n",
    "                'top': 0,\n",
    "                'bottom': video_info.get('height', 1080)\n",
    "            }\n",
    "            \n",
    "            # Convert to normalized coordinates\n",
    "            for key in court_params:\n",
    "                if key in ['left', 'right']:\n",
    "                    court_params[key] /= video_info.get('width', 1920)\n",
    "                else:\n",
    "                    court_params[key] /= video_info.get('height', 1080)\n",
    "            \n",
    "            player_positions = track_player_movement(\n",
    "                video_path,\n",
    "                pose_model,\n",
    "                court_params=court_params,\n",
    "                shot_info=video_info\n",
    "            )\n",
    "        \n",
    "        # Define court dimensions (in meters)\n",
    "        court_dimensions = {\n",
    "            'width': 10.97,  # standard tennis court width\n",
    "            'length': 23.77  # standard tennis court length\n",
    "        }\n",
    "        \n",
    "        # Calculate movement metrics\n",
    "        movement_metrics = calculate_movement_metrics(player_positions, court_dimensions)\n",
    "        movement_data = movement_metrics.get('movement_data', [])\n",
    "        \n",
    "        # Initialize plots dictionary\n",
    "        plots = {}\n",
    "        \n",
    "        # 1. Create comprehensive analysis panel (combines multiple plots)\n",
    "        analysis_panel = create_analysis_panel(movement_data, court_dimensions)\n",
    "        panel_filename = f\"video_{video_id}_analysis_panel.png\"\n",
    "        analysis_panel.savefig(os.path.join(output_dir, panel_filename))\n",
    "        plots['analysis_panel'] = panel_filename\n",
    "        plt.close(analysis_panel)\n",
    "        \n",
    "        # 2. Create court coverage heatmap\n",
    "        if len(movement_data) >= 2:\n",
    "            fig, ax = plot_court_heatmap(movement_data, plot_type='position', \n",
    "                                     court_dimensions=court_dimensions,\n",
    "                                     title=f\"Video {video_id} - Player Court Coverage\")\n",
    "            coverage_filename = f\"video_{video_id}_court_coverage.png\"\n",
    "            fig.savefig(os.path.join(output_dir, coverage_filename))\n",
    "            plots['court_coverage'] = coverage_filename\n",
    "            plt.close(fig)\n",
    "        \n",
    "        # 3. Process shot data if available\n",
    "        position_shot_correlation = None\n",
    "        situational_analysis = None\n",
    "        \n",
    "        if shot_data is not None:\n",
    "            # Filter shot data for this video\n",
    "            video_shot_data = [s for s in shot_data if s.get('video_id', 0) == video_id]\n",
    "            \n",
    "            if video_shot_data:\n",
    "                # Analyze position-shot correlation\n",
    "                position_shot_correlation = analyze_position_shot_correlation(movement_data, video_shot_data)\n",
    "                \n",
    "                # Create shot success heatmap\n",
    "                if position_shot_correlation and position_shot_correlation['merged_data']:\n",
    "                    fig, ax = plot_court_heatmap(\n",
    "                        position_shot_correlation['merged_data'], \n",
    "                        plot_type='success',\n",
    "                        court_dimensions=court_dimensions,\n",
    "                        title=f\"Video {video_id} - Shot Success by Position\"\n",
    "                    )\n",
    "                    success_filename = f\"video_{video_id}_shot_success.png\"\n",
    "                    fig.savefig(os.path.join(output_dir, success_filename))\n",
    "                    plots['shot_success'] = success_filename\n",
    "                    plt.close(fig)\n",
    "                    \n",
    "                    # Create shot type distribution map\n",
    "                    fig, ax = plot_court_heatmap(\n",
    "                        position_shot_correlation['merged_data'], \n",
    "                        plot_type='shot_type',\n",
    "                        court_dimensions=court_dimensions,\n",
    "                        title=f\"Video {video_id} - Shot Types by Position\"\n",
    "                    )\n",
    "                    shottype_filename = f\"video_{video_id}_shot_types.png\"\n",
    "                    fig.savefig(os.path.join(output_dir, shottype_filename))\n",
    "                    plots['shot_types'] = shottype_filename\n",
    "                    plt.close(fig)\n",
    "                \n",
    "                # Analyze situational movement\n",
    "                situational_analysis = analyze_situational_movement(movement_data, video_shot_data)\n",
    "                \n",
    "                if situational_analysis and situational_analysis['merged_data']:\n",
    "                    # Create situation comparison chart\n",
    "                    situation_metrics = situational_analysis['situation_metrics']\n",
    "                    if situation_metrics:\n",
    "                        # Average speed by situation\n",
    "                        fig = plot_comparison_chart(\n",
    "                            situation_metrics, \n",
    "                            x_key='situation', \n",
    "                            y_key='avg_speed',\n",
    "                            title=f\"Video {video_id} - Average Speed by Situation\",\n",
    "                            xlabel=\"Game Situation\",\n",
    "                            ylabel=\"Average Speed (m/s)\",\n",
    "                            count_key='count'\n",
    "                        )\n",
    "                        speed_filename = f\"video_{video_id}_situation_speeds.png\"\n",
    "                        fig.savefig(os.path.join(output_dir, speed_filename))\n",
    "                        plots['situation_speeds'] = speed_filename\n",
    "                        plt.close(fig)\n",
    "                        \n",
    "                        # Average position by situation\n",
    "                        fig = plot_positional_comparison(\n",
    "                            situational_analysis['situations'],\n",
    "                            label_key='Situation',\n",
    "                            court_dimensions=court_dimensions,\n",
    "                            title=f\"Video {video_id} - Average Position by Situation\"\n",
    "                        )\n",
    "                        position_filename = f\"video_{video_id}_situation_positions.png\"\n",
    "                        fig.savefig(os.path.join(output_dir, position_filename))\n",
    "                        plots['situation_positions'] = position_filename\n",
    "                        plt.close(fig)\n",
    "        \n",
    "        # 4. Create detailed movement trajectory\n",
    "        if len(movement_data) >= 2:\n",
    "            fig = plot_movement_trajectory(\n",
    "                movement_data, \n",
    "                court_dimensions=court_dimensions,\n",
    "                title=f\"Video {video_id} - Player Movement Trajectory\"\n",
    "            )\n",
    "            trajectory_filename = f\"video_{video_id}_trajectory.png\"\n",
    "            fig.savefig(os.path.join(output_dir, trajectory_filename))\n",
    "            plots['trajectory'] = trajectory_filename\n",
    "            plt.close(fig)\n",
    "            \n",
    "        # Store results for this video\n",
    "        results[video_id] = {\n",
    "            'movement_metrics': {\n",
    "                'total_distance': movement_metrics.get('total_distance', 0),\n",
    "                'avg_speed': movement_metrics.get('avg_speed', 0),\n",
    "                'max_speed': movement_metrics.get('max_speed', 0)\n",
    "            },\n",
    "            'player_positions': player_positions,\n",
    "            'movement_data': movement_data,\n",
    "            'view_type': view_type,\n",
    "            'plots': plots,\n",
    "            'position_shot_correlation': position_shot_correlation,\n",
    "            'situational_movement': situational_analysis\n",
    "        }    \n",
    "    return {'results': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive analysis\n",
    "analysis_results = analyze_player_movement_consolidated(video_data, shot_features)\n",
    "# Since there are too many images, We have dumped them into an output Directory.\n",
    "# However we have picked random 3 images of each type and plotting just for visualization purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing 9 analysis results for getting a raw idea on analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_9_images_by_pattern(output_dir='./output'):\n",
    "    \"\"\"\n",
    "    Scans the output directory for PNG images that match three categories:\n",
    "      - analysis_panel\n",
    "      - court_coverage\n",
    "      - trajectory\n",
    "    Randomly selects 3 images from each category and displays them in a 3x3 grid.\n",
    "    \"\"\"\n",
    "    # List all files in the output directory\n",
    "    all_files = os.listdir(output_dir)\n",
    "    # Filter for .png files\n",
    "    png_files = [f for f in all_files if f.endswith('.png')]\n",
    "    \n",
    "    # Build full paths and filter based on filename patterns\n",
    "    analysis_panel_files = [os.path.join(output_dir, f) for f in png_files if 'analysis_panel' in f]\n",
    "    court_coverage_files = [os.path.join(output_dir, f) for f in png_files if 'court_coverage' in f]\n",
    "    trajectory_files = [os.path.join(output_dir, f) for f in png_files if 'trajectory' in f]\n",
    "    \n",
    "    # Debug: print out how many files we found for each category\n",
    "    print(f\"Found {len(analysis_panel_files)} analysis panel files, {len(court_coverage_files)} court coverage files, and {len(trajectory_files)} trajectory files.\")\n",
    "    \n",
    "    # Randomly sample 3 files from each category (or as many as available)\n",
    "    sample_analysis = random.sample(analysis_panel_files, min(3, len(analysis_panel_files)))\n",
    "    sample_coverage = random.sample(court_coverage_files, min(3, len(court_coverage_files)))\n",
    "    sample_trajectory = random.sample(trajectory_files, min(3, len(trajectory_files)))\n",
    "    \n",
    "    # Combine the samples; ideally we have 9 images\n",
    "    selected_images = sample_analysis + sample_coverage + sample_trajectory\n",
    "    \n",
    "    # If fewer than 9 images, pad with None\n",
    "    while len(selected_images) < 9:\n",
    "        selected_images.append(None)\n",
    "    \n",
    "    # Create a 3x3 subplot grid\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        image_path = selected_images[i]\n",
    "        if image_path is not None:\n",
    "            try:\n",
    "                image = plt.imread(image_path)\n",
    "                ax.imshow(image)\n",
    "                ax.set_title(os.path.basename(image_path), fontsize=8)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {image_path}: {e}\")\n",
    "                ax.text(0.5, 0.5, 'Error loading image', ha='center', va='center')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'No image available', ha='center', va='center')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "visualize_random_9_images_by_pattern(output_dir='./output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Match Strategy and Performance Metrics\n",
    "Integrate the above components to develop high-level match strategy analysis and performance metrics.\n",
    "\n",
    "a) Develop a system to automatically extract key performance indicators (e.g., winners, unforced errors, serve efficiency).\n",
    "\n",
    "b) Implement algorithms to identify critical points and analyze player performance under pressure.\n",
    "\n",
    "c) Create visualizations that summarize match dynamics and player strategies.\n",
    "\n",
    "d) Propose and implement a novel metric or analysis technique that provides unique insights into tennis performance or strategy.\n",
    "\n",
    "Deliverables:\n",
    "- Python code for the integrated analysis system\n",
    "- A set of visualizations demonstrating your system's capabilities\n",
    "- A final report (max 5 pages) summarizing the entire project, including a discussion of strategic insights and potential applications for players and coaches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption for Success Metrics \n",
    "Since there's no success metric, We're generating shot based success and failure metrics and then later on use those metrics for doing above classifications.\n",
    "- These metrics are generated based on shot distance on double sideline and base line.\n",
    "- In some cases additional random factor is also used to tweak success metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate synthetic success data based on court position\n",
    "    \n",
    "    Parameters:\n",
    "    - video_data: List of dictionaries containing video information\n",
    "    \n",
    "    Returns:\n",
    "    - Enhanced video_data with success estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic success data based on court position\n",
    "def generate_success_data(video_data):\n",
    "    enhanced_data = []\n",
    "    \n",
    "    # Define \"sweet spots\" on the court - positions that typically yield higher success\n",
    "    # These are based on tennis strategy: being close to baseline for groundstrokes\n",
    "    # and closer to net for volleys\n",
    "    sweet_spots = [\n",
    "        {'to_sideline_distance': 3.0, 'to_baseline_distance': 1.0, 'radius': 2.0},  # Baseline corner\n",
    "        {'to_sideline_distance': 5.5, 'to_baseline_distance': 1.0, 'radius': 2.0},  # Baseline center\n",
    "        {'to_sideline_distance': 5.5, 'to_baseline_distance': 7.0, 'radius': 1.5},  # Net center\n",
    "    ]\n",
    "    \n",
    "    for video in video_data:\n",
    "        video_copy = video.copy()\n",
    "        \n",
    "        # Calculate distance to nearest sweet spot\n",
    "        min_distance = float('inf')\n",
    "        for spot in sweet_spots:\n",
    "            distance = sqrt(\n",
    "                (video['to_sideline_distance'] - spot['to_sideline_distance'])**2 +\n",
    "                (video['to_baseline_distance'] - spot['to_baseline_distance'])**2\n",
    "            )\n",
    "            normalized_distance = distance / spot['radius']\n",
    "            min_distance = min(min_distance, normalized_distance)\n",
    "        \n",
    "        # Convert distance to success probability (closer = higher success)\n",
    "        # Add some randomness for realism\n",
    "        base_probability = max(0, min(1, 1 - (min_distance * 0.25)))\n",
    "        random_factor = np.random.normal(0, 0.1)  # Mean 0, std 0.1\n",
    "        success_probability = max(0, min(1, base_probability + random_factor))\n",
    "        \n",
    "        # Determine binary success (1 = success, 0 = failure)\n",
    "        success = 1 if np.random.random() < success_probability else 0\n",
    "        \n",
    "        # Add to video data\n",
    "        video_copy['success'] = success\n",
    "        video_copy['success_probability'] = success_probability\n",
    "        \n",
    "        # Also add shot type based on position\n",
    "        if video['to_baseline_distance'] < 2.0:\n",
    "            # Near baseline - likely a groundstroke\n",
    "            if video['to_sideline_distance'] < 3.0 or video['to_sideline_distance'] > 8.0:\n",
    "                shot_type = 'backhand'\n",
    "            else:\n",
    "                shot_type = 'forehand'\n",
    "        elif video['to_baseline_distance'] > 7.0:\n",
    "            # Near net - likely a volley\n",
    "            shot_type = 'volley'\n",
    "        else:\n",
    "            # Middle of court - could be various shots\n",
    "            if video['environment'] == 'outdoor' and video['shot_type'] == 'cross':\n",
    "                shot_type = 'backhand'\n",
    "            else:\n",
    "                shot_type = 'forehand'\n",
    "        \n",
    "        video_copy['shot_type'] = shot_type\n",
    "        \n",
    "        enhanced_data.append(video_copy)\n",
    "    \n",
    "    return enhanced_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze shot distribution by court position\n",
    "    \n",
    "    Parameters:\n",
    "    - video_data: List of dictionaries containing video information with success estimates\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to perform basic court position analysis\n",
    "def analyze_court_positions(video_data):\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(video_data)\n",
    "    \n",
    "    # Calculate basic position-based metrics\n",
    "    position_metrics = {\n",
    "        'avg_sideline_distance': df['to_sideline_distance'].mean(),\n",
    "        'avg_baseline_distance': df['to_baseline_distance'].mean(),\n",
    "        'total_shots': len(df),\n",
    "        'success_rate': df['success'].mean() if 'success' in df.columns else None\n",
    "    }\n",
    "    \n",
    "    # Cluster positions to identify patterns\n",
    "    if len(df) >= 5:  # Need at least 5 data points for meaningful clustering\n",
    "        # Prepare position data\n",
    "        positions = df[['to_sideline_distance', 'to_baseline_distance']].values\n",
    "        \n",
    "        # Determine optimal number of clusters (between 2 and 5)\n",
    "        max_clusters = min(5, len(df) - 1)\n",
    "        inertias = []\n",
    "        for k in range(2, max_clusters + 1):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(positions)\n",
    "            inertias.append(kmeans.inertia_)\n",
    "        \n",
    "        # Find elbow point\n",
    "        if len(inertias) > 1:\n",
    "            k_opt = 2  # Default\n",
    "            max_curvature = 0\n",
    "            for i in range(1, len(inertias) - 1):\n",
    "                # Calculate curvature using angle between consecutive segments\n",
    "                a = np.array([i-1, inertias[i-1]])\n",
    "                b = np.array([i, inertias[i]])\n",
    "                c = np.array([i+1, inertias[i+1]])\n",
    "                \n",
    "                ab = b - a\n",
    "                bc = c - b\n",
    "                \n",
    "                # Normalize\n",
    "                ab = ab / np.linalg.norm(ab)\n",
    "                bc = bc / np.linalg.norm(bc)\n",
    "                \n",
    "                # Calculate angle\n",
    "                curvature = np.abs(np.arccos(np.dot(ab, bc)))\n",
    "                \n",
    "                if curvature > max_curvature:\n",
    "                    max_curvature = curvature\n",
    "                    k_opt = i + 2  # +2 because i starts at 1 and we add 1 for original range\n",
    "        else:\n",
    "            k_opt = 2\n",
    "        \n",
    "        # Cluster with optimal k\n",
    "        kmeans = KMeans(n_clusters=k_opt, random_state=42)\n",
    "        df['position_cluster'] = kmeans.fit_predict(positions)\n",
    "        \n",
    "        # Calculate success rate by cluster\n",
    "        cluster_stats = df.groupby('position_cluster').agg({\n",
    "            'to_sideline_distance': 'mean',\n",
    "            'to_baseline_distance': 'mean',\n",
    "            'success': 'mean' if 'success' in df.columns else None,\n",
    "            'shot_type': lambda x: x.value_counts().index[0]\n",
    "        }).reset_index()\n",
    "        \n",
    "        position_metrics['position_clusters'] = cluster_stats.to_dict('records')\n",
    "    \n",
    "    # Calculate shot type distribution\n",
    "    if 'shot_type' in df.columns:\n",
    "        shot_counts = df['shot_type'].value_counts().to_dict()\n",
    "        position_metrics['shot_type_distribution'] = shot_counts\n",
    "    \n",
    "    # Success rate by environment\n",
    "    if 'success' in df.columns and 'environment' in df.columns:\n",
    "        success_by_env = df.groupby('environment')['success'].mean().to_dict()\n",
    "        position_metrics['success_by_environment'] = success_by_env\n",
    "    \n",
    "    # Success rate by shot type\n",
    "    if 'success' in df.columns and 'shot_type' in df.columns:\n",
    "        success_by_shot = df.groupby('shot_type')['success'].mean().to_dict()\n",
    "        position_metrics['success_by_shot_type'] = success_by_shot\n",
    "    \n",
    "    return position_metrics\n",
    "\n",
    "# Function to visualize court position analysis\n",
    "def visualize_court_positions(video_data, court_dimensions=None):\n",
    "    \"\"\"\n",
    "    Create visualizations of shot distribution by court position\n",
    "    \n",
    "    Parameters:\n",
    "    - video_data: List of dictionaries containing video information with success estimates\n",
    "    - court_dimensions: Optional dictionary with court dimensions\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of matplotlib figures\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(video_data)\n",
    "    figures = {}\n",
    "    \n",
    "    # 1. Shot Distribution by Court Position\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Draw tennis court\n",
    "    draw_tennis_court(ax, court_dimensions)\n",
    "    \n",
    "    # Create scatter plot colored by success\n",
    "    if 'success' in df.columns:\n",
    "        scatter = ax.scatter(\n",
    "            df['to_sideline_distance'], \n",
    "            df['to_baseline_distance'], \n",
    "            c=df['success'],\n",
    "            cmap='RdYlGn',\n",
    "            alpha=0.7,\n",
    "            s=100\n",
    "        )\n",
    "        \n",
    "        cbar = fig.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Shot Success')\n",
    "        \n",
    "        ax.set_title('Shot Success by Court Position')\n",
    "    else:\n",
    "        # Color by shot type if success not available\n",
    "        if 'shot_type' in df.columns:\n",
    "            shot_types = df['shot_type'].unique()\n",
    "            for shot_type in shot_types:\n",
    "                subset = df[df['shot_type'] == shot_type]\n",
    "                ax.scatter(\n",
    "                    subset['to_sideline_distance'],\n",
    "                    subset['to_baseline_distance'],\n",
    "                    label=shot_type,\n",
    "                    alpha=0.7,\n",
    "                    s=100\n",
    "                )\n",
    "            ax.legend(title='Shot Type')\n",
    "            ax.set_title('Shot Type Distribution by Court Position')\n",
    "        else:\n",
    "            # Simple position plot\n",
    "            ax.scatter(df['to_sideline_distance'], df['to_baseline_distance'], alpha=0.7, s=100)\n",
    "            ax.set_title('Shot Distribution by Court Position')\n",
    "    \n",
    "    ax.set_xlabel('Distance to Sideline (m)')\n",
    "    ax.set_ylabel('Distance to Baseline (m)')\n",
    "    \n",
    "    figures['shot_distribution'] = fig\n",
    "    \n",
    "    # 2. Position Heatmap\n",
    "    if len(df) >= 5:  # Need enough points for a meaningful heatmap\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        # Draw tennis court\n",
    "        draw_tennis_court(ax, court_dimensions)\n",
    "        \n",
    "        try:\n",
    "            # Create heatmap using KDE\n",
    "            sns.kdeplot(\n",
    "                x=df['to_sideline_distance'],\n",
    "                y=df['to_baseline_distance'],\n",
    "                cmap='hot',\n",
    "                fill=True,\n",
    "                alpha=0.7,\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            ax.set_title('Shot Density Heatmap')\n",
    "            ax.set_xlabel('Distance to Sideline (m)')\n",
    "            ax.set_ylabel('Distance to Baseline (m)')\n",
    "            \n",
    "            figures['position_heatmap'] = fig\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating position heatmap: {e}\")\n",
    "    \n",
    "    # 3. Success Rate by Shot Type (if available)\n",
    "    if 'success' in df.columns and 'shot_type' in df.columns:\n",
    "        success_by_shot = df.groupby('shot_type')['success'].agg(['mean', 'count']).reset_index()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        bars = ax.bar(\n",
    "            success_by_shot['shot_type'],\n",
    "            success_by_shot['mean'] * 100,  # Convert to percentage\n",
    "            color='skyblue'\n",
    "        )\n",
    "        \n",
    "        # Add count labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            count = success_by_shot.iloc[i]['count']\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width()/2, \n",
    "                bar.get_height() + 2, \n",
    "                f'n={count}',\n",
    "                ha='center'\n",
    "            )\n",
    "        \n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_ylabel('Success Rate (%)')\n",
    "        ax.set_title('Shot Success Rate by Type')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        figures['success_by_shot_type'] = fig\n",
    "    \n",
    "    # 4. Environment Comparison (if available)\n",
    "    if 'environment' in df.columns:\n",
    "        env_counts = df['environment'].value_counts()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        \n",
    "        ax.pie(\n",
    "            env_counts,\n",
    "            labels=env_counts.index,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90\n",
    "        )\n",
    "        \n",
    "        ax.axis('equal')\n",
    "        ax.set_title('Shot Distribution by Environment')\n",
    "        \n",
    "        figures['environment_distribution'] = fig\n",
    "        \n",
    "        # Add success by environment if available\n",
    "        if 'success' in df.columns:\n",
    "            success_by_env = df.groupby('environment')['success'].agg(['mean', 'count']).reset_index()\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            \n",
    "            bars = ax.bar(\n",
    "                success_by_env['environment'],\n",
    "                success_by_env['mean'] * 100,  # Convert to percentage\n",
    "                color='lightgreen'\n",
    "            )\n",
    "            \n",
    "            # Add count labels\n",
    "            for i, bar in enumerate(bars):\n",
    "                count = success_by_env.iloc[i]['count']\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    bar.get_height() + 2, \n",
    "                    f'n={count}',\n",
    "                    ha='center'\n",
    "                )\n",
    "            \n",
    "            ax.set_ylim(0, 100)\n",
    "            ax.set_ylabel('Success Rate (%)')\n",
    "            ax.set_title('Shot Success Rate by Environment')\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            figures['success_by_environment'] = fig\n",
    "    \n",
    "    return figures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added Visualisations\n",
    "Here we have covered added visualisations based on different frames\n",
    "\n",
    "Function: **generate_position_insights**\n",
    "\n",
    "Generate strategic insights from court position analysis\n",
    "    \n",
    "    Parameters:\n",
    "    - position_metrics: Dictionary containing position analysis results\n",
    "    \n",
    "    Returns:\n",
    "    - List of insight dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Draw tennis court for visualization\n",
    "def draw_tennis_court(ax, court_dimensions=None):\n",
    "    # Default court dimensions in meters\n",
    "    court_width = 10.97\n",
    "    court_length = 23.77\n",
    "    \n",
    "    if court_dimensions is not None:\n",
    "        court_width = court_dimensions.get('width', court_width)\n",
    "        court_length = court_dimensions.get('length', court_length)\n",
    "    \n",
    "    # Draw outer court\n",
    "    court = Rectangle((0, 0), court_width, court_length, fill=False, color='black')\n",
    "    ax.add_patch(court)\n",
    "    \n",
    "    # Draw net\n",
    "    ax.plot([0, court_width], [court_length/2, court_length/2], 'k-', linewidth=2)\n",
    "    \n",
    "    # Draw service lines\n",
    "    ax.plot([0, court_width], [court_length*0.25, court_length*0.25], 'k-', linewidth=1)\n",
    "    ax.plot([0, court_width], [court_length*0.75, court_length*0.75], 'k-', linewidth=1)\n",
    "    \n",
    "    # Draw center service line\n",
    "    ax.plot([court_width/2, court_width/2], [court_length*0.25, court_length*0.75], 'k-', linewidth=1)\n",
    "    \n",
    "    # Set limits\n",
    "    ax.set_xlim(-1, court_width + 1)\n",
    "    ax.set_ylim(-1, court_length + 1)\n",
    "    \n",
    "    # Set aspect ratio to equal\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# Generate strategic insights based on court position analysis\n",
    "def generate_position_insights(position_metrics):\n",
    "    insights = []\n",
    "    \n",
    "    # 1. Overall Court Position Insights\n",
    "    avg_baseline = position_metrics.get('avg_baseline_distance')\n",
    "    if avg_baseline is not None:\n",
    "        if avg_baseline < 2.0:\n",
    "            insights.append({\n",
    "                \"category\": \"Court Positioning\",\n",
    "                \"insight\": \"Baseline-dominant play\",\n",
    "                \"description\": \"Player tends to stay close to the baseline, which may limit opportunities for aggressive net play.\"\n",
    "            })\n",
    "        elif avg_baseline > 5.0:\n",
    "            insights.append({\n",
    "                \"category\": \"Court Positioning\",\n",
    "                \"insight\": \"Net-approaching tendency\",\n",
    "                \"description\": \"Player frequently approaches the net, showing an aggressive tactical approach.\"\n",
    "            })\n",
    "    \n",
    "    # 2. Shot Type Distribution Insights\n",
    "    shot_dist = position_metrics.get('shot_type_distribution', {})\n",
    "    if shot_dist:\n",
    "        total_shots = sum(shot_dist.values())\n",
    "        \n",
    "        # Check for dominant shot types\n",
    "        for shot_type, count in shot_dist.items():\n",
    "            percentage = count / total_shots\n",
    "            if percentage > 0.7:\n",
    "                insights.append({\n",
    "                    \"category\": \"Shot Selection\",\n",
    "                    \"insight\": f\"Over-reliance on {shot_type} shots\",\n",
    "                    \"description\": f\"Player uses {shot_type} shots for {percentage:.1%} of all shots, which may make play predictable.\"\n",
    "                })\n",
    "    \n",
    "    # 3. Success Rate Insights\n",
    "    success_by_shot = position_metrics.get('success_by_shot_type', {})\n",
    "    if success_by_shot:\n",
    "        # Find strongest and weakest shots\n",
    "        if len(success_by_shot) > 1:\n",
    "            strongest_shot = max(success_by_shot.items(), key=lambda x: x[1])\n",
    "            weakest_shot = min(success_by_shot.items(), key=lambda x: x[1])\n",
    "            \n",
    "            insights.append({\n",
    "                \"category\": \"Shot Effectiveness\",\n",
    "                \"insight\": f\"Strongest shot: {strongest_shot[0]}\",\n",
    "                \"description\": f\"Player achieves {strongest_shot[1]:.1%} success rate with {strongest_shot[0]} shots.\"\n",
    "            })\n",
    "            \n",
    "            if weakest_shot[1] < 0.4:  # Only highlight if clearly a weakness\n",
    "                insights.append({\n",
    "                    \"category\": \"Areas for Improvement\",\n",
    "                    \"insight\": f\"Weakness in {weakest_shot[0]} shots\",\n",
    "                    \"description\": f\"Player achieves only {weakest_shot[1]:.1%} success rate with {weakest_shot[0]} shots, suggesting room for improvement.\"\n",
    "                })\n",
    "    \n",
    "    # 4. Environment Insights\n",
    "    success_by_env = position_metrics.get('success_by_environment', {})\n",
    "    if success_by_env and len(success_by_env) > 1:\n",
    "        # Compare indoor vs outdoor performance\n",
    "        if 'indoor' in success_by_env and 'outdoor' in success_by_env:\n",
    "            diff = success_by_env['indoor'] - success_by_env['outdoor']\n",
    "            if abs(diff) > 0.15:  # Significant difference\n",
    "                better_env = 'indoor' if diff > 0 else 'outdoor'\n",
    "                insights.append({\n",
    "                    \"category\": \"Environment Preference\",\n",
    "                    \"insight\": f\"Better performance in {better_env} conditions\",\n",
    "                    \"description\": f\"Player performs {abs(diff):.1%} better in {better_env} conditions compared to {'outdoor' if better_env == 'indoor' else 'indoor'}.\"\n",
    "                })\n",
    "    \n",
    "    # 5. Position Cluster Insights\n",
    "    clusters = position_metrics.get('position_clusters', [])\n",
    "    if clusters:\n",
    "        # Find highest success cluster\n",
    "        if 'success' in clusters[0]:\n",
    "            best_cluster = max(clusters, key=lambda x: x['success'])\n",
    "            \n",
    "            insights.append({\n",
    "                \"category\": \"Optimal Court Positioning\",\n",
    "                \"insight\": \"Identified optimal court position\",\n",
    "                \"description\": f\"Player achieves highest success ({best_cluster['success']:.1%}) when positioned around {best_cluster['to_sideline_distance']:.1f}m from sideline and {best_cluster['to_baseline_distance']:.1f}m from baseline.\"\n",
    "            })\n",
    "    \n",
    "    return insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprehensive Dashboard\n",
    "We have created a comprehensive dashboard of strategic insights based on court position\n",
    "    \n",
    "    Parameters:\n",
    "    - position_metrics: Dictionary containing position analysis results\n",
    "    - visualizations: Dictionary of matplotlib figures\n",
    "    - player_name: Name of the player for labeling\n",
    "    - output_path: Optional path to save the dashboard\n",
    "    \n",
    "    Returns:\n",
    "    - Figure of the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a strategic insights dashboard\n",
    "def create_position_dashboard(position_metrics, visualizations, player_name=\"Player\", output_path=None):\n",
    "    # Generate insights\n",
    "    insights = generate_position_insights(position_metrics)\n",
    "    \n",
    "    # Create dashboard figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Define the grid layout\n",
    "    gs = gridspec.GridSpec(3, 6, figure=fig)\n",
    "    \n",
    "    # 1. Header with player name and key metrics\n",
    "    ax_header = fig.add_subplot(gs[0, :])\n",
    "    ax_header.axis('off')\n",
    "    \n",
    "    header_text = f\"{player_name} - Court Position Analysis Dashboard\"\n",
    "    ax_header.text(0.5, 0.6, header_text, fontsize=24, ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    # Add key metrics below the header\n",
    "    metrics_text = \"\"\n",
    "    metrics_text += f\"Total Shots: {position_metrics.get('total_shots', 'N/A')} | \"\n",
    "    metrics_text += f\"Success Rate: {position_metrics.get('success_rate', 0):.1%} | \"\n",
    "    metrics_text += f\"Avg. Distance to Baseline: {position_metrics.get('avg_baseline_distance', 0):.1f}m | \"\n",
    "    metrics_text += f\"Avg. Distance to Sideline: {position_metrics.get('avg_sideline_distance', 0):.1f}m\"\n",
    "    \n",
    "    ax_header.text(0.5, 0.2, metrics_text, fontsize=14, ha='center', va='center')\n",
    "    \n",
    "    # 2. Shot Distribution Visualization\n",
    "    if 'shot_distribution' in visualizations:\n",
    "        ax_dist = fig.add_subplot(gs[1:3, 0:2])\n",
    "        # Copy content from the figure to the dashboard\n",
    "        shot_dist_fig = visualizations['shot_distribution']\n",
    "        shot_dist_ax = shot_dist_fig.axes[0]\n",
    "        \n",
    "        # Draw the court\n",
    "        draw_tennis_court(ax_dist)\n",
    "        \n",
    "        # Copy scatter points\n",
    "        for collection in shot_dist_ax.collections:\n",
    "            offsets = collection.get_offsets()\n",
    "            # Optionally get sizes, colors, etc.\n",
    "            sizes = collection.get_sizes()\n",
    "            facecolors = collection.get_facecolors()\n",
    "            edgecolors = collection.get_edgecolors()\n",
    "            \n",
    "            # Recreate the scatter plot on the new axes\n",
    "            ax_dist.scatter(\n",
    "                offsets[:, 0],\n",
    "                offsets[:, 1],\n",
    "                s=sizes,\n",
    "                c=facecolors if facecolors.size else None,\n",
    "                edgecolors=edgecolors if edgecolors.size else None\n",
    "            )\n",
    "        \n",
    "        ax_dist.set_title(shot_dist_ax.get_title())\n",
    "        ax_dist.set_xlabel(shot_dist_ax.get_xlabel())\n",
    "        ax_dist.set_ylabel(shot_dist_ax.get_ylabel())\n",
    "    \n",
    "    # 3. Position Heatmap\n",
    "    if 'position_heatmap' in visualizations:\n",
    "        ax_heat = fig.add_subplot(gs[1, 2:4])\n",
    "        # Copy content from the figure to the dashboard\n",
    "        heat_fig = visualizations['position_heatmap']\n",
    "        heat_ax = heat_fig.axes[0]\n",
    "        \n",
    "        # Draw the court\n",
    "        draw_tennis_court(ax_heat)\n",
    "        \n",
    "        for collection in heat_ax.collections:\n",
    "            if hasattr(collection, 'get_paths'):\n",
    "                # Extract vertices from each path\n",
    "                segments = []\n",
    "                for path in collection.get_paths():\n",
    "                    if hasattr(path, 'vertices') and len(path.vertices) > 1:\n",
    "                        # Only add the vertices array, not the Path object itself\n",
    "                        segments.append(path.vertices)\n",
    "                \n",
    "                if segments:  # Make sure there are segments to copy\n",
    "                    lc = LineCollection(segments, \n",
    "                                    colors=collection.get_edgecolors(),\n",
    "                                    linewidths=collection.get_linewidths(),\n",
    "                                    linestyles=collection.get_linestyles(),\n",
    "                                    alpha=collection.get_alpha())\n",
    "                    ax_heat.add_collection(lc)\n",
    "    \n",
    "    # 4. Success by Shot Type\n",
    "    if 'success_by_shot_type' in visualizations:\n",
    "        ax_shot = fig.add_subplot(gs[1, 4:6])\n",
    "        # Copy content from the figure to the dashboard\n",
    "        shot_fig = visualizations['success_by_shot_type']\n",
    "        shot_ax = shot_fig.axes[0]\n",
    "        \n",
    "        # Copy bar chart\n",
    "        for patch in shot_ax.patches:\n",
    "            ax_shot.bar(\n",
    "                patch.get_x() + patch.get_width()/2,\n",
    "                patch.get_height(),\n",
    "                width=patch.get_width(),\n",
    "                color=patch.get_facecolor()\n",
    "            )\n",
    "        \n",
    "        # Copy text annotations\n",
    "        for text in shot_ax.texts:\n",
    "            ax_shot.text(\n",
    "                text.get_position()[0],\n",
    "                text.get_position()[1],\n",
    "                text.get_text(),\n",
    "                ha=text.get_ha(),\n",
    "                va=text.get_va()\n",
    "            )\n",
    "        \n",
    "        ax_shot.set_ylim(0, 100)\n",
    "        ax_shot.set_ylabel(shot_ax.get_ylabel())\n",
    "        ax_shot.set_title(shot_ax.get_title())\n",
    "        ax_shot.set_xticks(shot_ax.get_xticks())\n",
    "        ax_shot.set_xticklabels(shot_ax.get_xticklabels())\n",
    "        ax_shot.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 5. Environment Comparison\n",
    "    if 'success_by_environment' in visualizations:\n",
    "        ax_env = fig.add_subplot(gs[2, 2:4])\n",
    "        # Copy content from the figure to the dashboard\n",
    "        env_fig = visualizations['success_by_environment']\n",
    "        env_ax = env_fig.axes[0]\n",
    "        \n",
    "        # Copy bar chart\n",
    "        for patch in env_ax.patches:\n",
    "            ax_env.bar(\n",
    "                patch.get_x() + patch.get_width()/2,\n",
    "                patch.get_height(),\n",
    "                width=patch.get_width(),\n",
    "                color=patch.get_facecolor()\n",
    "            )\n",
    "        \n",
    "        # Copy text annotations\n",
    "        for text in env_ax.texts:\n",
    "            ax_env.text(\n",
    "                text.get_position()[0],\n",
    "                text.get_position()[1],\n",
    "                text.get_text(),\n",
    "                ha=text.get_ha(),\n",
    "                va=text.get_va()\n",
    "            )\n",
    "        \n",
    "        ax_env.set_ylim(0, 100)\n",
    "        ax_env.set_ylabel(env_ax.get_ylabel())\n",
    "        ax_env.set_title(env_ax.get_title())\n",
    "        ax_env.set_xticks(env_ax.get_xticks())\n",
    "        ax_env.set_xticklabels(env_ax.get_xticklabels())\n",
    "        ax_env.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 6. Strategic Insights Panel\n",
    "    if insights:\n",
    "        # Group insights by category\n",
    "        \n",
    "        categories = defaultdict(list)\n",
    "        for insight in insights:\n",
    "            categories[insight['category']].append(insight)\n",
    "        \n",
    "        # Create text for insights panel\n",
    "        insights_text = \"STRATEGIC INSIGHTS:\\n\\n\"\n",
    "        \n",
    "        for category, category_insights in categories.items():\n",
    "            insights_text += f\"{category}:\\n\"\n",
    "            for i, insight in enumerate(category_insights, 1):\n",
    "                insights_text += f\"  {i}. {insight['insight']}\\n\"\n",
    "            insights_text += \"\\n\"\n",
    "        \n",
    "        # Add insights text to the dashboard\n",
    "        ax_insights = fig.add_subplot(gs[2, 4:6])\n",
    "        ax_insights.axis('off')\n",
    "        ax_insights.text(0.05, 0.95, insights_text, fontsize=12, va='top', linespacing=1.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if output path is provided\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, bbox_inches='tight')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Execution Function to Execute Analysis\n",
    "Run the complete tennis position analysis pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    - video_data: List of dictionaries containing video information\n",
    "    - player_name: Name of the player for labeling\n",
    "    - output_dir: Directory to save output files\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary containing analysis results and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main function to run the complete position-based tennis analysis\n",
    "def run_position_based_tennis_analysis(video_data, player_name=\"Player\", output_dir=\"./perf\"):\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Starting tennis position analysis for {player_name}...\")\n",
    "    \n",
    "    # 1. Generate synthetic success data based on position\n",
    "    print(\"Generating synthetic success estimates...\")\n",
    "    enhanced_data = generate_success_data(video_data)\n",
    "    \n",
    "    # 2. Analyze court positions\n",
    "    print(\"Analyzing court positions...\")\n",
    "    position_metrics = analyze_court_positions(enhanced_data)\n",
    "    \n",
    "    # 3. Create visualizations\n",
    "    print(\"Creating visualizations...\")\n",
    "    court_dimensions = {\n",
    "        'width': 10.97,\n",
    "        'length': 23.77\n",
    "    }\n",
    "    visualizations = visualize_court_positions(enhanced_data, court_dimensions)\n",
    "    \n",
    "    # 4. Create dashboard\n",
    "    print(\"Creating position analysis dashboard...\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    dashboard_path = os.path.join(output_dir, f\"{player_name}_position_dashboard_{timestamp}.png\")\n",
    "    dashboard = create_position_dashboard(\n",
    "        position_metrics,\n",
    "        visualizations,\n",
    "        player_name,\n",
    "        dashboard_path\n",
    "    )\n",
    "    \n",
    "    print(f\"Analysis complete. Dashboard saved to: {dashboard_path}\")\n",
    "    \n",
    "    # 5. Generate text report\n",
    "    report_path = os.path.join(output_dir, f\"{player_name}_position_analysis_{timestamp}.txt\")\n",
    "    insights = generate_position_insights(position_metrics)\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(f\"Tennis Position Analysis Report for {player_name}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"SUMMARY STATISTICS:\\n\")\n",
    "        f.write(f\"Total Shots: {position_metrics.get('total_shots', 'N/A')}\\n\")\n",
    "        f.write(f\"Success Rate: {position_metrics.get('success_rate', 0):.1%}\\n\")\n",
    "        f.write(f\"Avg. Distance to Baseline: {position_metrics.get('avg_baseline_distance', 0):.1f}m\\n\")\n",
    "        f.write(f\"Avg. Distance to Sideline: {position_metrics.get('avg_sideline_distance', 0):.1f}m\\n\\n\")\n",
    "        \n",
    "        f.write(\"SHOT TYPE DISTRIBUTION:\\n\")\n",
    "        shot_dist = position_metrics.get('shot_type_distribution', {})\n",
    "        for shot_type, count in shot_dist.items():\n",
    "            percentage = count / position_metrics['total_shots'] if position_metrics['total_shots'] > 0 else 0\n",
    "            f.write(f\"{shot_type}: {count} shots ({percentage:.1%})\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"STRATEGIC INSIGHTS:\\n\")\n",
    "        for insight in insights:\n",
    "            f.write(f\"[{insight['category']}] {insight['insight']}\\n\")\n",
    "            f.write(f\"  {insight['description']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\nThis analysis was generated automatically based on available court position data generated by members of group 09 for the subject Video Analytics.\\n\")\n",
    "        f.write(\"Generated on: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    print(f\"Analysis report saved to: {report_path}\")\n",
    "    \n",
    "    return {\n",
    "        'enhanced_data': enhanced_data,\n",
    "        'position_metrics': position_metrics,\n",
    "        'visualizations': visualizations,\n",
    "        'dashboard': dashboard,\n",
    "        'insights': insights,\n",
    "        'dashboard_path': dashboard_path,\n",
    "        'report_path': report_path\n",
    "    }\n",
    "results = run_position_based_tennis_analysis(video_data, \"Tennis Player\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
