{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "\n",
    "# Pre setup to avoid ssl issues\n",
    "import ssl\n",
    "\n",
    "# Disable SSL verification globally\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "# Each image is a grayscale image of 784 pixels (784,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">201,488</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m201,488\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,720</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m476,720\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,720</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m476,720\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "encoding_dim = 32  # Size of our encoded representations \n",
    "\n",
    "input_img = keras.Input(shape=(x_train.shape[1],))                   # Input image\n",
    "encoded = layers.Dense(256, activation='relu')(input_img)   # \"encoded\" is encoded representation of  input\n",
    "encoded = layers.Dense(128, activation='relu')(encoded)   # \"encoded\" is encoded representation of  input\n",
    "\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)   # \"encoded\" is encoded representation of  input -> This is also latent space\n",
    "\n",
    "decoded = layers.Dense(128, activation='relu')(encoded)   # \"encoded\" is encoded representation of  input\n",
    "decoded = layers.Dense(256, activation='relu')(decoded)   # \"encoded\" is encoded representation of  input\n",
    "\n",
    "\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)           # \"decoded\" is lossy reconstruction of  input\n",
    "autoencoder = keras.Model(input_img, decoded)                        # This model maps an input to its reconstruction\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4345 - val_loss: 0.3150\n",
      "Epoch 2/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3083 - val_loss: 0.3063\n",
      "Epoch 3/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2978 - val_loss: 0.2951\n",
      "Epoch 4/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2921 - val_loss: 0.2919\n",
      "Epoch 5/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2888 - val_loss: 0.2888\n",
      "Epoch 6/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2859 - val_loss: 0.2867\n",
      "Epoch 7/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2838 - val_loss: 0.2849\n",
      "Epoch 8/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2819 - val_loss: 0.2847\n",
      "Epoch 9/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2824 - val_loss: 0.2824\n",
      "Epoch 10/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2796 - val_loss: 0.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x383243e60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m x_testr \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(input_img, encoded)            \u001b[38;5;66;03m# This model maps an input to its encoded representation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(encoding_dim,))   \u001b[38;5;66;03m# This is our encoded (32-dimensional) input\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m decoder \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(encoded_input, \u001b[43mdecoder_layer\u001b[49m(encoded_input))  \u001b[38;5;66;03m# Create the decoder model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m decoded_imgs \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mpredict(encoded_imgs)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_layer' is not defined"
     ]
    }
   ],
   "source": [
    "x_testr = keras.Model(input_img, encoded)            # This model maps an input to its encoded representation\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))   # This is our encoded (32-dimensional) input\n",
    "\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))  # Create the decoder model\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('First row is orignal images')\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print('Second row is reconstrcuted images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded representations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = keras.Model(input_img, encoded)           # This model maps an input to its encoded representation\n",
    "encoded_imgs = encoder.predict(x_test)              # This is our encoded (32-dimensional) input\n",
    "\n",
    "print('Encoded representations')\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape((1, 4 * 8)).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
